[ { "title": "Spring", "url": "/posts/Spring/", "categories": "笔记", "tags": "Spring", "date": "2023-03-22 22:34:00 +0000", "snippet": "Spring基础1. Spring特性从Spring框架的特性来看，有以下内容 非侵入式：基于Spring开发的应用中的对象可以不依赖于Spring的API； 控制反转：IOC指的是将对象的创建权交给Spring去创建。使用Spring之前，对象的创建都是用new来进行； 依赖注入：DI是指依赖的对象不需要手动调用set方法去设置。而是通过配置赋值； 面向切面编程：AOP 容器：S...", "content": "Spring基础1. Spring特性从Spring框架的特性来看，有以下内容 非侵入式：基于Spring开发的应用中的对象可以不依赖于Spring的API； 控制反转：IOC指的是将对象的创建权交给Spring去创建。使用Spring之前，对象的创建都是用new来进行； 依赖注入：DI是指依赖的对象不需要手动调用set方法去设置。而是通过配置赋值； 面向切面编程：AOP 容器：Spring是一个容器，因为它包含并且管理应用对象的声明周期 组件化：Spring实现了使用简单的组件配置组合成一个复杂的应用。在Spring中可以使用XML和Java注解来组合这些对象；2. Spring组件Spring框架的所有模块如下：Spring Core ContainerSpring的核心容器是其他模块建立的基础，由Beans模块，Core核心模块，Context上下文模块和SpEL表达式语言模块组成。 Beans模块：提供了框架的基础部分，包括控制反转和依赖注入。 Core核心模块：封装了Spring框架的底层部分，包括资源访问，类型转换以及一些常用的工具类。 Context上下文模块：建立在Core和Beans模块的基础上，基础Beans模块功能并添加资源绑定，数据验证，国际化，JavaEE支持，容器生命周期，事件传播等。 SpEL模块：提供强大的表达式语言支持，支持访问和修改属性值，方法调用，支持访问及修改数组等。Data Access/Integration数据访问/集成层包括JDBC，ORM，OXM，JMS和Transactions模块 JDBC模块：提供了一个JDBC的样例模板，使用这些模板能消除冗长的JDBC编码还有必须的事务控制，能享受到Spring管理事务的好处。 ORM模块：提供与流行的对象-关系映射框架无缝集成的API，包括 JPA、JDO、Hibernate 和 MyBatis 等。而且还可以使用 Spring 事务管理，无需额外控制事务。 OXM模块：提供了一个支持Object/XML映射的抽象层实现。将Java对象映射成XML数据，或者将XML数据映射成Java对象。 JMS模块：指Java消息服务，用于在两个应用之间或分布式系统中发送消息，进行异步通信。 Transactions事务模块：支持编程和声明式事务管理。Web模块Spring的Web层包含以下组件： Web模块：提供了最基本的Web开发集成特性，例如多文件上传功能，使用的Servlet监听器和IOC容器初始化以及Web应用上下文。 Servlet模块：提供了一个Spring MVC Web框架实现。Spring MVC框架提供了基于注解的请求资源注入，更简单的数据绑定，数据验证等。 WebSocket模块：提供了简单的接口，用户只要实现响应的接口就可以快速的搭建WebSocket Server，从而实现双向通讯。 WebFlux模块：Spring WebFlux是Spring Framework5中引入的新的响应式web框架。与Spring MVC不同，它不需要Servlet API，是完全异步且非阻塞的，并且通过Reactor项目实现了Reactive Streams规范，Spring WebFlux用于创建基于事件循环执行模型的完全异步且非阻塞的应用程序。AOP，Aspects，Instrumentation和Messaging具体包含以下组件： AOP模块：提供了面向切面编程的实现，提供比如日志记录，权限控制，性能统计等通用功能和业务逻辑分离的技术，并且通过动态的把这些功能添加到需要的代码中来降低系统的耦合。 Aspects模块：提供与AspectJ的集成，是一个强大且成熟的AOP框架。 Instrumentation模块：提供了类工具的支持和类加载器的实现，可以在特定的应用服务器中使用。 messaging模块：提供了对消息传递体系结构和协议的支持。Test模块提供了对JUnit和TestNG测试的支持，还提供了一些基于Spring的测试功能。IOC控制反转1. 基础IoC（控制反转）是一种设计思想，将原本在程序中手动创建对象的控制权，交由Spring框架管理。Spring里面的bean就类似是定义的一个组件，而组件的作用就是实现某个功能。传统的Java程序设计需要直接在对象内部通过new进行创建，而在Spring中，Spring框架管理这些Bean的创建工作。Spring框架将托管的Bean放置在IoC容器中，支持xml配置，Java配置以及注解配置等，并管理Bean的整个生命周期。应用程序从IoC容器中获取依赖的Bean，注入到程序中，这个过程叫依赖注入，控制反转通过依赖注入实现。2. Spring Bean作用域singleton唯一bean实例，Spring中的bean默认都是单例的。prototype每次请求都会创建一个新的bean实例。request每一次HTTP请求都会产生一个新的bean，该bean仅在当前的HTTP request内有效。session每一次HTTP请求都会产生一个新的bean，该bean仅在当前HTTP session内有效。global-session全局session作用域，仅仅在给予portlet的web中才有意义，Spring5已经没有了。单例bean线程安全多个线程操作同一个对象的时候，对这个对象的成员变量的写操作会存在线程安全问题。一般情况下，常用的Controller，Service，Dao这些Bean都是无状态的，无状态的bean不能保存数据，因此是线程安全的。解决方法：在类中定义一个ThreadLocal成员变量，将需要的可变成员变量保存在ThreadLocal中。改变Bean的作用域为“prototype”：每次请求都会创建一个新的bean实例，自然不会存在线程安全问题。@Component和Bean区别Component注解作用于类，通常是通过类路径扫描来自动侦测以及自动装配到Spring容器中。Bean作用于方法，@Bean告诉Spring这是某个类的示例，当需要用他的时候还给。@Bean注解比Component注解的自定义性更强，而且很多地方我们只能通过@Bean注解来注册Bean，比如当引用第三方库中的类需要装配到Spring容器中时，则只能通过Bean来实现。类声明为Spring的Bean注解@Autowired注解自动装配bean@Component，通用的注解，可标注任意类为Spring组件。如果一个Bean不知道属于哪个层，可以用@Component注解标注。@Repository，对应持久层，主要用于数据库相关操作。@Service，对应服务层，主要涉及一些复杂逻辑，需要用到dao层。@Controller，对应SpringMVC控制层，主要用于接受用户请求并调用Service层返回数据给前端页面。Bean生命周期 BeanDefinitionReader读取Bean的配置信息(XML等)，将读取到的每个Bean的配置信息使用BeanDefinition表示，同时注册到相应的BeanDefinitionRegistry(一个map)中。 通过实现了BeanFactoryPostProcessor的类，自定义修改BeanDefinition中的信息(如果有的话) Bean的实例化:(1) 采用策略化bean的实例， 两种方式: cglib，反射(2) 获取Bean的实例之后，根据BeanDefinition中信息，填充Bean的属性、依赖 检测各种Aware接口，BeanFactory的、ApplicationContext的等 调用BeanPostProcessor接口的前置处理方法，处理符合要求的Bean实例 如果实现了InitializingBean接口，执行对应的afterPropertiesSet()方法 如果定义了init-method，执行对应的自定义初始化方法 调用BeanPostProcessor接口的前置处理方法，处理符合要求的Bean实例 使用 判断Bean的Scope，如果是prototype类型，不再管理 如果是单例类型，如果实现了DisposableBean接口，执行对应的destoy方法 如果定义了destory-method，执行对应的自定义销毁方法概括起来就是4个阶段实例化：实例化一个bean对象；属性赋值：为bean设置相关属性和依赖；初始化：Aware接口的依赖注入、BeanPostProcessor在初始化前后的处理以及InitializingBean和init-method的初始化操作；销毁：注册相关销毁回调接口，最后通过DisposableBean 和 destory-method 进行销毁。Aware接口若Spring检测到bean实现了Aware接口，则会为其注入相应的依赖。所以通过让bean实现Aware接口，则能在bean中获得相应的Spring容器资源。3. IOC容器IoC容器指Spring用来实现IoC的载体，用来控制对象的生命周期以及对象间的关系。实际上就是个Map，存放的是各种对象。比如xml里配置的bean节点，@controller，@repository，@compoment等。在Spring中BeanFactory是IoC容器的实际代表者。4. IoC配置IoC配置有三种方式，目前主流的方式是注解+Java配置。xml配置就是将bean的信息配置到xml文件里，通过Spring加载文件为我们创建bean。这种方式出现较早，优点是可以使用于任何场景，结构清晰，通俗易懂，缺点是配置繁琐，不宜维护，拓展性差。Java配置将类的创建交给自己创建的JavaConfig来完成，Spring只负责维护和管理，采用纯Java方式，其本质上就是把在XML上的配置声明转移到Java配置类中。优点是适用于任何场景，由于是纯Java代码，扩展性高，但是缺点是声明不明显，如果大量配置可读性较差。注解配置通过在类上加注解的方式，来声明一个类交给Spring管理，Spring会自动扫描带有@Component，@Controller，@Service，@Repository这四个注解的类，然后帮我们创建和管理。前提是要先配置Spring的注解扫描器。优点是开发便捷，通俗易懂，方便维护，缺点是具有局限性，对于一些第三方资源无法添加注解。5. 依赖注入常用的注入方式主要有三种：构造方法注入（Construct注入），setter注入，基于注解的注入（接口注入）setter方式setter方式本质上包含两步，第一步是需要new UserServiceImpl()创建对象, 所以需要默认构造函数，第二步，调用setUserDao()函数注入userDao的值, 所以需要setUserDao()函数。构造方法注入本质上是new UserServiceImpl(userDao)创建对象，注解注入以@Autowired注解注入为例，修饰符有三个属性：Constructor，byType，byName。默认按照byType注入。 constructor：通过构造方法进行自动注入，spring会匹配与构造方法参数类型一致的bean进行注入，如果有一个多参数的构造方法，一个只有一个参数的构造方法，在容器中查找到多个匹配多参数构造方法的bean，那么spring会优先将bean注入到多参数的构造方法中。 byName：被注入bean的id名必须与set方法后半截匹配，并且id名称的第一个单词首字母必须小写，这一点与手动set注入有点不同。 byType：查找所有的set方法，将符合符合参数类型的bean注入。AOP面向切面编程1. 基础即面向切面编程，其把功能分为核心业务功能，和周边功能 所谓的核心业务，比如登录，增加数据，删除数据都叫核心业务 所谓的周边功能，比如性能统计，日志，事务管理等等周边功能在 Spring 的面向切面编程AOP思想里，即被定义为切面。在面向切面编程AOP的思想里面，核心业务功能和切面功能分别独立进行开发，然后把切面功能和核心业务功能 “编织” 在一起，这就叫AOP。我们将记录日志功能解耦为日志切面，它的目标是解耦。进而引出AOP的理念：就是将分散在各个业务逻辑代码中相同的代码通过横向切割的方式抽取到一个独立的模块中。他将那些与业务无关，却为业务模块所共同调用的逻辑或责任（如事务处理，日志管理，权限控制等）封装起来。AOP能够减少那些与业务无关，却被业务模块共同调用的逻辑封装起来，从而减少系统的重复代码，降低模块间的耦合度，提高可拓展性。2. 术语 连接点（Jointpoint）：表示需要在程序中插入横切关注点的扩展点，连接点可能是类初始化、方法执行、方法调用、字段调用或处理异常等； 切入点（Pointcut）：选择一组相关连接点的模式，即可以认为连接点的集合，Spring默认使用AspectJ语法； 通知（Advice）：在连接点上执行的行为，通知提供了在AOP中需要在切入点所选择的连接点处进行扩展现有行为的手段；包括前置通知（before advice）、后置通知(after advice)、环绕通知（around advice），在Spring中通过代理模式实现AOP，并通过拦截器模式以环绕连接点的拦截器链织入通知； 方面/切面（Aspect）：横切关注点的模块化，比如的日志组件。可以认为是通知、引入和切入点的组合；在Spring中可以使用Schema和@AspectJ方式进行组织实现； 引入（inter-type declaration）：也称为内部类型声明，为已有的类添加额外新的字段或方法，Spring允许引入新的接口（必须对应一个实现）到所有被代理对象（目标对象）； 目标对象（Target Object）：需要被织入横切关注点的对象，即该对象是切入点选择的对象，需要被通知的对象，从而也可称为被通知对象； 织入（Weaving）：把切面连接到其它的应用程序类型或者对象上，并创建一个被通知的对象。这些可以在编译时（例如使用AspectJ编译器），类加载时和运行时完成。Spring和其他纯Java AOP框架一样，在运行时完成织入； AOP代理（AOP Proxy）：AOP框架使用代理模式创建的对象，从而实现在连接点处插入通知（即应用切面），就是通过代理来对目标对象应用切面。通知类型 前置通知：在某连接点之前执行的通知，但这个通知不能阻止连接点之前的执行流程； 后置通知：在某连接点正常完成后执行的通知； 异常通知：在方法抛出异常推出时执行的通知； 最终通知：在某连接点推出的时候执行的通知，不管他是正常结束或者抛出异常； 环绕通知：包围一个连接点的通知，如方法调用。环绕通知可以在方法调用前后完成自定义行为。环绕通知是最常用的通知类型。和AspectJ一样，Spring提供所有类型的通知。但是推荐尽量使用简单的通知类型来实现需要的功能。3. Spring AOP和AspectJAspectJAspectJ是一个java实现的AOP框架，它能够对java代码进行AOP编译（一般在编译期进行），让java代码具有AspectJ的AOP功能（当然需要特殊的编译器）。AspectJ是目前实现AOP框架中最成熟，功能最丰富的语言，更幸运的是，AspectJ与java程序完全兼容。两者关系 AspectJ是更强的AOP框架，是实际意义的AOP标准； Spring为何不写类似AspectJ的框架？ Spring AOP使用纯Java实现, 它不需要专门的编译过程, 它一个重要的原则就是无侵入性（non-invasiveness）; Spring 小组完全有能力写类似的框架，只是Spring AOP从来没有打算通过提供一种全面的AOP解决方案来与AspectJ竞争。Spring的开发小组相信无论是基于代理的框架如Spring AOP或者是成熟的框架如AspectJ都是很有价值的，他们之间应该是互补而不是竞争的关系。 Spring小组喜欢@AspectJ注解风格更胜于Spring XML配置； 所以在Spring 2.0使用了和AspectJ 5一样的注解，并使用AspectJ来做切入点解析和匹配。但是，AOP在运行时仍旧是纯的Spring AOP，并不依赖于AspectJ的编译器或者织入器（weaver）。4. AOP配置方式Spring AOP支持对XML模式和基于@AspectJ注解的两种配置方式。XML Schema配置方式Spring提供了使用aop命名空间来定义一个切面。通过在xml文件中配置关联目标类和切面来进行AOP。&lt;aop:aspectj-autoproxy/&gt; &lt;!-- 目标类 --&gt; &lt;bean id=\"demoService\" class=\"tech.pdai.springframework.service.AopDemoServiceImpl\"&gt; &lt;!-- configure properties of bean here as normal --&gt; &lt;/bean&gt; &lt;!-- 切面 --&gt; &lt;bean id=\"logAspect\" class=\"tech.pdai.springframework.aspect.LogAspect\"&gt; &lt;!-- configure properties of aspect here as normal --&gt; &lt;/bean&gt; &lt;aop:config&gt; &lt;!-- 配置切面 --&gt; &lt;aop:aspect ref=\"logAspect\"&gt; &lt;!-- 配置切入点 --&gt; &lt;aop:pointcut id=\"pointCutMethod\" expression=\"execution(* tech.pdai.springframework.service.*.*(..))\"/&gt; &lt;!-- 环绕通知 --&gt; &lt;aop:around method=\"doAround\" pointcut-ref=\"pointCutMethod\"/&gt; &lt;!-- 前置通知 --&gt; &lt;aop:before method=\"doBefore\" pointcut-ref=\"pointCutMethod\"/&gt; &lt;!-- 后置通知；returning属性：用于设置后置通知的第二个参数的名称，类型是Object --&gt; &lt;aop:after-returning method=\"doAfterReturning\" pointcut-ref=\"pointCutMethod\" returning=\"result\"/&gt; &lt;!-- 异常通知：如果没有异常，将不会执行增强；throwing属性：用于设置通知第二个参数的的名称、类型--&gt; &lt;aop:after-throwing method=\"doAfterThrowing\" pointcut-ref=\"pointCutMethod\" throwing=\"e\"/&gt; &lt;!-- 最终通知 --&gt; &lt;aop:after method=\"doAfter\" pointcut-ref=\"pointCutMethod\"/&gt; &lt;/aop:aspect&gt;&lt;/aop:config&gt;AspectJ注解方式基于XML声明式配置存在一些不足，比如需要在Spring配置文件配置大量的代码信息，所以Spring使用了@AspectJ框架为AOP的实现提供了一套注解。 @Aspect：用来定义一个切面； @pointcut：用于定义切入点表达式，在使用时还需要定义一个包含名字和任意参数的方法签名来表示切入点名称，这个方法签名就是一个返回值为void，且方法体为空的普通方法； @Before：用于定义前置通知，相当于BeforeAdvice，在使用时，通常需要指定一个value属性值，该属性值用于指定一个切入点表达式(可以是已有的切入点，也可以直接定义切入点表达式)； @AfterReturning：用于定义后置通知，相当于AfterReturningAdvice，在使用时可以指定pointcut / value和returning属性，其中pointcut / value这两个属性的作用一样，都用于指定切入点表达式； @Around：用于定义环绕通知，相当于MethodInterceptor，在使用时需要指定一个value属性，该属性用于指定该通知被植入的切入点； @After-Throwing：用于定义异常通知来处理程序中未处理的异常，相当于ThrowAdvice； @After：用于定义最终final通知，不管是否异常，该通知都会执行。使用的时候需要指定一个value属性，该属性用于指定该通知被植入的切入点。AspectJ注解织入方式Spring AOP的实现方式是动态织入，动态织入的方式是在运行的时候动态的将要增强的代码织入到目标类中，这样往往是通过动态代理技术实现完成的。如Java JDK的动态代理或者CGLIB的动态代理。Spring AOP采用的是基于运行时增强的代理技术。定义Aspect如下@Aspectpublic class PerformanceTraceAspect { private final Log logger = LogFactory.getLog(PerformanceTraceAspect.class); @Pointcut(\"execution(public void *.method1()) || execution(public void *.method2())\") public void myPointcut() {} @Around(\"myPointcut()\") public Object performanceTrace(ProceedingJoinPoint joinPoint) throws Throwable { StopWatch watch = new StopWatch(); try { watch.start(); return joinPoint.proceed(); } finally { watch.stop(); if (logger.isInfoEnabled()) { logger.info(\"PT in method[\" + joinPoint.getSignature().getName() + \"]&gt;&gt;&gt;\" + watch.toString()); } } }}通过AspectJProxyFactory手动织入private static void manualWeaver() { // 手动织入 AspectJProxyFactory weaver = new AspectJProxyFactory(); weaver.setProxyTargetClass(true); // 声明目标对象 weaver.setTarget(new Foo()); // 声明切面 weaver.addAspect(PerformanceTraceAspect.class); // 获取代理 Object proxy = weaver.getProxy(); // 执行已经织入切面逻辑的方法 ((Foo) proxy).method1(new FlyImpl()); ((Foo) proxy).method2();}Spring事务1. 基础Spring 事务的本质，其实就是通过 Spring AOP 切面技术，在合适的地方开启事务，接着在合适的地方提交事务或回滚事务，从而实现了业务编程层面的事务操作分类：编程式事务：代码中硬编码声明式事务：基于XML的声明式事务和基于注解的事务2. 隔离级别Spring的事务隔离级别和Mysql数据库类似，分为五种 ISOLATION_DEFAULT：使用后端数据库默认隔离级别 ISOLATION_READ_UNCOMMITED：读未提交，允许读取尚未提交的数据，最低的隔离级别 ISOLATION_READ_COMMITED：读已提交，允许读取并发事务已提交的数据，可以阻止脏读 ISOLATION_REPEATALBE_READ：可重复读，对同一字段多次读取结果都是一致的，无法阻止幻读 ISOLATION_SERIAZABLE：串行化，效率较低 3. 事务传播行为事务传播类型，指的是事务与事务之间的交互策略。例如：在事务方法 A 中调用事务方法 B，当事务方法 B 失败回滚时，事务方法 A 应该如何操作。Spring 事务中定义了 7 种事务传播类型，分别是：REQUIRED，SUPPORTS，MANDATORY，REQUIRES_NEW，NOT_SUPPORTED，NEVER，NESTED。其中最常用的只有 3 种，即：REQUIRED，REQUIRES_NEW，NESTED。 PROPAGATE_REQUIRED：REQUIRED 是 Spring 默认的事务传播类型，该传播类型的特点是：当前方法存在事务时，子方法加入该事务。此时父子方法共用一个事务，无论父子方法哪个发生异常回滚，整个事务都回滚。即使父方法捕捉了异常，也是会回滚。而当前方法不存在事务时，子方法新建一个事务。 PROPAGATE_REQUIRES_NEW：该传播类型的特点是：无论当前方法是否存在事务，子方法都新建一个事务。此时父子方法的事务时独立的，它们都不会相互影响。但父方法需要注意子方法抛出的异常，避免因子方法抛出异常，而导致父方法回滚。 PROPAGATE_NESTED：当前方法存在事务时，子方法加入在嵌套事务执行。当父方法事务回滚时，子方法事务也跟着回滚。当子方法事务发送回滚时，父事务是否回滚取决于是否捕捉了异常。如果捕捉了异常，那么就不回滚，否则回滚。与REQUIRED的区别是在子方法事务发生异常回滚时，父方法有着不同的反应动作。4. Spring事务失效若同一类中的其他没有 @Transactional 注解的方法内部调用有 @Transactional 注解的方法，有 @Transactional 注解的方法的事务会失效。这是由于 Spring AOP 代理的原因造成的，因为只有当 @Transactional 注解的方法在类以外被调用的时候，Spring 事务管理才生效。另外，如果直接调用，不通过对象调用，也是会失效的。因为 Spring 事务是通过 AOP 实现的。@Transactional 注解只有作用到 public 方法上事务才生效。被 @Transactional 注解的方法所在的类必须被 Spring 管理。底层使用的数据库必须支持事务机制，否则不生效。5. Spring设计模式工厂设计模式Spring使用工厂模式通过BeanFactory，ApplicationContext创建Bean对象。代理设计模式Spring AOP的功能实现。单例设计模式Spring中的Bean默认都是单例的。模版方法模式Spring中jdbcTemplate，hibernateTemplate等以template结尾等对数据库操作的类，他们就是用到了模版模式。包装器设计模式项目需要连接多个数据库，而不同的客户每次访问就要访问不同的数据库，这种模式让我们可以根据客户的需求去动态切换不同的数据库。观察者模式Spring事件驱动模型就是一个典型。适配器模式Spring AOP增强或通知使用到了这个模式。SpringBoot1. 基础SpringFramework优缺点Spring是Java企业版的轻量级替代品，其为企业级Java开发提供了一种相对简单的方法，通过依赖注入和面向切面编程，用简单的Java对象实现了企业级Java的功能.Spring可以带来一下好处： 使用Spring IOC容器，将对象之间的依赖关系交给Spring，降低组件之间的耦合性； 可以提供众多服务如事务管理等； 支持AOP，方便面向切面编程； 对主流框架提供了很好的集成支持，如hibernate，jpa等； Spring依赖注入降低了业务对象替换的复杂性； Spring属于低入侵，代码污染低； Spring高可开放，并不强制依赖于Spring，开发者可选择Spring的部分或全部。但是，Spring也有以下问题：虽然Spring的组件代码是轻量级的，但是他的配置却是重量级的。一开始Spring用XML配置，数量非常多。Spring2.5引入了基于注解的组件扫描，消除了大量显式XML配置。Spring3.0引入基于Java的配置。除此之外，项目的依赖管理也是一件耗时耗力的事情。在环境搭建时，需要分析要导入哪些库的坐标，而且还需要分析导入与之有依赖关系的其他库的坐标，一旦选错了依赖的版本，随之而来的不兼容问题就会严重阻碍项目的开发进度。SpringBoot特点SpringBoot对上述缺点进行了改善和优化，基于约定优于配置的思想，可以让开发人员不必在配置与逻辑业务之间进行思维转换。 为基于Spring的开发提供更快的入门体验； 开箱即用，没有代码生成，也无需XML配置。同时也可以修改默认值来满足特定的需求； 提供了一些大型项目中常见的非功能性特性，如嵌入式服务器，安全，指标，健康检测，外部配置等；SpringBoot不是对Spring功能上的增强，而是提供了一种快速使用Spring的方式。SpringBoot核心功能 起步依赖：其本质上是一个Maven项目对象模型，定义了对其他库的传递依赖，这些东西加在一起即支持某项功能。简单地说，起步依赖就是将具备某种功能的坐标打包到一起，并提供一些默认功能。 自动配置：SpringBoot的自动配置是一个运行时的过程，其是Spring自动完成的。常用注解 @SpringBootApplication：定义在main方法入口处，用于启动SpringBoot应用项目； @EnableAutoConfiguration：让SpringBoot根据路径中的jar包依赖当前项目进行自动配置，比如在src/main/resources的META-INF/spring.factories里； @Value：application.properties定义属性，直接使用@Value注入即可； @ConfigurationProperties(prefix=”person”)：可以新建一个properties文件，注解的属性prefix指定为properties配置的前缀，通过location指定properties文件的位置； @RestController：RestController只返回对象，其返回JSON或XML形式数据，在开发时需要与@Controller和@ResponseBody组合； @Controller：Controller只返回一个页面，用于标注组件的控制层； @Service, @Repository, @RequsetMapping, @RequestParam, @PathVariable @ResponseBody：支持将返回值放在response体内。而不是返回一个页面； @PostConstruct：Spring容器要初始化的时候，执行该方法； @Autowired：在默认情况下使用@Autowired注解进行自动注入时，Spring容器中匹配的候选Bean数目有且只能有一个。2. 统一封装接口RESTful APIREST指Representational State Transfer，即表现层状态转化，是所有Web应用都应该遵守的架构设计指导原则。面向资源是REST最明显的特征。RESTful API是符合REST设计标准的API，REST 架构设计，遵循的各项标准和准则，就是 HTTP 协议的表现，换句话说，HTTP 协议就是属于 REST 架构的设计模式。比如，无状态，请求-响应。为什么现在大多数项目采用前后端分离的模式进行开发，统一返回方便前端进行开发和封装，以及返回时给出响应编码和信息。3. MyBatisJDBCJDBC (Java数据库连接) 是一种用于执行SQL语句的Java API，可以为多种关系数据库提供统一访问。它由一组用Java语言编写的类和接口组成。JDBC提供了一种基准，据此可以构建更高级的工具和接口。其优点是运行的时候快捷高效，但是在编译器代码量大，繁琐的异常处理，不支持数据库跨平台。基础MyBatis是一个优秀的持久层框架，它对jdbc的操作数据库的过程进行封装，使开发者只需要关注 SQL 本身，而不需要花费精力去处理例如注册驱动、创建connection、创建statement、手动设置参数、结果集检索等jdbc繁杂的过程代码。Mybatis通过xml或注解的方式将要执行的各种statement配置起来，并通过java对象和statement中的sql进行映射生成最终执行的sql语句，最后由mybatis框架执行sql并将结果映射成java对象并返回。配置 mybatis配置 SqlMapConfig.xml，此文件作为mybatis的全局配置文件，配置了mybatis的运行环境等信息。 mapper.xml文件即sql映射文件，文件中配置了操作数据库的sql语句。此文件需要在SqlMapConfig.xml中加载。 通过mybatis环境等配置信息构造SqlSessionFactory即会话工厂。 由会话工厂创建sqlSession即会话，操作数据库需要通过sqlSession进行。 mybatis底层自定义了Executor执行器接口操作数据库，Executor接口有两个实现，一个是基本执行器、一个是缓存执行器。 Mapped Statement也是mybatis一个底层封装对象，它包装了mybatis配置信息及sql映射信息等。mapper.xml文件中一个sql对应一个Mapped Statement对象，sql的id即是Mapped statement的id。 Mapped Statement对sql执行输入参数进行定义，包括HashMap、基本类型、pojo，Executor通过Mapped Statement在执行sql前将输入的java对象映射至sql中，输入参数映射就是jdbc编程中对preparedStatement设置参数。 Mapped Statement对sql执行输出结果进行定义，包括HashMap、基本类型、pojo，Executor通过Mapped Statement在执行sql后将输出结果映射至java对象中，输出结果映射过程相当于jdbc编程中对结果的解析处理过程。" }, { "title": "Reactive Programming", "url": "/posts/Reactive-Programming/", "categories": "笔记", "tags": "Reactive Programming", "date": "2022-05-14 23:30:00 +0000", "snippet": "Reactive Streams基本概念Java9开始，通过Reactive Streams和Flow API实现响应式编程。Stream-Oriented Pub/Sub patterns使用Pub-Sub模型，publisher负责发送消息，subscriber负责通知publisher自己可以接受多少消息并接受。包含两个部分Iterator: which applies a “pull...", "content": "Reactive Streams基本概念Java9开始，通过Reactive Streams和Flow API实现响应式编程。Stream-Oriented Pub/Sub patterns使用Pub-Sub模型，publisher负责发送消息，subscriber负责通知publisher自己可以接受多少消息并接受。包含两个部分Iterator: which applies a “pull model” where app subscriber(s) pull items from a publisher source.Observer: which applies a “push model” that reacts when a publisher source pushes an item to subscriber sink(s).Flow APIFlow API包含三个组成部分：Publisher相当于信息的发布源，Subscriber负责消化Publisher发布的事件；Publisher通过钩子函数onNext，onError, onComplete向Subscriber发送信息；Subscription用来控制Pub和Sub之间的数据流。由于Reactive Streams只有当.subscribe()方法被调用时才会执行，所以是lazy的。当Subscriber发送请求给Publisher后，Publisher会调用onSubscribe钩子函数，可以确保Sub可以接受到信息；Publisher调用onNext(data)钩子函数来回复请求；如果事件结束，Pub会调用onComplete钩子函数。" }, { "title": "Serverless architecture", "url": "/posts/Serverless-architecture/", "categories": "笔记", "tags": "CS5289", "date": "2022-03-25 06:00:00 +0000", "snippet": "How the client app connects to api, lambda and DBBasicLambda software is composed of a number of functions. Creating a serverless app with AWS Lambda is built upon event-based development, so a use...", "content": "How the client app connects to api, lambda and DBBasicLambda software is composed of a number of functions. Creating a serverless app with AWS Lambda is built upon event-based development, so a user’s action serves as a trigger that kickstarts backend and frontend response.For traditional three-tier client-oriented system, the client make a request to server, then the server side deals with these requests, send some queries to database, and then send response to client. The basic example is online store like following.With this architecture the client can be relatively unintelligent, with much of the logic in the system is implemented by the server application. Such as authentication, page navigation, searching, transactions and exception handling.Serverless architectureThis is a massively simplified view, but even here we see a number of significant changes: We’ve deleted the authentication logic in the original application and have replaced it with a third-party BaaS service (e.g., Auth0.) Using another example of BaaS, we’ve allowed the client direct access to a subset of our database (for product listings), which itself is fully hosted by a third party (e.g., Google Firebase.) We likely have a different security profile for the client accessing the database in this way than for server resources that access the database. These previous two points imply a very important third: some logic that was in the Pet Store server is now within the client—e.g., keeping track of a user session, understanding the UX structure of the application, reading from a database and translating that into a usable view, etc. The client is well on its way to becoming a Single Page Application. We may want to keep some UX-related functionality in the server, if, for example, it’s compute intensive or requires access to significant amounts of data. In our pet store, an example is “search.” Instead of having an always-running server, as existed in the original architecture, we can instead implement a FaaS function that responds to HTTP requests via an API gateway (described later). Both the client and the server “search” function read from the same database for product data. If we choose to use AWS Lambda as our FaaS platform we can port the search code from the original Pet Store server to the new Pet Store Search function without a complete rewrite, since Lambda supports Java and Javascript—our original implementation languages. Finally, we may replace our “purchase” functionality with another separate FaaS function, choosing to keep it on the server side for security reasons, rather than reimplement it in the client. It too is fronted by an API gateway. Breaking up different logical requirements into separately deployed components is a very common approach when using FaaS.API gatewaysOne aspect of Serverless that we brushed upon earlier is an “API gateway.”An API gateway is an HTTP server where routes and endpoints are defined in configuration, and each route is associated with a resource to handle that route. In a Serverless architecture such handlers are often FaaS functions.API gateway only exposes single port to client. When an API gateway receives a request, it finds the routing configuration matching the request, and, in the case of a FaaS-backed route, will call the relevant FaaS function with a representation of the original request. The FaaS function will execute its logic and return a result to the API gateway, which in turn will transform this result into an HTTP response that it passes back to the original caller.Also for the example of pet store, client sends a GET request for searching cats, and API gateway receives this request, find port in router and connect to cats function. Finally cats function will return an HTTP response and sends it back to client.RESTfulAPIBasicRESTful API is an interface that two computer systems use to exchange information securely over the internet.Most business applications have to communicate with other internal and third-party applications to perform various tasks.RESTful APIs support this information exchange because they follow secure, reliable, and efficient software communication standards.Representational State Transfer (REST) is a software architecture that imposes conditions on how an API should work.BenefitRESTful APIs include the following benefits:ScalabilitySystems that implement REST APIs can scale efficiently because REST optimizes client-server interactions. Statelessness removes server load because the server does not have to retain past client request information. Well-managed caching partially or completely eliminates some client-server interactions. All these features support scalability without causing communication bottlenecks that reduce performance.FlexibilityRESTful web services support total client-server separation. They simplify and decouple various server components so that each part can evolve independently. Platform or technology changes at the server application do not affect the client application. The ability to layer application functions increases flexibility even further. For example, developers can make changes to the database layer without rewriting the application logic.IndependenceREST APIs are independent of the technology used. You can write both client and server applications in various programming languages without affecting the API design. You can also change the underlying technology on either side without affecting the communication.LambdaBut In AWS lambda, their architecture are following. AWS Lambda is a compute service that lets you run code without provisioning or managing servers.Example serverless application architecture using API GatewayA Lambda authorizer is an AWS Lambda function which API Gateway calls for an authorization check when a client makes a request to an API method.In amazon API gateway at AWS, they support WebSockets.A WebSocket API is composed of one or more routes. A route selection expression is there to determine which route a particular inbound request should use, which will be provided in the inbound request. The expression is evaluated against an inbound request to produce a value that corresponds to one of your route’s routeKey values. For example, if our JSON messages contain a property call action, and you want to perform different actions based on this property, your route selection expression might be ${request.body.action}.For example: if your JSON message looks like {“action” : “onMessage” , “message” : “Hello everyone”}, then the onMessage route will be chosen for this request.Lambda handles: Load balancing Auto scaling Handling failures Security isolation Operating system management Managing utilizationIt runs all the logic that behind your website and interfaces with databases, other backend services, or anything else your site needs." }, { "title": "JVM", "url": "/posts/JVM/", "categories": "笔记", "tags": "JVM", "date": "2022-03-22 06:00:00 +0000", "snippet": "JVM类加载1. 类的生命周期类加载的过程包括了加载，验证，准备，解析，初始化五个阶段。在这五个阶段中，加载，验证，准备和初始化这四个阶段发生的顺序是确定的，而解析阶段不一定。加载类的加载指查找并加载类的二进制数据。加载是类加载过程的第一个阶段，在加载阶段，虚拟机需要完成以下三件事： 通过一个类的全限定名来获取其定义的二进制字节流； 将这个字节流所代表的静态存储结构转化为方法区的运行时数...", "content": "JVM类加载1. 类的生命周期类加载的过程包括了加载，验证，准备，解析，初始化五个阶段。在这五个阶段中，加载，验证，准备和初始化这四个阶段发生的顺序是确定的，而解析阶段不一定。加载类的加载指查找并加载类的二进制数据。加载是类加载过程的第一个阶段，在加载阶段，虚拟机需要完成以下三件事： 通过一个类的全限定名来获取其定义的二进制字节流； 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构； 在Java堆中生成一个代表这个类的java.lang.Class对象，作为对方法区中这些数据的访问入口。相对于启发阶段而言，类的加载阶段是可控性最强的阶段，因为开发人员可以使用系统提供的类加载器，也可以使用自定义的类加载器来完成加载。加载完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区中，而且在Java堆中也创建一个java.lang.Class对象，这样可以通过该对象访问方法区中的数据。加载class文件有以下几种方式 从本地系统中直接加载； 通过网络下载class文件； 从zip，jar等归档文件中加载； 从专有数据库中加载； 将java源文件动态编译为class文件。连接验证：确保被加载类的正确性验证是连接阶段的第一步，这一阶段的目的是确保Class文件的字节流中所包含的信息符合当前虚拟机的要求。有以下四个检验动作 文件格式验证：验证字节流是否符合class文件格式的规范； 元数据验证：对字节码描述的信息进行语义分析； 字节码验证：确认程序语义是合法的，符合逻辑的； 符号引用验证：确保解析动作正确执行。验证阶段很重要，但不是必须的，它对程序运行期没有影响。准备：为类的静态变量分配内存，并将其初始化为默认值准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中分配。类变量是指static，不包括实例变量，实例变量会在对象实例化时随着对象一起分配到java堆中。 对于基本数据类型，类变量static和全局变量，如果不显式赋值，系统会默认赋值为0； static final同时修饰的变量以及局部static变量必须显式赋值，否则编译不通过； 如果在数组初始化时没有对数组中的各元素赋值，那么其中的元素将根据对应的数据类型而被赋予默认的零值。 解析：把类中的符号引用转换为直接引用解析是虚拟机将常量池内的符号引用替换为直接引用的过程。直接引用就是直接指向目标的指针，相对偏移量或一个间接定位到目标的句柄。初始化初始化，为类的静态变量赋予正确的初始值，JVM负责对类进行初始化，主要对类变量进行初始化。在Java中对类变量进行初始设定有两种方式：声明类变量的直到初始值和使用静态代码块为类变量指定初始值。类初始化时机： 创建类的实例，也就是new； 访问某个类或接口的静态变量，或者对该静态变量赋值； 调用类的静态方法； 反射； 初始化某个类的子类，其父类也会被初始化； Java虚拟机启动时被标明为启动类的类。使用类访问方法区内的数据结构的接口，对象是Heap区的数据。卸载Java虚拟机将结束生命周期的几种情况： 执行了System.exit()方法； 程序正常结束； 程序在执行过程中遇到了一场或错误而终止； 由于操作系统出现错误而导致Java迅即进程终止。2. 类的加载内存模型3. 类加载机制类的加载有三种方式： 命令行启动应用时候由JVM初始化加载。 通过Class.forName()方法动态加载； 通过ClassLoader.loadClass()方法动态加载。后两种加载方式的区别如下： Class.forName()：将类的.class文件加载到jvm中，还会对类进行解释，执行类中的static块； ClassLoader.loadClass()：只加载类的.class文件，不做其他事；类加载器的层次如下：JVM类加载机制 全盘负责：当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入，除非显示使用另一个类加载器来载入； 父类委托：先让父类加载器试图加载该类，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类； 缓存机制：缓存机制将会保证所有加载过的Class都会被缓存。当程序中需要使用某个Class时，类加载器会先从缓存中寻找Class，只有缓存区不在才会从系统中读取。这就是为什么修改了Class后必须重启JVM才会生效； 双亲委派机制：如果一个类加载器收到了类加载的请求，他首先不会自己尝试加载这个类，而是把请求委托给父加载器去完成，依次向上。因此所有的类加载请求都应该被传递到顶层的启动类加载器中。只有当父加载器在它的搜索范围中没有找到所需的类时，即无法完成该加载，子加载器才会尝试自己去加载该类。双亲委派优势 系统类防止内存中出现多份同样的字节码 保证Java程序安全稳定运行JVM运行时数据区JVM内存大致分为线程私有区域和线程共享区域，其主要由5个部分组成，统称为运行时数据区:虚拟机栈，本地方法栈，程序计数器是线程私有的，而方法区和堆区市共享的。栈帧的生命周期是和线程关联的。方法区和堆区主要存放对象，数组等不具有确定性的数据。1. 程序计数器程序计数器是当前线程正在执行的那条字节码指令的地址。如果当前线程正在执行的是一个本地方法，那么此时程序计数器为Undefined。在多线程情况下，其可以记录当前线程执行的位置，是唯一一个不会出现内存越界的区域。2. 虚拟机栈定义Java虚拟机栈是描述Java方法运行过程的内存模型。Java虚拟机会为每个即将运行的Java方法创建一块叫做栈帧的区域，用于存放该方法运行过程中的一些信息，如局部变量表，操作数栈，动态链接，方法出口信息等。当方法运行过程中需要创建局部变量的时候，就将局部变量的值存入栈帧中的局部变量表中。局部变量表定义为一个数字数组主要用于存储方法参数，定义在方法体内部的局部变量，数据类型包含表八大原始类型，对象引用，以及返回地址。局部变量表容量大小是在编译期确定下来的。在栈帧中，与性能调优最密切。操作数栈 栈顶缓存技术：由于操作数是存储在内存中，频繁的进行内存读写操作影响执行速度，将栈顶元素全部缓存到物理 CPU 的寄存器中，以此降低对内存的读写次数，提升执行引擎的执行效率。 每一个操作数栈会拥有一个明确的栈深度，用于存储数值，最大深度在编译期就定义好。32bit 类型占用一个栈单位深度，64bit 类型占用两个栈单位深度操作数栈。 并非采用访问索引方式进行数据访问，而是只能通过标准的入栈、出栈操作完成一次数据访问。方法的调用 静态链接：当一个字节码文件被装载进 JVM 内部时，如果被调用的目标方法在编译期可知，且运行时期间保持不变，这种情况下降调用方的符号引用转为直接引用的过程称为静态链接。 动态链接：如果被调用的方法无法在编译期被确定下来，只能在运行期将调用的方法的符号引用转为直接引用，这种引用转换过程具备动态性，因此被称为动态链接。3. 本地方法栈本地方法栈是为 JVM 运行 Native 方法准备的空间，用于管理本地方法的调用，是线程私有的。一个本地方法就是一个Java调用非Java代码的接口，这些接口包括与Java环境外交互或者与操作系统交互。4. 堆区定义对是用来存放对象的内存空间，几乎所有的对象都存储在堆中。特点 线程共享，整个 Java 虚拟机只有一个堆，所有的线程都访问同一个堆。而程序计数器、Java 虚拟机栈、本地方法栈都是一个线程对应一个。 在虚拟机启动时创建。 是垃圾回收的主要场所。 堆可分为新生代、老年代。 逻辑上连续，物理内存空间可以不连续。 主流情况下堆的大小可以扩展。内存划分为了进行高效的垃圾回收，虚拟机把堆内存逻辑上划分成三块区域： 新生代：新对象和没达到一定年龄的对象都在新生代； 老年代：被长时间使用的对象，老年代的内存空间比年轻代要大； 元空间：JDK1.8之前叫永久代：像一些方法中的操作临时对象等。JDK1.8之前是占用JVM内存，JDK1.8之后直接使用物理内存。年轻代年轻代是所有新对象创建的地方。当填充年轻代时，执行垃圾收集。这种垃圾收集称为Minor GC。年轻代被分为三个部分：Eden Memory，和两个Survivor Memory，默认比例是8：1：1.老年代旧的一代内存包含那些经过许多轮GC后仍然存活的对象。通常，垃圾收集是在老年代内存满时执行的。老年代垃圾收集成为Major GC。对象在堆中的生命周期 在JVM的内存模型中，对被划分为新生代和老年代，新生代有Eden区和Survivor区，Survivor又由From Survivor和To Survivor组成。 当创建一个对象的时候，对象会被优先分配到新生代的Eden区，此时JVM会给对象定义一个对象年轻计数器。 当Eden空间不足的时候，JVM将执行新生代垃圾回收（Minor GC） JVM会把存活的对象转移到Survivor中，并且对象年龄+1 对象在Survivor中同样也会经历Minor GC，每经历一次Minor GC，对象年龄都会+1 如果分配的对象过多，对象会被直接分配到老年代。5. 方法区定义Java虚拟机定义方法区是堆的一个逻辑部分，其存放以下信息： 已经被虚拟机加载的类信息 常量 静态变量 即时编译器编译后的代码特点方法区有以下特点： 线程共享。 方法区是堆的一个逻辑部分，因此和堆一样，都是线程共享的。整个虚拟机中只有一个方法区。 永久代。方法区中的信息一般需要长期存在，而他又是堆的逻辑分区，因此用堆的划分方法，把方法区称为永久代。 内存回收效率低。方法区中的信息一般需要长期存在，回收一遍之后可能只有少量信息无效。 允许固定大小，也允许动态扩展。运行时常量池为什么需要常量池？运行时常量池是方法区的一部分。一个有效的Class文件中除了包含类的版本信息，字段，方法以及接口的描述信息外。还有一项是常量池表，包含各种字面量和对类型，域和方法的符号引用。Java中的Class需要数据支持，通常这种数据会很大以至于不能直接存储到Class文件中，不过可以存到常量池，包含了指向常量池的引用。在动态链接的时候用到的就是运行时常量池。运行时常量池 在加载类和结构到虚拟机后，就会创建对应的运行时常量池； 常量池表是Class文件的一部分，用于存储编译期生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法去的运行时常量池中 JVM为每个已加载的类型都维护一个常量池，池中的数据项和数组项一样通过索引访问； 运行时常量池中包含各种不同的常量，包括编译器就已经明确的数值字面量，也包括运行期解析后才能够获得的方法或字段引用。垃圾回收1. 哪些内存需要回收JVM的内存结构包括五大区域：程序计数器、虚拟机栈、本地方法栈、堆区、方法区。其中程序计数器、虚拟机栈、本地方法栈3个区域随线程而生、随线程而灭，因此这几个区域的内存分配和回收都具备确定性。而Java堆区和方法区的内存是动态的，需要进行垃圾回收。2. 如何判断一个对象是垃圾程序在运行过程中会创建对象，但当方法执行完成或这个对象使用完毕后，它便被定义成了垃圾，这时就需要用垃圾收集器将内存区域清理出来。判定一个对象的存活与否，常见的算法有两种：引用计数法 和可达性分析算法。(1) 引用计数法：堆中每个对象实例都有一个引用计数。当一个对象被创建时，就将该对象实例分配给一个变量，该变量计数设置为1。当任何其它变量被赋值为这个对象的引用时，计数加1，但当一个对象实例的某个引用超过了生命周期或者被设置为一个新值时，对象实例的引用计数器减1，高效但是无法处理循环引用，现在基本已经抛弃。(2) 可达性分析算法：根搜索算法的中心思想，就是从某一些指定的根对象（GC Roots）出发，一步步遍历找到和这个根对象具有引用关系的对象，然后再从这些对象开始继续寻找，从而形成一个个的引用链（其实就和图论的思想一致），然后不在这些引用链上面的对象便被标识为引用不可达对象。在Java中，可作为根对象包括下面几种： 虚拟机栈中引用的对象（栈帧中的本地变量表）； 方法区中类静态属性引用的对象； 方法区中常量引用的对象； 本地方法栈中JNI（Native方法）引用的对象； 活跃线程。3. 引用类型强引用创建一个对象并把这个对象赋给一个引用变量，普通 new 出来对象的变量引用都是强引用，有引用变量指向时永远不会被垃圾回收。Object obj = new Object();软引用如果一个对象具有软引用，内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。使用 SoftReference 类来创建软引用。Object obj = new Object();SoftReference&lt;Object&gt; sf = new SoftReference&lt;Object&gt;(obj);obj = null; // 使对象只被软引用关联弱引用非必需对象，当 JVM 进行垃圾回收时，无论内存是否充足，都会回收被弱引用关联的对象。使用 WeakReference 类来实现弱引用。Object obj = new Object();WeakReference&lt;Object&gt; wf = new WeakReference&lt;Object&gt;(obj);obj = null;虚引用虚引用并不会决定对象的生命周期，如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。使用 PhantomReference 来实现虚引用。Object obj = new Object();PhantomReference&lt;Object&gt; pf = new PhantomReference&lt;Object&gt;(obj);obj = null;4. 方法区回收判断方法区主要回收的内容有：废弃常量和无用的类。 对于废弃常量也可通过引用的可达性来判断，但是对于无用的类则需要同时满足下面3个条件： 该类所有的实例都已经被回收，也就是Java堆中不存在该类的任何实例； 加载该类的ClassLoader已经被回收； 该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。5. 常用垃圾回收算法(1) 标记-清除法：标记的过程其实就是上面的可达性算法(根搜索)所标记的不可达对象，当所有的待回收的“垃圾对象”标记完成之后，便进行第二个步骤：统一清除。优点是性能比较高，缺点是容易产生不连续的内存块。(2) 标记-整理法：该算法并不会直接清除掉可回收对象 ，而是让所有的对象都向一端移动，然后将端边界以外的内存全部清理掉。(3) 复制算法：复制算法将内存区域均分为了两块（记为S0和S1），而每次在创建对象的时候，只使用其中的一块区域（例如S0），当S0使用完之后，便将S0上面存活的对象全部复制到S1上面去，然后将S0全部清理掉。缺点是费内存。6. 分代收集它的核心思想是根据对象存活的生命周期将内存划分为若干个不同的区域。一般情况下将堆区划分为老年代（Tenured Generation） 和 新生代（Young Generation），在堆区之外还有一个代就是永久代（Permanet Generation）(JDK1.8后移除)。老年代的特点是每次垃圾收集时只有少量对象需要被回收，而新生代的特点是每次垃圾回收时都有大量的对象需要被回收，那么就可以根据不同代的特点采取最适合的收集算法。7. 垃圾收集器分类在Java中，垃圾回收器按照执行机制分为四种类型： 串行垃圾回收器（Serial Garbage Collector）； 并行垃圾回收器（Parallel Garbage Collector）； 并发标记扫描垃圾回收器（CMS Garbage Collector）； G1垃圾回收器（G1 Garbage Collector）。收集器HotSpot VM 提供了 7 种垃圾收集器，分别为：Serial串行收集器，是单线程的收集器，只会使用一个线程进行垃圾收集工作。其优点是简单高效，没有线程交互的开销，因此拥有最高的单线程收集效率。它是Client模式下默认的新生代收集器，因为在用户的桌面场景下，分配给虚拟机管理的内存一般来说不会很大。PraNew是串行收集器的多线程版本，是Server模式下虚拟机首选的新生代收集器。除了性能原因外，主要是因为除了Serial收集器，只有它能与CMS收集器配合工作。Parallel Scavenge是多线程收集器，目标是达到一个可控的吞吐量，它被称为吞吐量优先收集器。这里的吞吐量指CPU用于运行用户代码的时间占总时间的比值。Serial Old是Serial收集器的老年代版本。Parallel Old是Parallel Scavenge的老年代版本。CMSConcurrent Mark Sweep，Mark Sweep指的是标记-清除算法。分为以下四个流程: 初始标记：仅仅只是标记一下GC Roots能直接关联到的对象，速度快，需要停顿； 并发标记：进行GC Roots Tracing的过程，它在整个回收过程中耗时最长，不需要停顿； 重新标记：为了修正并发标记期间因用户程序继续运作而导致标记产生变动，需要停顿。 并发清除：不需要停顿。其具有以下缺点： 吞吐量低，低停顿时间是以牺牲吞吐量为代价的。 无法处理浮动垃圾，浮动垃圾是指并发清除阶段由于用户线程继续运行而产生的垃圾，只能到下一次GC进行回收。 标记 - 清除算法导致的空间碎片，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象，不得不提前触发一次 Full GC。G1Garbage First，它是一款面向服务端应用的垃圾收集器，在多CPU和大内存场景下有很好的性能。堆被分为新生代和老年代，其他收集器进行收集的范围都是整个新生代或者老年代，而G1可以直接对新生代和老年代一起回收。G1把堆划分成多个大小相等的独立区域，新生代和老年代不再物理隔离。通过引入Region的概念，从而将原来的一整块内存空间划分成多个小空间，使得每个小空间可以单独进行垃圾回收。这种划分方法带来很大的灵活性，是的可以测的停顿时间模型成为可能。通过记录每个Region垃圾回收的时间以及回收所获得的空间，并维护一个优先列表，优先回收价值最大的Region。其具备以下特点： 空间整合：张体看来是基于标记-整理算法实现的收集器，从局部上来看是基于复制的算法实现的，这意味着收集过程中不会产生碎片。 可预测的停顿：能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在GC上的时间不得超过N毫秒。分代收集 新生代可配置的回收器：Serial、ParNew、Parallel Scavenge 老年代配置的回收器：CMS、Serial Old、Parallel Old8. 内存泄露定义对象已经没有被应用程序使用，但是垃圾回收器没法移除他们，因为还在被引用。这些对象具有以下特点：首先，这些对象是可达的；其次，这些对象是无用的。如果对象满足这两个条件，这些对象就可以判定为Java中的内存泄漏，这些对象不会被GC所回收，然而它却占用内存。原因根本原因是长生命周期的对象持有短生命周期对象的引用很可能发生内存泄漏。当短生命周期的对象已经不再需要，但是长生命周期持有他的引用而导致不能被回收，就发生了内存泄漏。具体有以下几类： 静态集合类引起内存泄漏 监听器 各种连接 内部类和外部模块的引用 单例模式避免 使用最新稳定版本的Java 尽量减少使用静态变量，使用完之后及时赋值 null，移除引用 明确对象的有效作用域，尽量缩小对象的作用域。局部变量回收会很快。 减少长生命周期对象持有短生命周期的引用 各种连接应该及时关闭（数据库连接，网络，IO等） 使用内存泄漏检测工具如MAT,Visual VM，jprofile 等 避免在代码中使用System.gc() 避免使用内部类JVM调优参数1. JVM参数 -Xms：堆的最小值； -Xmx：对的最大值，-Xms和-Xmx的单位默认字节都是以k，m做单位的； -Xmn：新生代大小； -Xss：每个线程池堆栈大小； -XX:NewRatio：设置新生代与老年代的比值。-XX:NewRatio=4 表示新生代与老年代所占比例为1:4 ，新生代占比整个堆的五分之一。如果设置了-Xmn的情况下，该参数是不需要在设置的。 -XX:PermSize：设置持久代初始值，默认是物理内存的1/64； -XX:MaxPermSize：设置持久代最大值，默认是物理内存1/4； -XX:MaxTenuringThreshold：新生代对象存活次数，默认15 (若对象在eden区，经历一次MinorGC后还活着，则被移动到Survior区，年龄加1。以后，对象每次经历MinorGC，年龄都加1。达到阀值，则移入老年代)； -XX:SurvivorRatio：Eden区与Subrvivor区大小的比值，如果设置为8，两个Subrvivor区与一个Eden区的比值为2:8，一个Survivor区占整个新生代的十分之一；经验： Xmn用于设置新生代大小，国小会增加Minor GC的频率，过大会减小老年代的大小，一般设为整个对空间的1/4或1/3. XX:SurvivorRatio用于设置新生代中survivor空间和eden空间的大小比例，XX:TargetSurvivorRatio表示当经历Minor GC后，survivor空间占有量百分比超过他的时候，就会压缩进入老年代。默认值为50%； 为了性能考虑，一开始尽量将新生代对象留在新生代，避免新生代的大对象直接进入老年代。因为新生代的对象大部分都是短期的，这就造成了老年代内存的浪费，并且回收代价也高； 当Xms=Xmx，可以使得堆相对稳定，避免不停震荡； 一般来说，MaxPermSize设为64MB可以满足绝大多数的应用了。2. 垃圾回收垃圾回收算法 引用计数法: 会有循环引用的问题，古老的方法； 标记清除。根可达判断，最大的问题是空间碎片(清除垃圾之后剩下不连续的内存空间)； 复制算法。对于短命对象来说有用，否则需要复制大量的对象，效率低。如Java的新生代堆空间中就是使用了它(survivor空间的from和to区)； 标记整理。对于老年对象来说有用，无需复制，不会产生内存碎片。GC考虑的指标 吞吐量：应用耗时和实际耗时的比值； 停顿时间：垃圾回收的时候，由于Stop the World，应用的所有程序的所有线程都会挂起，造成应用的停顿。回收器的JVM参数 -XX:+UseSerialGC：串行垃圾回收，现在基本很少使用； -XX:+UseParNewGC：新生代使用并行，老年代使用串行； -XX:+UseConcMarkSweepGC：新生代使用并行，老年代使用CMS； -XX:ParallelGCThreads：指定并行的垃圾回收器的线程数量，最好等于CPU数量； -XX:+DisableExplicitGC：禁用System.gc()，因为它会触发Full GC，这是很浪费性能的，JVM会在需要GC的时候自己触发GC； -XX:CMSFullGCsBeforeCompaction：在多少次GC后进行内存压缩，这个是因为并行收集器不对内存空间进行压缩的，所以运行一段时间后会产生很多碎片，使得运行效率降低； -XX:+CMSParallelRemarkEnabled：降低标记停顿； -XX:+UseCMSCompactAtFullCollection：在每一次Full GC时对老年代区域碎片整理，因为CMS是不会移动内存的，因此会非常容易出现碎片导致内存不够用的； -XX:+UseCmsInitiatingOccupancyOnly：使用手动触发或者自定义触发cms 收集，同时也会禁止hostspot 自行触发CMS GC； -XX:CMSInitiatingOccupancyFraction：使用CMS作为垃圾回收，使用70%后开始CMS收集。" }, { "title": "计算机网络", "url": "/posts/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/", "categories": "笔记", "tags": "计算机网络", "date": "2022-03-16 02:34:00 +0000", "snippet": "计算机网络TCP1. TCP基础TCP全程传输控制协议，是面向连接的，可靠的，基于字节流的传输层通信协议。 面向连接：连接是一对一的，而不是和UDP一样可以一堆多； 可靠的：无论网络中出现了怎样的链路变化，TCP都能保证一个报文一定能到达接收端； 字节流：用户消息通过TCP传输时，消息可能会被操作系统分组成多个的TCP报文，如果接收方不知道消息的边界，是无法读取出有效信息的。TCP消息...", "content": "计算机网络TCP1. TCP基础TCP全程传输控制协议，是面向连接的，可靠的，基于字节流的传输层通信协议。 面向连接：连接是一对一的，而不是和UDP一样可以一堆多； 可靠的：无论网络中出现了怎样的链路变化，TCP都能保证一个报文一定能到达接收端； 字节流：用户消息通过TCP传输时，消息可能会被操作系统分组成多个的TCP报文，如果接收方不知道消息的边界，是无法读取出有效信息的。TCP消息流有顺序，只有前一个TCP报文收到才能接受下一个报文。TCP头部TCP头部格式分为以下几部分： 序列号：在建立连接的时候由计算机生成的随机数作为初始值，通过SYN包传给接收端主机，每发送一次，就累加一次该数据字节数的大小，用来解决网络包的乱序问题。 确认应答号：指下一次期望收到的数据的序列号，发送端收到这个确认应答号之后，可以认为在这个之前的数据已被正常接受，用来解决丢包问题。 控制位： ACK：该位为1时，确认应答的字段变为有效，TCP 规定除了最初建立连接时的 SYN 包之外该位必须设置为 1 。 RST：该位为1时，表示 TCP 连接中出现异常必须强制断开连接。 SYN：该位为1时，表示希望建立连接，并在其序列号的字段进行序列号初始值的设定。 FIN：该位为1时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 FIN 位为 1 的 TCP 段。 TCP连接用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括Socket，序列号和窗口大小称为连接。TCP的四元组可以确定唯一一个连接源地址和目标地址字段（32位）是在IP头部，作用是通过IP协议发送报文到对方主机。源端口和目的端口字段（16位）是在TCP头部，作用是告诉TCP协议该把报文发送到哪个进程中。TCP/UDPUDP全称用户数据报协议，他不提供复杂的控制机制，利用IP提供面向无连接的通信服务。UDP协议头部只有8个字节，分别是：源端口和目标端口号，包长度，校验和。他们的区别如下： 连接 TCP是面向连接的传输协议，在传输数据前要先建立连接；UDP不需要建立连接，即刻传输数据。 服务对象 TCP是一对一的两点服务，仅支持一对一连接；UDP支持一对一，一对多，多对多的交互通信。 可靠性 TCP是可靠的，数据可以无差错，不丢失，不重复，按顺序到达；UDP 是尽最大努力交付，不保证可靠交付数据。 拥塞控制，流量控制 TCP拥有流量控制，拥塞控制的功能，保证传输数据的安全，UDP没有。 首部开销 TCP的首部较长，会有一定的开销，首部在没有使用选项的大小是20字节；UDP首部较短，只有固定的8个字节，开销较小。 传输方式 TCP是流式传输，没有边界，但是保证顺序和可靠。UDP是一个一个包发送是有边界的，但是可能丢包和乱序。 分片 TCP的大小如果大于MSS（最大报文长度）大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装TCP包。如果中途丢失了一个分片，只需要传输这个丢失的分片。 UDP的数据如果大于MTU，则会在IP层进行分片，目标主机收到后，在IP层进行组装。 TCP和UDP可以共用同一个端口。当主机收到数据包的时候，可以在IP包头的协议号字段知道该数据包是TCP还是UDP，并发送给不同的模块。因此TCP和UDP的端口相互独立。TCP特点(1) 超时重传重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 ACK 确认应答报文，就会重发该数据，也就是我们常说的超时重传。(2) 流量控制如果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。为了解决这种现象发生，TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。(3) 拥塞控制在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大….所以，TCP 不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量。于是，就有了拥塞控制，控制的目的就是避免「发送方」的数据填满整个网络。2. TCP/IP模型（四层） 应用层：软件实现层面，HTTP、FTP、Telnet、DNS、SMTP等。 传输层：TCP/UDP。TCP是传输控制协议，相比 UDP 多了很多特性，比如流量控制、超时重传、拥塞控制等，这些都是为了保证数据包能可靠地传输给对方。UDP 相对来说就很简单，简单到只负责发送数据包，传输效率高。可以在应用层实现TCP的功能。 网络层：IP/ICMP协议。数据部分+TCP/UDP头+IP头。 IP地址有两种意义： 一个是网络号，负责标识该 IP 地址是属于哪个「子网」的； 一个是主机号，负责标识同一「子网」下的不同主机； IP地址和子网掩码做AND运算得到网络号。 IP 协议的寻址作用是告诉我们去往下一个目的地该朝哪个方向走，路由则是根据「下一个目的地」选择路径。寻址更像在导航，路由更像在操作方向盘。 网络接口层：MAC头部，包含了接收方和发送方的 MAC 地址。网络接口层主要为网络层提供「链路级别」传输的服务，负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址来标识网络上的设备。Ping是由ICMP协议控制的。在浏览器输入URL之后，具体流程是什么？具体的流程如下： URL解析：浏览器首先解析输入的URL，提取出协议、主机名、端口号、路径等信息。 DNS解析：浏览器将主机名转换为对应的IP地址，通过DNS解析来完成这一步骤。 建立TCP连接：浏览器与服务器之间建立TCP连接，通过三次握手建立可靠的连接。 发送HTTP请求：浏览器构建HTTP请求报文，包括请求方法（GET、POST等）、请求头部、请求体等信息，并将其发送给服务器。 服务器处理请求：服务器接收到请求后，根据请求的路径、参数等进行处理，并生成对应的HTTP响应。 接收HTTP响应：浏览器接收到服务器返回的HTTP响应报文，包括响应状态码、响应头部、响应体等信息。 渲染页面：浏览器根据接收到的响应数据，解析HTML、CSS、JavaScript等资源，并进行页面的渲染，展示给用户。 关闭TCP连接：页面渲染完成后，浏览器与服务器之间的TCP连接会被关闭，释放网络资源。3. TCP三次握手 一开始，客户端和服务端都处于 CLOSE 状态。先是服务端主动监听某个端口，处于 LISTEN 状态 客户端会随机初始化序号（client_isn），将此序号置于 TCP 首部的「序号」字段中，同时把 SYN 标志位置为 1，表示 SYN 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 SYN-SENT 状态 服务端收到客户端的 SYN 报文后，首先服务端也随机初始化自己的序号（server_isn），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 client_isn + 1, 接着把 SYN 和 ACK 标志位置为 1。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 SYN-RCVD 状态 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 ACK 标志位置为 1 ，其次「确认应答号」字段填入 server_isn + 1 ，最后把报文发送给服务端，这次报文可以携带客户到服务端的数据，之后客户端处于 ESTABLISHED 状态。 服务端收到客户端的应答报文后，也进入 ESTABLISHED 状态第三次握手是可以携带数据的，前两次握手是不可以携带数据的。TCP 的连接状态在 Linux下可以通过 netstat -napt 命令查看。为什么是三次握手？由之前的定义，TCP的连接包含Socket，序列号和窗口大小。保持三次连接可以防止重复连接，同步序列号以及减少资源浪费。 防止重复连接 三次握手的首要原因是为了防止旧的重复连接初始化造成混乱 当客户端先发送了SYN=90的报文，但是此时客户端突然下线，而发送的SYN报文也因为网络原因造成拥塞，服务端没有及时收到。而现在客户端重新上线后，又发送了SYN=100的报文。此时如果旧的SYN=90的报文先到达服务端，假如没有第三次握手，服务端就会直接和旧的报文建立连接。而在三次握手的情况下，服务端会返回SYN=90+1给客户端，客户端收到后发现于预期SYN=100+1不符，于是向服务器发送RST主动终止旧的连接。 所以TCP使用三次握手建立连接的最主要原因就是防止「历史连接」初始化了连接。 同步序列号 TCP通信协议的双方，都要维护一个序列号，增加传输的可靠性。其有以下作用： 接收方可以去掉重复数据； 接收方可以按照序列号确认包的接受顺序； 可以标识发送出去的数据包中，哪些是已被对方接收的。 服务端接收到客户端的序列号，回应ACK并发送自己的序列号，客户端收到后再回应服务端ACK，这样可以确认两者都接收到各自的序列号。 减少资源浪费 在第一点中，如果没有第三次握手，服务端建立了旧的连接，那么会发送大量无用数据包，占用网络资源。 所以，不使用两次握手和四次握手的原因： 两次握手：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号； 四次握手：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。序列号的初始化每次建立TCP连接时，都需要初始化不同的序列号，这样的原因是，为了防止历史报文被下一个相同的四元组的连接接收，以及防止TCP报文被伪造。连接丢失第一次握手丢失会触发超时重传；第二次握手丢失客户端会认为第一次握手没有成功，也会触发超时重传。如果第三次握手丢失，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。4. TCP四次挥手 客户端打算关闭连接，此时会发送一个 TCP 首部 FIN 标志位被置为 1 的报文，也即 FIN 报文，之后客户端进入 FIN_WAIT_1 状态。 服务端收到该报文后，就向客户端发送 ACK 应答报文，接着服务端进入 CLOSE_WAIT 状态。 客户端收到服务端的 ACK 应答报文后，之后进入 FIN_WAIT_2 状态。 等待服务端处理完数据后，也向客户端发送 FIN 报文，之后服务端进入 LAST_ACK 状态。 客户端收到服务端的 FIN 报文后，回一个 ACK 应答报文，之后进入 TIME_WAIT 状态 服务端收到了 ACK 应答报文后，就进入了 CLOSE 状态，至此服务端已经完成连接的关闭。 客户端在经过 2MSL 一段时间后，自动进入 CLOSE 状态，至此客户端也完成连接的关闭。为什么挥手四次服务器在收到客户端的FIN报文时，通常还会有等待完成的数据的发送和处理，所以服务端的ACK和FIN一般是分开发送。但在某些特定情况下，四次挥手也可以变为三次挥手。挥手丢失第一次挥手丢失，客户端在调用close函数后发送FIN报文，迟迟没有等来ACK，那么会触发超时重传。重传次数由tcp_orphan_retries控制，如果超出，就不再发送，在等待一段时间后，会直接进入到close状态。第二次挥手丢失，由于ACK报文不会重传，则在一段时间后会触发客户端的超时重传。第三次挥手丢失，当服务端进程调用close后，服务端发送FIN报文，如果迟迟没有等来客户端的ACK，则会尝试重新发送，重传次数由tcp_orphan_retries控制，如果超出，就不再发送，在等待一段时间后，会直接断开连接。第四次挥手丢失，客户端发送的ACK报文服务端没有收到，那么服务端就会认为FIN报文丢失，触发重传机制。客户端在TIME_WAIT状态时，如果重新收到FIN报文，就会重置2MSL定时器，直到断开连接。TIME_WAIT为什么等待时间是2MSLMSL指最大报文生成时间，他是报文在网络上存在的最长时间，超出报文会被丢弃。TCP是基于IP协议的，而IP头中有一个TTL字段，是IP数据包可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。MSL的时间长度大于TTL消耗为0的时间，以确保报文自动消亡。一般来说，网络中可能有发送方的数据包，这些数据包被接收后处理后，又会向对方发送响应，一个来回正好是2MSL。为什么需要只有主动发起关闭连接的一方才有TIME_WAIT，主要原因如下： 防止历史连接中的数据，被后面相同的四元组接收 为防止TCP连接中的数据被错误接收，TCP中设计了TIME_WAIT状态，并且为2MSL，这样可以保证本次连接中的数据都自然消失，再出现的数据包都是下一次连接的。 保证被动关闭连接的一方能正确关闭 等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。比如服务端没收到ACK报文，出发了超时重传，那么客户端就会在关闭前有时间重新收到服务端发来的FIN重传报文，从而重置等待时间，帮助服务端正确关闭。 过多如何解决解决TIME_WAIT状态过多的首要方法就是避免服务器频繁主动断开连接，让客户端去断开，由分布在各处的客户端去承受 TIME_WAIT。解决 time_wait 状态大量存在，导致新连接创建失败的问题，一般解决办法：1.客户端：HTTP 请求的头部，connection 设置为 keep-alive，保持存活一段时间：现在的浏览器，一般都这么进行了2.服务器端：允许 time_wait 状态的 socket 被重用缩减 time_wait 时间，设置为1 MSL（即，2 mins）但是等待2MSL时间主要目的是怕最后一个ACK包对方没收到，那么对方在超时后将重发第三次握手的FIN包，主动关闭端接到重发的FIN包后可以再发一个ACK应答包。5. Socket编程针对TCP该如何进行Socket编程 服务端和客户端初始化socket，得到文件描述符； 服务端调用bind，将socket绑定在指定的IP和端口； 服务端调用listen，进行监听； 服务端调用accept，等待客户端连接； 客户端调用connect，向服务端的地址和接口发起连接请求； 服务端accept，返回用于传输socket的文件描述符； 客户端调用write写入数据，服务端调用read读取数据； 客户端断开连接时，会调用close，那么服务端 read 读取数据的时候，就会读取到了 EOF，待处理完数据后，服务端调用 close，表示连接关闭。监听的 socket 和真正用来传送数据的 socket，是两个 socket，一个叫作监听 socket，一个叫作已完成连接 socket。6. TCP重传重传机制TCP实现可靠传输的方式之一，是通过序列号与确认应答。在TCP中，当发送端的数据到达接收主机时，接收端会返回一个确认应答消息，表示已收到消息。但是数据传输过程中会有丢失，所以TCP针对丢包情况，会有重传机制。 超时重传 在发送数据时设定一个定时器，当超过指定时间后，没有收到对方的ACK确认应答报文，就会重发该数据。一般发生在：数据包丢失，确认应答丢失。 超时重传的时间是以RT0表示（Retransmission Timeout 超时重传时间），而RTT（Round-Trip Time 往返时延）是数据从发送时刻到接收到确认的时刻的差值。RTO不能过大也不能过小，超时重传时间RTO的值应该略大于报文往返RTT的值。 报文往返RTT是经常变化的，因为网络经常变化，所以超时重传RTO的值应该是一个动态变化的值。在TCP的策略下，如果超时重发的数据，再次要超时重传，会将超时时间加倍。每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。 快速重传 以数据为驱动重传。当收到三个相同的ACK报文时，就会在定时器过期之前，重传丢失的报文。但是无法判断该重传哪些TCP报文。 例如发送方发送了Seq=1，2，3，4，5，6六条数据，而Seq2由于某些原因没有收到，所以在接收方收到后面的Seq3，4，5时，还是会回传ACK=2，而发送方收到三次相同的ACK=2后，知道了 Seq2 还没有收到，就会在定时器过期之前，重传丢失的 Seq2。但是如果Seq2，3都丢失，接收方还是只会传ACK=2，发送方无法判断是重传Seq2还是Seq2及之后的报文。 SACK方法 即选择性确认，其在TCP头部选项字段里加一个SACK，他可以将已经收到的数据信息发送给发送方，这样发送方就知道哪些数据丢失，就可以只重传丢失的数据。 Duplicated SACK 又称D-SACK，其主要使用了SACK来告诉发送方有哪些数据被重复接受了。一般用于ACK报文丢失的情况。 ACK丢失 发送方超时重传后，接收方发给发送方的两个ACK都丢失了，接收方收到数据包1，2，在下次在收到发送方重传的数据包1后，发现数据重复，所以返回一个ACK和SACK=数据包1，如果发送方收到应答，则知道数据没有丢失，而是ACK丢失。 网络延时 发送方的数据包1000-1499被网络延迟，导致没收到ACK=1500的应答，后面发送方收到三个ACK=1500的确认报文，于是触发了快速重传机制，但是在重传后，接收方又收到了1000-1499的数据包。所以接收方回了一个 SACK=1000~1500，因为 ACK 已经到了 3000，所以这个 SACK 是 D-SACK，表示收到了重复的包。 7. 滑动窗口TCP每发送一个数据都要进行一次确认应答。但是当往返时间越长，通信的效率越低。为了解决这个问题，TCP引入了窗口的概念，窗口的大小就是无需等待确认应答，而可以继续发送数据的最大值。窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答前，必须在缓冲区中保留已发送过的数据，如果收到确认应答，此时数据就可以从缓存区清除。窗口的大小由TCP头中的Window字段决定。这个字段是接收方告诉发送端自己还有多少缓冲区可以接受数据。 发送方的滑动窗口 发送方的缓存窗口如下： 当发送方一次性发送所有数据后，滑动窗口的大小会变成0，表示可用窗口耗尽。在下一个ACK回应到来前，无法再发送数据。 当接收方确认5个字节的数据后，滑动窗口会往右移动5个字节。 接收方的窗口 接收方窗口大小约等于发送方窗口大小，但不一定完全相等。 8. 流量控制如果发送方发送数据不考虑接收方的能力，那么就会一直触发重传机制。为了解决这种现象的发生，TCP提供一种机制可以让发送方根据接收方发实际接受能力控制发送的数据量，这就是流量控制。操作系统与滑动窗口的关系在滑动窗口中，发送窗口和接收窗口中所存放的字节数，都是放在操作系统内存缓冲区，而内存缓冲区会被操作系统调整。当接收端的进程长时间没有读取缓冲区里的内容时，数据会占用缓冲区，而随着发送方持续发送数据，接收窗口会收缩到0，发生了窗口关闭。当服务端操作系统资源很紧张时，可能会改变其接收窗口的大小。当客户端发送一段数据包后，服务端的接收窗口发生了收缩，没有及时告知客户端，导致服务端收到的字节数大于其现在的窗口大小，则会发生数据的丢失。所以，如果发生了先减少缓存，再收缩窗口，就会出现丢包的现象。为了防止这种情况发生，TCP 规定是不允许同时减少缓存又收缩窗口的，而是采用先收缩窗口，过段时间再减少缓存，这样就可以避免了丢包情况。窗口关闭如果窗口大小为0时，就会阻止发送方给接收方传递数据，直到窗口变为非0，这就是窗口关闭。接收方向发送方通告窗口大小，是通过ACK报文通告。但是如果此时非0的ACK报文丢失，则会造成死锁现象。所以TCP每个连接都设有一个持续定时器，只要TCP连接一方收到对方的零窗口通知，就会启动持续计时器。如果持续计时器超时，就会发送窗口探测报文，而对方在收到这个报文时，会返回自己现在窗口的大小。如果窗口仍为0，则重置定时器。糊涂窗口综合症当接收方较忙时，如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，那么发送方会义无反顾的发送这几个字节，称为糊涂窗口综合症。其一般出现在发送方可以发送一个小窗口和接收方可以通告一个小窗口的情况下，解决方式如下： 对于接收方，当窗口大小小于min(MSS, 缓存空间/2)时，则会向发送方通告窗口为0，阻止了发送方发送数据。 对于发送方，可以使用Nagle算法，延时处理，满足下面任意一个条件才可以发送数据： 要等到窗口大小 &gt;= MSS 并且 数据大小 &gt;= MSS； 收到之前发送数据的 ack 回包； 发送方和接收方同时满足上面的要求后，才能避免糊涂窗口综合症。9. 拥塞控制流量控制可以控制发送接收方，但无法知道网络中发生什么。在网络出现拥堵时，如果继续发送大量数据包，可能导致数据包延时，丢失等，这时TCP就会重传数据，但是重传会导致网络负担更重，所以为了避免上述情况，当网络发生拥塞时，TCP会降低数据发送量。拥塞控制的目的是避免发送方的数据填满整个网络。为了让发送方调节所要发送数据的量，定义了拥塞窗口，拥塞窗口 (cwnd)是发送方维护的一个状态变量，他会根据网络的拥塞程度动态变化。发送端和接受端在有发送窗口和接收窗口下，加入拥塞窗口，此时发送窗口的值为swnd=min(cwnd,rwnd)。在Linux中，可以用ss -nli|grep cwnd来查看每一个TCP连接的窗口初始值。拥塞控制有以下四个算法： 慢启动 TCP刚建立连接后，首先有慢启动的过程，即一点一点提高发送数据包的数量，当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。 慢启动达到一定数量后，就会使用拥塞避免算法。 拥塞避免 当前窗口超过慢启动门限ssthresh后会进入拥塞避免算法。一般来说sstheesh的大小是65535字节。在进入拥塞避免算法后，每当收到一个 ACK 时，cwnd 增加 1/cwnd。 当网络发生拥塞，就会有丢包现象，如果触发超时重传机制，就会进入拥塞发生算法。 拥塞发生 拥塞发生有两种重传情况，超时重传和快速重传，这两种重传使用的拥塞发生算法不同。 当发生超时重传，就会使用拥塞发生算法，这时ssthreshr和cwnd的值会发生变化。 ssthresh 设为 cwnd/2， cwnd 重置为初始值。 但这种方法比较激进，容易发生网络卡顿。 当发生快速重传，此时TCP认为丢包不是很严重，只丢了一小部分，这时ssthreshr和cwnd的值变化如下： cwnd 设为cwnd/2， ssthresh 设为 cwnd， 进入快速恢复算法。 快速恢复 快速重传一般和快速恢复算法同时使用，在进入快速恢复前，cwnd和ssthresh已经被更新： 拥塞窗口 cwnd = ssthresh + 3 （ 3 的意思是确认有 3 个数据包被收到了）； 重传丢失的数据包； 如果再收到重复的 ACK，那么 cwnd 增加 1； 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态。 10. TCP半连接队列和全连接队列在TCP三次握手的过程中，Linux内核会维护两个队列，分别是： 半连接队列，也称SYN队列； 全连接队列，也称accept队列。服务端在收到客户端发起的SYN请求时，内核会把该连接储存到半连接队列，并向客户端响应SYN+ACK，接着客户端会返回ACK，服务端在收到第三次握手的ACK后，内核会把连接从半连接队列移除，然后创建新的完全连接，并将其添加到accept队列，等待进程调用accept函数时把连接取出来。不管是半连接还是全连接队列，都有最大长度限制，超过限制时，内核会直接丢弃，或返回RST包。11. TCP流式传输TCP是面向字节流的协议，而UDP是面向报文的协议，是因为操作系统对他们的发送机制不同。面向报文当用户通过UDP发送消息时，操作系统不会对消息进行拆分，在组装好UDP头部后就交给网络层处理，所以每一个UDP报文就是一个用户消息的边界，这样接收方在收到消息后，读一个UDP报文就能读取到完整的用户信息。操作系统在收到UDP报文后，会将其插入到队列里，队列里每一个元素就是一个UDP报文。字节流当用户通过TCP发送消息时，消息可能会被操作系统拆分成多个TCP报文，这时，如果接收方不知道发送消息的长度，也不知道消息边界，则无法读出用户信息。不能认为一个用户消息对应一个 TCP 报文，正因为这样，所以 TCP 是面向字节流的协议。如何解决粘包粘包问题的出现是接受端不知道用户消息的边界，从而无法有效划分出用户消息。一般有三种分包方式： 固定长度的消息 即每个用户消息都是固定长度的，比如64字节，当接收方收满64字节时，就认为其为完整有效的信息。不过此方法灵活性不高，一般很少使用。 特殊字符作为边界 可以在两个用户消息之间插一个特殊字符串，这样接收方在接受数据时，读到这个特殊字符，就认为已经读完一个完整的消息。比如HTTP协议就用回车，换行符作为HTTP消息的边界。 自定义消息结构 可以自定义一种数据结构，比如包头固定大小，包头里有一个字段来表明后面的数据体的大小。 IP1. 基础知识IP处于网络层，而网络层的作用就是实现主机与主机之间的通信，也叫点对点通信。IPv4地址由32位正整数来表示。IP地址分类IP地址分为5种类型，分别是A，B，C，D，E：对于A，B，C类地址，分为网络号和主机号。在IP地址中有两个特殊地址，分别是主机号全为0和主机号全为1的地址。 主机号全为 1 指定某个网络下的所有主机，用于广播 主机号全为 0 指定某个网络广播地址用于在同一个链路中相互连接的主机之间发送数据包。对于D，E类地址，是没有主机号的，所以不可用于主机IP，D类为多播地址，E类留用。2. Ping工作原理ICMP协议Ping是基于ICMP协议工作的，ICMP全程互联网控制报文协议，其主要功能包括确认IP包是否成功送达目标地址，报告发送过程中IP包被废弃的原因和改善网络设置等。如果IP通信中某个IP包因为某种原因未能到达目标地址，那么具体原因将由ICMP协议通知。HTTP1. HTTP解析（网页请求过程）解析URL数据协议+web服务器+目录名/文件名HTTP的请求报文和响应报文：DNS解析通过解析URL生成HTTP消息后，需要查询服务器域名对应的IP地址。在域名中，越靠右的位置表示其层级越高。其解析流程如下：协议栈应用程序（浏览器）通过调用 Socket 库，来委托协议栈工作。协议栈的上半部分别是负责收发数据的 TCP 和 UDP 协议，下面一半是用 IP 协议控制网络包收发操作，在互联网上传数据时，数据会被切分成一块块的网络包，而将网络包发送给对方的操作就是由 IP 负责的。TCPTCP会给数据包加上TCP头部，而TCP数据部分存放着HTTP头部和数据。IPTCP 模块在执行连接、收发、断开等各阶段操作时，都需要委托 IP 模块将数据封装成网络包发送给通信对象。IP会加IP头部。IP 中的 ICMP 协议和 ARP 协议。 ICMP 用于告知网络包传送过程中产生的错误以及各种控制信息。 ARP 用于根据 IP 地址查询相应的以太网 MAC 地址。IP 下面的网卡驱动程序负责控制网卡硬件，而最下面的网卡则负责完成实际的收发操作，也就是对网线中的信号执行发送和接收操作。MAC用于两点传输。MAC包头的协议类型只是用IP协议和ARP协议。发送方的MAC地址是写在网卡ROM里的。对于接收方，只需要告诉以太网对方的MAC地址，以太网就会把包发过去。发送方可以查路由表来找到目标，然后把包发给Gateway中的IP地址。如果不知道对方MAC地址，就用ARP协议广播。网卡数字信号——&gt;电信号交换机交换机的端口不核对接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中。因此，交换机的端口不具有 MAC 地址。交换机有mac地址表映射网线端口。找不到对应的mac就广播发送。广播地址： MAC 地址中的 FF:FF:FF:FF:FF:FF IP 地址中的 255.255.255.255路由器路由器的接收与自己端口MAC地址匹配的包。然后根据路由表和包的IP来判断转发目标。得到目标IP后，再用ARP协议得到其MAC地址转发。和交换机区别： 因为路由器是基于 IP 设计的，俗称三层网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址； 而交换机是基于以太网设计的，俗称二层网络设备，交换机的端口不具有 MAC 地址。2. HTTP状态码 100 Continue 继续。客户端应继续其请求 101 Switching Protocols 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到HTTP的新版本协议       200 OK 请求成功。一般用于GET与POST请求 201 Created 已创建。成功请求并创建了新的资源 202 Accepted 已接受。已经接受请求，但未处理完成 203 Non-Authoritative Information 非授权信息。请求成功。但返回的meta信息不在原始的服务器，而是一个副本 204 No Content 无内容。服务器成功处理，但未返回内容。在未更新网页的情况下，可确保浏览器继续显示当前文档 205 Reset Content 重置内容。服务器处理成功，用户终端（例如：浏览器）应重置文档视图。可通过此返回码清除浏览器的表单域 206 Partial Content 部分内容。服务器成功处理了部分GET请求       300 Multiple Choices 多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择 301 Moved Permanently 永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替 302 Found 临时移动。与301类似。但资源只是临时被移动。客户端应继续使用原有URI 303 See Other 查看其它地址。与301类似。使用GET和POST请求查看 304 Not Modified 未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源 305 Use Proxy 使用代理。所请求的资源必须通过代理访问 306 Unused 已经被废弃的HTTP状态码 307 Temporary Redirect 临时重定向。与302类似。使用GET请求重定向       400 Bad Request 客户端请求的语法错误，服务器无法理解 401 Unauthorized 请求要求用户的身份认证 402 Payment Required 保留，将来使用 403 Forbidden 服务器理解请求客户端的请求，但是拒绝执行此请求 404 Not Found 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置”您所请求的资源无法找到”的个性页面 405 Method Not Allowed 客户端请求中的方法被禁止 406 Not Acceptable 服务器无法根据客户端请求的内容特性完成请求 407 Proxy Authentication Required 请求要求代理的身份认证，与401类似，但请求者应当使用代理进行授权 408 Request Time-out 服务器等待客户端发送的请求时间过长，超时 409 Conflict 服务器完成客户端的 PUT 请求时可能返回此代码，服务器处理请求时发生了冲突 410 Gone 客户端请求的资源已经不存在。410不同于404，如果资源以前有现在被永久删除了可使用410代码，网站设计人员可通过301代码指定资源的新位置 411 Length Required 服务器无法处理客户端发送的不带Content-Length的请求信息 412 Precondition Failed 客户端请求信息的先决条件错误 413 Request Entity Too Large 由于请求的实体过大，服务器无法处理，因此拒绝请求。为防止客户端的连续请求，服务器可能会关闭连接。如果只是服务器暂时无法处理，则会包含一个Retry-After的响应信息 414 Request-URI Too Large 请求的URI过长（URI通常为网址），服务器无法处理 415 Unsupported Media Type 服务器无法处理请求附带的媒体格式 416 Requested range not satisfiable 客户端请求的范围无效 417 Expectation Failed 服务器无法满足Expect的请求头信息       500 Internal Server Error 服务器内部错误，无法完成请求 501 Not Implemented 服务器不支持请求的功能，无法完成请求 502 Bad Gateway 作为网关或者代理工作的服务器尝试执行请求时，从远程服务器接收到了一个无效的响应 503 Service Unavailable 由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的Retry-After头信息中 504 Gateway Time-out 充当网关或代理的服务器，未及时从远端服务器获取请求 505 HTTP Version not supported 服务器不支持请求的HTTP协议的版本，无法完成处理 3. HTTP字段Host字段：客户端发送请求时，用来指定服务器的域名；Content-Length字段：服务器在返回数据时会有此字段，用来表示本次回应的数据长度；HTTP是基于TCP传输协议进行通信的，TCP协议会存在粘包的问题，HTTP协议通过设置回车符，换行符作为HTTP header的边界，通过Content-Length作为HTTP body的边界来解决粘包的问题。Connection字段：该字段最常用于客户端要求服务端使用HTTP长连接机制，以便请求其他复用。HTTP长连接的特点是，只要一方没有明确提出断开连接，则保持TCP连接状态。HTTP/1.1版本默认都是长连接，但为了兼容老版本HTTP，需要指定Connection首部字段的值为Keep-Alive.Content-Type字段该字段用于回应服务器时，告诉客户端，本次数据是什么格式。Content-Type: text/html; Charset=utf-8上面的类型表明，发送的是网页，而且编码是UTF-8。客户端请求的时候，可以用Accept字段声明自己接受哪些数据格式。Content-Encoding字段该字段说明数据的压缩方法，表示服务器返回的数据使用了什么压缩格式。客户端在请求时，用 Accept-Encoding 字段说明自己可以接受哪些压缩方法。4. GET与POST区别GET的语义是从服务器获取指定资源；POST的语义是根据请求负荷（报文Body）对指定资源作出处理。GET的请求参数位置一般是写在URL中的，URL规定只能支持ASCII，所以GET请求只允许ASCII字符，而且浏览器会对URL的长度有限制（HTTP协议对URL的长度是没有限制的）。POST请求携带数据的位置一般是写在抱文body中，body中可以是任意格式的数据，而且浏览器一般不限制大小。对于安全和幂等，在HTTP协议中，所谓安全是指请求方法不会破坏服务器上的资源；而所谓幂等是指多次执行相同操作，结果都是相同的。所以在安全和幂等方面： GET 方法就是安全且幂等的，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。所以，可以对 GET 请求的数据做缓存，这个缓存可以做到浏览器本身上（彻底避免浏览器发请求），也可以做到代理上（如nginx），而且在浏览器中 GET 请求可以保存为书签。 POST 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创建多个资源，所以不是幂等的。所以，浏览器一般不会缓存 POST 请求，也不能把 POST 请求保存为书签。RFC 规范并没有规定 GET 请求不能带 body 的。理论上，任何请求都可以带 body 的。只是因为 RFC 规范定义的 GET 请求是获取资源，所以根据这个语义不需要用到 body。5. HTTP缓存实现方式对于一些重复性请求，我们可以把这对请求-响应的数据都缓存在本地，那么下次就直接读取本地的数据，所以避免发送HTTP请求的方法是通过缓存技术。HTTP的缓存实现方式分为强制缓存和协商缓存。 强制缓存 强制缓存是指只要浏览器判断缓存没有过期，则直接使用浏览器本地缓存，决定权在浏览器这边。其是利用下面两个HTTP响应头部字段来实现的，他们表示资源在客户段缓存的有效期： Cache-Control， 是一个相对时间； Expires，是一个绝对时间； 如果 HTTP 响应头部同时有 Cache-Control 和 Expires 字段的话，Cache-Control 的优先级高于 Expires 。 Cache-control 选项更多一些，设置更加精细，所以建议使用 Cache-Control 来实现强缓存。具体的实现流程如下： 当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小； 浏览器再次请求访问服务器中的该资源时，会先通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期，如果没有，则使用该缓存，否则重新请求服务器； 服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。 协商缓存 当请求返回304的时候，一般是服务端告诉浏览器可以使用本地缓存资源，这种通过服务端告知客户端是否可以使用缓存的方式被称为协商缓存。 上图为协商缓存的一个过程，所以协商缓存就是与服务端协商后，通过协商结果来判断是否使用本地缓存。 协商缓存可以基于两种头部实现： (1) 请求头部中的 If-Modified-Since 字段与响应头部中的 Last-Modified 字段实现，这两个字段的意思是： 服务器发回的HTTP响应头部中的 Last-Modified：标示这个响应资源的最后修改时间； 客户端请求头部中的 If-Modified-Since：当资源过期了，发现响应头中具有 Last-Modified 声明，则客户端再次发起请求的时候带上 If-Modified-Since 字段，值为其第一次请求时返回的 Last-Modified ，服务器收到请求后与被请求资源的最后修改时间进行对比，如果最后修改时间较新（大），说明资源又被改过，则返回最新资源，HTTP 200 OK；如果最后修改时间较旧（小），说明资源无新修改，响应 HTTP 304 走缓存。 (2) 请求头部中的 If-None-Match 字段与响应头部中的 ETag 字段，这两个字段的意思是： 响应头部中 Etag：唯一标识响应资源； 请求头部中的 If-None-Match：当资源过期时，浏览器发现响应头里有 Etag，则再次向服务器发起请求时，会将请求头 If-None-Match 值设置为 Etag 的值。服务器收到请求后进行比对，如果资源没有变化返回 304，如果资源变化了返回 200。 第一种是根据时间实现的，第二种方法是根据唯一标识实现的，相对来说后者可以更加准确判断文件内容是否被修改，避免由于篡改时间导致的不可靠问题。 如果第一次请求的时候服务器返回的HTTP头部同时有Last-Modified和ETag字段时，那么客户端下一次请求的时候，如果带上这两个值，则ETag的优先级更高，即服务端先会判断ETag是否变化，如果没变化再判断Last-Modified。ETag优先级更高的原因有下： 在没有修改文件的情况下最后修改时间也有可能会变，导致重复请求； 有些文件是在秒级以内修改的，If-Modified字段只能以秒为颗粒度检测，使用ETag就能保证一秒内刷新多次。 有些服务器不能精确获取文件修改时间。 协商缓存的这两个字段都需要配合强制缓存中的Cache-control字段来使用，只有在未能命中强制缓存的时候，才能发起协商缓存字段的请求。 下面是强制缓存和协商缓存的工作流程： 6. HTTP版本到目前为止，HTTP 常见到版本有 HTTP/1.1，HTTP/2.0，HTTP/3.0，不同版本的 HTTP 特性是不一样的。HTTP/1.1HTTP1.1最突出的特点是简单，灵活和易于扩展以及应用广泛和跨平台。简单：HTTP报文的格式是head+body，头部信息也是key-value的简单形式，易于理解。灵活和易于扩展：HTTP请求里的各类方法，URI/URL，状态码等都允许开发者自定义和补充；同时由于HTTP工作在应用层，则它的下层可以随意变化，比如HTTPS就是在HTTP和TCP层之间加了SSL/TLS安全协议。应用广泛和跨平台：大家都用。但是HTTP也有缺点，无状态，明文传输，不安全。无状态：好处是服务器不用记忆HTTP的状态，可以减轻服务器负担；坏处就是服务器没有记忆能力，在完成有关联性的操作会非常麻烦。对于无状态问题，解决方法之一就是Cookie。明文传输：用HTTPS解决。HTTP1.1是基于TCP/IP，并且使用了请求-应答通信模式。其性能从以下三个方面来看： 长连接 早期HTTP1.0有一个问题是，每发起一次请求都要建立一次TCP连接，并且是串行请求，增加了网络开销。在HTTP1.1时期，提出了长连接的通信方式，这种连接方式的特点是只要一方没有明确提出断开连接，则保持TCP连接状态。如果一方长时间没有数据交互，则HTTP会自动断开连接。 管道网络传输 HTTP1.1采用了长连接的方式，这使得管道传输成为可能。管道网络传输指在同一个TCP连接中，客户端可以发起多个请求，只要第一个请求发出，不必等其回来，就可以发第二个请求，减少响应时间。但是服务器必须按照接收请求的顺序发送对这些管道化请求的响应。如果服务器在处理前面的请求耗时较长，那么后面的请求处理会被阻塞住，这称为队头阻塞。所以，HTTP1.1 管道解决了请求的队头阻塞，但是没有解决响应的队头阻塞。 队头阻塞 请求-应答的模式会造成HTTP的性能问题，产生队头阻塞，所以HTTP1.1性能一般。 HTTP/2HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。其相比于HTTP/1.1有如下性能上的改进： 头部压缩 如果你同时发出多个请求，他们具有相同或相似的头部，那么HTTP/2会消除重复的部分。这就是所谓的HPACK算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，之后就发送索引号，加快传输速度。 二进制格式 区别于HTTP/1.1的纯文本形式的报文，HTTP/2采用二进制格式，头部信息和数据都是二进制格式，统称为帧，头信息帧（Headers Frame）和数据帧（Data Frame）。 计算机在收到报文后，无需进行转换，可以直接解析二进制报文，增加了数据传输效率。 并发传输 HTTP/1.1是基于请求-响应模型的，同一个连接中，HTTP完成一个事物才能进行下一个，如果遇到响应迟迟不来，则会造成队头阻塞。 HTTP/2引出了Stream概念，多个Stream复用在一条TCP连接。一个TCP连接包含多个Stream，每个Stream里可以包含一个或多个Message，Message 对应 HTTP/1 中的请求或响应，由 HTTP 头部和包体构成。Message 里包含一条或者多个 Frame，Frame 是 HTTP/2 最小单位，以二进制压缩格式存放 HTTP/1 中的内容（头部和包体）。 针对不同的HTTP请求用独一无二的Stream ID来进行区分，接收端可以通过Stream ID来有序组装成HTTP消息，不同Stream的帧可以是乱序发送的，因此可以并发不同的Stream，即交错发送请求和相应。 服务器主动推送资源 服务器不仅是被动的响应，而是可以主动向客户端发起信息。客户端和服务端都可以建立Stream， Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。 比如客户端在请求HTML网页时，服务端可以主动推送css文件，减少通信次数。 HTTP/2的缺陷有以下几点： HTTP/2在HTTP层面解决了请求和响应的阻塞问题，但是在TCP层面依然可能发生拥塞。 HTTP/2通过多个请求复用一个TCP连接，一旦发生TCP丢包，就会阻塞住所有的HTTP请求。由于是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当前面的字节数据没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。HTTP/3HTTP/2的队头阻塞是因为TCP，所以HTTP/3把HTTP下层的协议改成UDP。UDP协议可以不管发送顺序，也不用管丢包。不过，基于UDP的QUIC协议可以实现类似TCP的可靠传输。QUIC协议有以下特点： 无队头阻塞 QUIC协议也有类似HTTP/2 Stream的多路复用概念，也可以在同一条连接上并发传输多个Stream。QUIC也可以保证传输的可靠性，当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题。而HTTP/2只要有一个流阻塞，那么整个TCP连接都会受到阻塞。 更快的连接建立 对于HTTP/1和HTTP/2协议，TCP和TLS是分层的，很难合并到一起，因此需要分批次握手，先TCP，再TLS。 HTTP/3在传输前虽然需要QUIC协议握手，但握手过程只需要1RTT，握手的目的是确认双方的连接ID，连接迁移就是基于连接ID实现的。 HTTP/3的QUIC协议并不与TLS协议分层，而是QUIC协议包含TLS，他自己的帧里会携带TLS的记录。 连接迁移 基于TCP传输的HTTP协议由四元组来确定一条TCP连接，那么当用户切换网络，比如WIFI到蜂窝网络，那么IP地址就会发生变化，就必须断开重连，而重连过程中又涉及多次握手，就会有延迟，连接迁移的成本就会高。 而QUIC协议没有通过四元组的方式，而使用连接ID来标记通信的两个端点。客户端和服务端可以自行选择一组ID来表示自己，即使网络变化，只要仍保有上下文信息，就可以无缝切换连接。 QUIC是新协议，可能会有适配性问题，会被当作普通UDP。 7. HTTP和HTTPS两者的区别 HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。 HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。 两者的默认端口不一样，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。 HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。HTTPS解决了HTTP的哪些问题HTTPS在HTTP与TCP层之间加入了SSL/TLS协议，可以很好的解决HTTP不安全的风险 信息加密：交互信息无法被窃取。 校验机制：无法篡改通信内容，篡改了就不能正常显示。 身份证书：证明淘宝是真的淘宝网。HTTPS通过混合加密，摘要算法，数字证书来保证通信的安全。 混合加密 通过混合加密的方式可以保证信息的机密性。HTTPS采用的是对称加密和非对称加密结合的混合加密方式： 在通信建立前采用非对称加密的方式交换「会话秘钥」，后续就不再使用非对称加密。 在通信过程中全部使用对称加密的「会话秘钥」的方式加密明文数据。 摘要算法+数字签名 为了保证内容不被篡改，我们要对内容计算出一个”指纹“，发给对方，然后对方收到后也对内容做一个“指纹”，与发来的指纹进行比较，来检查数据是否被篡改。 在计算机中会用到摘要算法来计算出内容的哈希值，也就是内容的指纹。但是为了防止内容和指纹同时被篡改，要用到非对称加密算法来解决。一共有两个密钥，公钥和私钥。 这两个密钥是可以双向加解密的，公钥加密，私钥解密，是为了防止内容被篡改；而私钥加密，公钥解密是为了防止消息被冒充。但是一般不会用非对称加密直接加密内容，比较耗费性能。 所以非对称加密的用途主要在于通过「私钥加密，公钥解密」的方式，来确认消息的身份，我们常说的数字签名算法，就是用的是这种方式，不过私钥加密内容不是内容本身，而是对内容的哈希值加密。 数字证书 数字证书一般用来验证身份，其工作流程如下： 首先，服务器会把自己的公钥注册到数字证书认证机构，数字证书认证机构会用自己的私钥将服务器的公钥加密做数字签名，然后颁发数字证书。客户端在向服务端请求的时候拿到服务器的数字证书，使用预先内置的数字证书认证机构的公钥来验证服务器数字证书的真实性。然后从数字证书中获得服务器的公钥加密报文。 HTTPS如何建立连接SSL/TLS协议基本流程： 客户端向服务器索要并验证服务器的公钥。 双方协商生产「会话秘钥」。 双方采用「会话秘钥」进行加密通信。前两步就是SSL/TLS的握手阶段，TLS的握手阶段涉及四次通信。使用不同的密钥交换算法，握手流程也会不同。现在常用的密钥交换算法有两种：RSA算法和ECDHE算法。基于RSA算法的TLS握手过程如下所示：详细流程如下： ClientHello 首先，由客户端向服务器发起 ClientHello 加密通信请求。 在这一步，客户端主要向服务器发送一下信息： 客户端支持的TLS协议版本； 客户端产生的随机数，用于后续的会话加密； 客户端支持的密码套件，如RSA加密。 ServerHello 服务端收到客户端请求后，向客户端发出响应，包含以下内容： 确认TLS版本，如果浏览器不支持，则关闭加密通信； 服务器产生随机数，用于后面生成会话密钥； 确认的密码套件，如RSA； 服务器的数字证书。 客户端回应 客户端在收到服务器的回应之后，首先通过浏览器或者操作系统中的CA公钥核实服务器数字证书的真实性。 如果证书没有问题，客户端就会从证书中取出服务器的公钥，然后使用它加密报文，向服务器发送如下信息： 一个随机数，会被服务器公钥加密； 加密方法改变通知，表明之后都会用会话密钥加密通信； 客户端握手结束通知，表示客户端的握手阶段已经结束。同时把之前的数据做个摘要，用来供服务端校验。 服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」。 服务端最后的回应 服务端收到客户端的第三个随机数后，通过协商加密的算法，计算出本次通信的会话密钥； 然后，向客户端发送最后的消息： 加密算法改变的通知； 服务器握手结束的通知，并将之前的数据做摘要给客户端校验。 至此，整个 TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。数字证书签发数字证书的签发过程大致如下：CA签发证书为上图左部分，首先CA会把持有者的公钥，用途，颁发者，过期时间等有效信息打包，对其进行Hash加密，将加密后的哈希值用自己的私钥进行加密，形成CA的认证签名。将信息和签名组合成证书。而客户端在拿到签名后用公钥将CA的签名解密，得到Hash值，与证书中信息的Hash值进行比较，如果相同则校验通过。证书一般有多个层级，是为了保证根证书的安全性。HTTPS应用数据如何保持完整性TLS在实现上分为握手协议和记录协议两层： 握手协议就是TLS的四次握手过程，负责协商加密算法和生成加密密钥； 记录协议负责保护应用数据并验证其完整性和来源，所以对HTTP数据加密使用的是记录协议。TLS记录协议主要负责消息的压缩，加密及数据的认证，过程如下： 首先，消息会被分成许多更短的片段，然后分别对每个片段进行压缩； 接下来，经过压缩的片段会被加上消息认证码（MAC值，由Hash算法生成），这是为了保证完整性，并进行数据认证。通过MAC码可以识别出篡改，其中包含片段编码以防止重放攻击； 经过压缩的片段再加上消息认证码一起被对称加密； 最后，经过加密的数据再加上由数据类型、版本号、压缩后的长度组成的报头就是最终的报文数据。HTTPS安全性HTTPS 协议本身到目前为止还是没有任何漏洞的，即使你成功进行中间人攻击，本质上是利用了客户端的漏洞（用户点击继续访问或者被恶意导入伪造的根证书），并不是 HTTPS 不够安全。HTTPS抓包能实现就是抓包软件让客户端信任了他自己签发的证书，从而实现解包。" }, { "title": "数据库", "url": "/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/", "categories": "笔记", "tags": "数据库", "date": "2022-03-16 02:34:00 +0000", "snippet": "数据库MySQL1. InnoDB引擎MySQL支持数个存储引擎作为对不同表的类型的处理器。MySQL存储引擎包括处理事务安全表的引擎和处理非事务安全表的引擎。 MyISAM管理非事务表。它提供高速存储和检索，以及全文搜索能力。MyISAM在所有MySQL配置里被支持，它是MySQL之前的默认存储引擎。 MEMORY存储引擎提供”内存中”表。MERGE存储引擎允许集合将被处理同样的MyI...", "content": "数据库MySQL1. InnoDB引擎MySQL支持数个存储引擎作为对不同表的类型的处理器。MySQL存储引擎包括处理事务安全表的引擎和处理非事务安全表的引擎。 MyISAM管理非事务表。它提供高速存储和检索，以及全文搜索能力。MyISAM在所有MySQL配置里被支持，它是MySQL之前的默认存储引擎。 MEMORY存储引擎提供”内存中”表。MERGE存储引擎允许集合将被处理同样的MyISAM表作为一个单独的表。就像MyISAM一样，MEMORY和MERGE存储引擎处理非事务表，这两个引擎也都被默认包含在MySQL中。现在MySQL默认采用InnoDB引擎，其兼具可靠性和高性能，其为多线程的模型。其主要优点有： 其DML操作，即数据操作语言遵循ACID模型，具有提交，回滚和崩溃回复等功能，可以有效保护数据。 行级锁定，表示只针对当前操作的行进行加锁，可以大大减少数据库的冲突，增加并发度。 将数据安排在磁盘上，来优化基于主键的查询。而且每一个表都有主键索引。 支持外键约束，来保持数据的完整性。InnoDB如何存储数据为了提高一次读取的效率，减少I/O操作，InnoDB按照数据页来读写的。数据库I/O的最小单位是页，InnoDB默认数据页大小为16KB。数据页包含七个部分如下：文件头：用于表示页的信息；页头：表示页的状态信息；最小和最大记录：两个虚拟的为记录，用来记录分页中的最小记录和最大记录；用户记录：储存行记录数据；空闲空间：页中还没被使用的空间；页目录：存储用户记录的相对位置，对记录起到索引作用；文件尾：检验页是否完整。在文件头中有两个指针，分别指向上一个数据页和下一个数据页，相当于双向链表：数据页中用户记录如何组织数据数据页中的记录是按照主键顺序来组成单向链表，由于单链表检索效率不高，所以要在数据页中加入一个页目录来起到索引的作用。在InnoDB中，页目录与记录的关系如下：页目录的创建过程如下： 将所有的记录划分成几组，包括最小记录和最大记录，但不包括已删除的记录（mysql会用标签标记已删除的记录但并不擦除）； 每个记录组的最后一条记录就是组内最大的那条记录，并且最后一条记录的头信息中会存储该组一共有多少条记录，作为n_owned字段； 页目录用来存储每组最后一条数据的地址偏移量，这些地址偏移量会按照先后顺序存储，每组的地址偏移量也被称之为slot，每个slot相当于指针指向了不同组的最后一个记录。页目录就是由多个槽组成的，槽相当于分组记录的索引。因为记录按照从小到大排列，所以可以用二分法查找，定位到槽后，再遍历槽中的内容，找到记录。InnoDB的分组一般遵循以下原则： 第一个分组中的记录只能有 1 条记录； 最后一个分组中的记录条数范围只能在 1-8 条之间； 剩下的分组中记录条数范围只能在 4-8 条之间。2. SQL语句执行连接器：MySQL基于TCP，最大连接数由 max_connections 参数控制。查询缓存：对于更新比较频繁的表，查询缓存的命中率很低的，因为只要一个表有更新操作，那么这个表的查询缓存就会被清空，所以一般不用。解析语句：词法分析和语法分析。预处理器：查询表或字段是否存在，将*拓展为表上所有列。优化器：确定SQL查询的执行方案，选择索引。执行器：主键索引查询，全表扫描，索引下推。MySQL连接池连接池是connection对象的缓冲区，它里面会放一些connection，当程序需要连接的时候，不需要重新创建连接，直接从连接池中获取即可。数据库连接池就是在程序启动时就创建一定数量的数据库连接，将这些连接放入一个池子进行管理。由程序动态的进行连接的申请、使用和释放。其有以下好处 资源复用：避免频繁创建连接，销毁带来的性能开销，减少系统资源消耗； 更快的响应速度：由于程序启动时就准备好了若干连接备用，业务请求直接使用即可，不需要实时进行连接的创建。 统一的连接管理，避免数据库连接泄露：可预先设定连接占用的超时时间，假如某条连接被占用超过设定值，可以强制回收该连接。数据库连接池有以下 C3P0：太古老，代码及其复杂，不利于维护。 dbcp：是 apache上的一个 java 连接池项目，也是 tomcat 使用的连接池组件。 druid：是alibba出品的一个功能比较全面，且扩展性较好的数据库连接池，比较方便对jdbc接口进行监控跟踪等。 HikariCP：光连接池，目前被SpringBoot2官方推荐使用的数据库连接池。3. 索引：数据的目录分类： 按「数据结构」分类：B+tree索引、Hash索引、Full-text索引。 按「物理存储」分类：聚簇索引（主键索引）、二级索引（辅助索引）。 按「字段特性」分类：主键索引、唯一索引、普通索引、前缀索引。 按「字段个数」分类：单列索引、联合索引。B树/B+树B+ 树就是对 B 树做了一个升级，MySQL 中索引的数据结构就是采用了 B+ 树，B+ 树结构如下图：B+ 树与 B 树差异的点，主要是以下这几点： 叶子节点（最底部的节点）才会存放实际数据（索引+记录），非叶子节点只会存放索引； 所有索引都会在叶子节点出现，叶子节点之间构成一个有序链表； 非叶子节点的索引也会同时存在在子节点中，并且是在子节点中所有索引的最大（或最小）。 非叶子节点中有多少个子节点，就有多少个索引。当我们需要存储大量记录时，需要建立多个数据页。InnoDB采用B+树作为索引，因为B+树更为矮胖，可以减少磁盘操作的次数。InnoDB的B+树中每一个结点都是一个数据页：B+树和B树区别，为什么用B+树B+Tree 只在叶子节点存储数据，而 B 树的非叶子节点也要存储数据，所以 B+Tree 的单个节点的数据量更小，在相同的磁盘 I/O 次数下，就能查询更多的节点。另外，B+Tree 叶子节点采用的是双链表连接，适合 MySQL 中常见的基于范围的顺序查找，而 B 树无法做到这一点。二叉树只有两个叶子结点，层次太多，IO操作更频繁。Hash 表不适合做范围查询，它更适合做等值的查询。不同索引：(1) 主键索引（聚簇索引）和二级索引（辅助索引）区别： 主键索引的 B+Tree 的叶子节点存放的是实际数据，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里； 二级索引的 B+Tree 的叶子节点存放的是主键值，而不是实际数据。当根据二级索引查询的时候，根据二级索引的B+树得到主键值，再用主键的B+树进行查找得到数据，这个操作叫做回表。当查询的数据可以在二级索引的B+树里查到，就叫做覆盖索引。在InnoDB中，由于表的数据放在主键索引的叶子结点里，所以InnoDB一定会为表创建一个主键索引，且由于这个数只会保存一份，所以主键索引只能有一个。InnoDB创建主键索引遵循以下原则： 如果有主键，默认会使用主键作为聚簇索引的索引键； 如果没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键； 在上面两个都没有的情况下，InnoDB 将自动生成一个隐式自增 id 列作为聚簇索引的索引键。一张表只能有一个主键索引，但是可以有多个二级索引，二级索引的叶子结点存放主键值，其B+树结构如下： B+ 树的叶子节点之间是用「双向链表」进行连接，这样的好处是既能向右遍历，也能向左遍历。 B+ 树点节点内容是数据页，数据页里存放了用户的记录以及各种信息，每个数据页默认大小是 16 KB。(2) 唯一索引，普通索引和前缀索引唯一索引可以有多个，可以为空值；普通索引可以重复，用INDEX(column,…)创建。前缀索引是指对字符类型字段的前几个字符建立的索引，而不是在整个字段上建立的索引，用来减少储存空间。(3) 联合索引将多个字段组合成一个索引，其B+树如下所示，叶子结点为双向链表：使用联合索引时遵循最左匹配原则，如果在查询到时候不遵循最左匹配原则，索引就会失效。在索引为(a,b,c)的情况下，是先按 a 排序，在 a 相同的情况再按 b 排序，在 b 相同的情况再按 c 排序。所以，b 和 c 是全局无序，局部相对有序的，如果查询时没有a，则会索引失效。范围查询：假设数据表中(a,b)作为联合主键，其范围查询分为以下几种情况 SELECT * FROM &lt;table&gt; WHERE a&gt;1 AND b=2 由于联合索引是根据a的顺序排序的，所以先按照a的范围进行索引查询，程序找到a&gt;1的部分，向后扫描，在a&gt;1的部分里b的值是无序的，所以b字段无法用到联合索引。 SELECT * FROM &lt;table&gt; WHERE a&gt;=1 AND b=2 与上面不同的是，在a=1的时候，b的字段是有序的，所以当a=1的时候，直接找到b=2，从这之后往后扫描，可以减少二级索引的记录范围，这时a和b都用了联合索引。 SELECT * FROM &lt;table&gt; WHERE a BETWEEN 2 AND 8 AND b=2 在mysql中，between为两侧闭区间，所以a和b都可以用到联合索引。 SELECT * FROM &lt;table&gt; WHERE a LIKE ‘j%’ AND b=2 这里a的扫面范围是[j,k)，所以a和b都可以用到联合索引。 (4) 索引优化：前缀索引优化，使用某个字段中字符串的前几个字符建立索引，减小索引字段的大小。覆盖索引优化，指语句中查询的所有字段都在联合索引中，用来减少主键自增。提高性能，避免出现页分裂。索引下推优化， 可以在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。防止索引失效，尽量利用索引进行查询。当存在%like%和%like查询时会发生索引失效。(5) 索引区分度：是某个字段 column 不同值的个数「除以」表的总行数。(6) 索引失效： 当我们使用左或者左右模糊匹配的时候，也就是 like %xx 或者 like %xx%这两种方式都会造成索引失效； 当我们在查询条件中对索引列使用函数，就会导致索引失效。 当我们在查询条件中对索引列进行表达式计算，也是无法走索引的。 MySQL 在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较。如果字符串是索引列，而条件语句中的输入参数是数字的话，那么索引列会发生隐式类型转换，由于隐式类型转换是通过 CAST 函数实现的，等同于对索引列使用了函数，所以就会导致索引失效。 联合索引要能正确使用需要遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。 在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。COUNT函数按照性能，count(*)=count(1)&gt;count(主键字段)&gt;count(字段)count(*)=count(0)其对主键索引进行遍历，将读取到的记录返回server层，但不读取记录中的任何字段的值。如果不为null就让count字段+1count(主键)会读取主键值，而count(字段)对进行全表扫描。5. 事务事务的特性事务是由 MySQL 的引擎来实现的，我们常见的 InnoDB 引擎它是支持事务的。事务具有以下四个特性(ACID)： 原子性（Atomicity）：一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样，就好比买一件商品，购买成功时，则给商家付了钱，商品到手；购买失败时，则商品在商家手中，消费者的钱也没花出去。 一致性（Consistency）：是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态。比如，用户 A 和用户 B 在银行分别有 800 元和 600 元，总共 1400 元，用户 A 给用户 B 转账 200 元，分为两个步骤，从 A 的账户扣除 200 元和对 B 的账户增加 200 元。一致性就是要求上述步骤操作后，最后的结果是用户 A 还有 600 元，用户 B 有 800 元，总共 1400 元，而不会出现用户 A 扣除了 200 元，但用户 B 未增加的情况（该情况，用户 A 和 B 均为 600 元，总共 1200 元）。 隔离性（Isolation）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致，因为多个事务同时使用相同的数据时，不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的。也就是说，消费者购买商品这个事务，是不影响其他消费者购买的。 持久性（Durability）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。并行事务引发的问题： 脏读 如果一个事务读到了另一个未提交事务修改过的数据，就意味着发生了脏读现象 如上图所示，如果事务A发生了回滚，那么B会读到过期的数据。 不可重复读 在一个事务内多次读取同一个数据，如果出现前后两次读到数据不一样的情况，就意味着发生了不可重复读 比如当事务A第一次读取余额数据后，事务B更新了余额数据，在提交前，事务A再次读取了这条数据，就会发生两次读取不一致的情况。 幻读 在一个事务内多次查询符合条件的记录数量，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了幻读 当事务A第一次读取符合条件的记录数量后，事务B插入了一条数据，而当A再次读取记录数量后会发现数量改变，发生了幻读。 严重性：脏读&gt;不可重复读&gt;幻读事务的隔离级别： 读未提交（read uncommitted），指一个事务还没提交时，它做的变更就能被其他事务看到； 读提交（read committed），指一个事务提交之后，它做的变更才能被其他事务看到； 可重复读（repeatable read），指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，MySQL InnoDB 引擎的默认隔离级别； 串行化（serializable）；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；隔离水平高低：串行化&gt;可重复读&gt;读已提交&gt;读未提交针对不同的隔离级别，并发事务可能发生的现象不同实现方式对于读未提交，直接读取最新数据；对于串行化，通过加读写锁的方式来避免并行访问；对于读提交和可重复读的事务来说，他们是通过Read View实现的，类似于数据快照。读提交是在每个语句执行前都会重新生成一个Read View，而可重复读诗在启动事务时生成一个Read View，然后整个事务中就用这个Read View。Read ViewRead View有四个重要的字段： m_ids ：指的是在创建 Read View 时，当前数据库中「活跃事务」的事务 id 列表，注意是一个列表，“活跃事务”指的就是，启动了但还没提交的事务。 min_trx_id ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 id 最小的事务，也就是 m_ids 的最小值。 max_trx_id ：这个并不是 m_ids 的最大值，而是创建 Read View 时当前数据库中应该给下一个事务的 id 值，也就是全局事务中最大的事务 id 值 + 1； creator_trx_id ：指的是创建该 Read View 的事务的事务 id。聚簇索引中的两个隐藏列：对于InnoDB，其主键索引中包含两个隐藏列： trx_id，当一个事务对某条聚簇索引记录进行改动时，就会把该事务的事务 id 记录在 trx_id 隐藏列里； roll_pointer，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后这个隐藏列是个指针，指向每一个旧版本记录，于是就可以通过它找到修改前的记录。在创建Read View后，记录可以分三种情况： 如果记录的 trx_id 值小于 Read View 中的 min_trx_id 值，表示这个版本的记录是在创建 Read View 前已经提交的事务生成的，所以该版本的记录对当前事务可见。 如果记录的 trx_id 值大于等于 Read View 中的 max_trx_id 值，表示这个版本的记录是在创建 Read View 后才启动的事务生成的，所以该版本的记录对当前事务不可见。 如果记录的 trx_id 值在 Read View 的min_trx_id和max_trx_id之间，需要判断 trx_id 是否在 m_ids 列表中： 如果记录的 trx_id 在 m_ids 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务不可见。 如果记录的 trx_id 不在 m_ids列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务可见。 这种通过版本链来控制并发事务访问同一个记录的行为就叫MVCC多版本并发控制。6. 日志undo log（回滚日志）在执行一条增删改语句的时候，MySQL会隐式开启事务来执行。执行一条语句是否自动提交事务是由autocommit参数决定的，默认开启。如果在提交事务之前，MySQL发生了崩溃，就会调用undo log。它是 Innodb 存储引擎层生成的日志，通过事务回滚实现了事务中的原子性，也时实现 MVCC的关键因素之一。Buffer Pool（缓冲池）为了提高数据库的读写性能，InnoDB设计了一个缓冲池。有了缓冲池后： 当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。 当修改数据时，如果数据存在于 Buffer Pool 中，那直接修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页（该页的内存数据和磁盘上的数据已经不一致），为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。在MySQL启动的时候，InnoDB回味Buffer Pool申请一片连续的内存空间，然后按照默认16kb的大小划分出一个个的页，缓冲池中的页就叫缓存页。缓存页的组成如下所示：redo log（重做日志）由于Buffer Pool是基于内存的，为了防止断电重启导致数据丢失，当有一条记录需要更新的时候，InnoDB就会先更新内存，同时标记为脏页，然后将本次对这个页的修改以redo log的形式记录下来，这时候算更新完成。其是Innodb 存储引擎层生成的日志，实现了事务中的持久性。然后，InnoDB会在适当的时候，有后台线程将缓存在Buffer Pool的脏页刷新到磁盘，这就是WAL （Write-Ahead Logging）技术。WAL 技术指的是， MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上。其过程如下图：binlog （归档日志）Binlog是 Server 层生成的日志，主要用于数据备份和主从复制。MySQL在完成一条更新操作后，Server层还会生成一条binlog，等之后事务提交的时候，会将该事务执行过程中产生的所有binlog同意写入binlog文件。binlog文件是记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作。redo log和binlog有四点不同： 适用对象不同 binlog是mysql的server层实现的日志，所有存储引擎都可以用； redo log是InnoDB存储引擎实现的日志。 文件格式不同 binlog有3种格式类型，而redo log是物理日志。 写入方式不同 binlog是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志； redo log是循环写，日志空间大小固定。 用途不同 binlog用于备份恢复，主从复制； redo log用于掉电等故障恢复。 7. 锁全局锁将数据库变为只读状态，对数据库修改的操作都会被阻塞。flush tables with read lock unlock tables全局锁的应用场景主要是全库逻辑备份，这样在备份数据库期间，不会因为数据或表结构的更新，出现数据不一致的情况。但是加上全局锁后，在数据库备份期间，就会造成业务停滞。表级锁1. 表锁如果相对学生表加锁，可以用一下命令。//表级别的共享锁，也就是读锁；lock tables t_student read;//表级别的独占锁，也就是写锁；lock tables t_stuent write;表锁会限制别的线程的读写之外，也会限制本线程接下来的读写操作。2. 元数据锁(MDL)当我们对数据表进行操作的时候，会自动给这个表加上MDL： 对一张表进行 CRUD 操作时，加的是 MDL 读锁； 对一张表做结构变更操作的时候，加的是 MDL 写锁；MDL是为了保证用户执行CRUD操作的时候，防止其他线程改变表结构。其在事务被提交后才会释放，所以在事务执行期间，MDL是一直持有的。而且写锁的优先级高于读锁。3. 意向锁 在使用 InnoDB 引擎的表里对某些记录加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」； 在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」；当执行插入，更新，删除操作时，要先对表加上意向独占锁，然后对该记录加独占锁，而普通的SELECT语句是利用MVCC来实现一致性读的，是无锁的。意向锁是表级锁，不会与行级锁冲突。意向锁的目的是为了快速判断表中是否有记录被加锁。4. AUTO-INC锁表的主键自增是根据声明AUTO_INCREMENT实现的，之后在数据表中插入数据时，会给表加一个AUTO-INC锁，然后被自增修饰的字段赋值，等插入语句执行完成后，才会把锁释放掉。但是大量插入数据时，AUTO-INC会降低性能，所以在MySQL 5.1.22后InnoDB存储引擎提供了一种轻量级的锁，当插入语句执行时，会被AUTO INCREMENT加一个轻量锁，然后给改字段赋值一个字增的值，就把这个轻量级的锁释放了，而不需要等待整个插入语句执行完成后在释放。行级锁InnoDB支持行级加锁。如果要在查询时对记录加行锁，可以用如下语句，这种查询会加锁的语句称为锁定读。//对读取的记录加共享锁select ... lock in share mode;//对读取的记录加独占锁select ... for update上面两条语句必须在一个事务中，因为当事务被提交了，锁就会被释放，所以在使用这两条语句的时候要加上begin，start transaction或者set autocommit=0。共享锁（S锁）满足读读共享，读写互斥。独占锁（X锁）满足写写互斥、读写互斥。1. Record LockRecord Lock称为记录锁，锁住的是一条记录，而且是有S锁和X锁之分的： 当一个事务对一条记录加了 S 型记录锁后，其他事务也可以继续对该记录加 S 型记录锁（S 型与 S 锁兼容），但是不可以对该记录加 X 型记录锁（S 型与 X 锁不兼容）; 当一个事务对一条记录加了 X 型记录锁后，其他事务既不可以对该记录加 S 型记录锁（S 型与 X 锁不兼容），也不可以对该记录加 X 型记录锁（X 型与 X 锁不兼容）。2. Gap LockGap Lock称为间隙锁，只存在于可重复读隔离级别，目的是为了可重复读隔离级别下幻读的现象。举例来说，表中有一个3-5的间隙锁，那么其他事务就无法插入。间隙锁之间是兼容的，即两个事务可以同时持有包含共同间隙范围的间隙锁，并不存在互斥关系，因为间隙锁的目的是防止插入幻影记录而提出的。3. Next-Key LockNext-key Lock称为临键锁，是Record Lock+Gap Lock的组合，锁定一个范围，并且锁定记录本身。next-key lock 是包含间隙锁+记录锁的，如果一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，是会被阻塞的。4. 插入意向锁一个事务在插入一条记录的时候需要判断插入位置是否依旧被其他事务加了间隙锁，如果有的话，插入操作就会发生阻塞，知道拥有间隙锁的那个事务提交为止，在此期间会生成一个插入意向锁，表明有事务想在某个区间插入新纪录，但是现在处于等待状态。举个例子，假设事务 A 已经对表加了一个范围 id 为（3，5）间隙锁。当事务A还没有提交的时候，事务B向该表插入一条id=4的新纪录，这时会判断到插入的位置已经被事务 A 加了间隙锁，于是事物 B 会生成一个插入意向锁，然后将锁的状态设置为等待状态（PS：MySQL 加锁时，是先生成锁结构，然后设置锁的状态，如果锁状态是等待状态，并不是意味着事务成功获取到了锁，只有当锁状态为正常状态时，才代表事务成功获取到了锁），此时事务 B 就会发生阻塞，直到事务 A 提交了事务。插入意向锁的名字虽然有意向锁，但他并不是意向锁，他是一种特殊的间隙锁，属于行级别锁。MySQL如何加行级锁加锁的对象是索引，加锁的基本单位是next-key lock，他是由记录锁和间隙锁组合而成的，next-key lock 是前开后闭区间，而间隙锁是前开后开区间。但是，next-key lock在一些场景下会退化为记录锁或间隙锁，即在能适应记录锁或间隙锁就能避免幻读的场景下，next-key lock就会退化成记录锁或间隙锁。1. 唯一索引等值查询当我们使用唯一索引进行等值查询的时候，查询的记录存在与否，加锁的规则也会不同。 当查询的记录是「存在」的，在索引树上定位到这一条记录后，将该记录的索引中的 next-key lock 会退化成「记录锁」。 当查询的记录是「不存在」的，在索引树找到第一条大于该查询记录的记录后，将该记录的索引中的 next-key lock 会退化成「间隙锁」。2. 唯一索引范围查询当唯一索引进行范围查询时，会对每一个扫描到的索引加 next-key 锁，然后如果遇到下面这些情况，会退化成记录锁或者间隙锁： 情况一：针对「大于等于」的范围查询，因为存在等值查询的条件，那么如果等值查询的记录是存在于表中，那么该记录的索引中的 next-key 锁会退化成记录锁。 情况二：针对「小于或者小于等于」的范围查询，要看条件值的记录是否存在于表中： 当条件值的记录不在表中，那么不管是「小于」还是「小于等于」条件的范围查询，扫描到终止范围查询的记录时，该记录的索引的 next-key 锁会退化成间隙锁，其他扫描到的记录，都是在这些记录的索引上加 next-key 锁。 当条件值的记录在表中，如果是「小于」条件的范围查询，扫描到终止范围查询的记录时，该记录的索引的 next-key 锁会退化成间隙锁，其他扫描到的记录，都是在这些记录的索引上加 next-key 锁；如果「小于等于」条件的范围查询，扫描到终止范围查询的记录时，该记录的索引 next-key 锁不会退化成间隙锁。其他扫描到的记录，都是在这些记录的索引上加 next-key 锁。 3. 非唯一索引等值查询当我们用非唯一索引进行等值查询的时候，因为存在两个索引，一个是主键索引，一个是非唯一索引（二级索引），所以在加锁时，同时会对这两个索引都加锁，但是对主键索引加锁的时候，只有满足查询条件的记录才会对它们的主键索引加锁。针对非唯一索引等值查询时，查询的记录存不存在，加锁的规则也会不同： 当查询的记录「存在」时，由于不是唯一索引，所以肯定存在索引值相同的记录，于是非唯一索引等值查询的过程是一个扫描的过程，直到扫描到第一个不符合条件的二级索引记录就停止扫描，然后在扫描的过程中，对扫描到的二级索引记录加的是 next-key 锁，而对于第一个不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。同时，在符合查询条件的记录的主键索引上加记录锁。 当查询的记录「不存在」时，扫描到第一条不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。因为不存在满足查询条件的记录，所以不会对主键索引加锁。4. 非唯一索引范围查询非唯一索引和主键索引的范围查询的加锁也有所不同，不同之处在于非唯一索引范围查询，索引的 next-key lock 不会有退化为间隙锁和记录锁的情况，也就是非唯一索引进行范围查询时，对二级索引记录加锁都是加 next-key 锁。5. 没有加锁的查询如果锁定读查询语句，没有使用索引列作为查询条件，或者查询语句没有走索引查询，导致扫描是全表扫描。那么，每一条记录的索引上都会加 next-key 锁，这样就相当于锁住的全表，这时如果其他事务对该表进行增、删、改操作的时候，都会被阻塞。不只是锁定读查询语句不加索引才会导致这种情况，update 和 delete 语句如果查询条件不加索引，那么由于扫描的方式是全表扫描，于是就会对每一条记录的索引上都会加 next-key 锁，这样就相当于锁住的全表。因此，在线上在执行 update、delete、select … for update 等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了。MySQL死锁死锁的四个必要条件：互斥、占有且等待、不可强占用、循环等待。只要系统发生死锁，这些条件必然成立，但是只要破坏任意一个条件就死锁就不会成立。在数据库层面，有两种策略通过「打破循环等待条件」来解除死锁状态： 设置事务等待锁的超时时间。当一个事务的等待时间超过该值后，就对这个事务进行回滚，于是锁就释放了，另一个事务就可以继续执行了。在 InnoDB 中，参数 innodb_lock_wait_timeout 是用来设置超时时间的，默认值时 50 秒。 当发生超时后，就出现下面这个提示： 开启主动死锁检测。主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑，默认就开启。 当检测到死锁后，就会出现下面这个提示： Redis1. 基础Redis 是一种基于内存的数据库，对数据的读写操作都是在内存中完成，因此读写速度非常快，常用于缓存，消息队列、分布式锁等场景。Redis 提供了多种数据类型来支持不同的业务场景，比如 String(字符串)、Hash(哈希)、 List (列表)、Set(集合)、Zset(有序集合)、Bitmaps（位图）、HyperLogLog（基数统计）、GEO（地理信息）、Stream（流），并且对数据类型的操作都是原子性的，因为执行命令由单线程负责的，不存在并发竞争的问题。2. Redis用作MySQL的缓存Redis 具备高性能，将该用户访问的数据缓存在 Redis 中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了，操作 Redis 缓存就是直接操作内存，所以速度相当快。Redis 具备高并发，直接访问 Redis 能够承受的请求是远远大于直接访问 MySQL 的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。3. Redis数据结构常见的有五种数据类型：String（字符串），Hash（哈希），List（列表），Set（集合）、Zset（有序集合）随着版本的更新，后面又支持了四种数据类型：BitMap,HyperLogLog, GEO, Stream常见5种数据类型的应用场景：StringString是最基本的key-value结构，其主要内部实现是int和SDS。其多用于缓存对象，常规计数，分布式锁，共享session等；ListList列表是简单的字符串列表，按照插入顺序排序，可以从头部或尾部添加元素。其内部实现主要由双向链表或压缩列表实现。如果列表元素个数小于512个，列表么每个元素的值都小于64字节，Redis会用压缩列表存储。如果不满足上述条件，则会用双向链表存储。但在3.2版本后，List就只由quicklist实现。一般应用于消息队列（但是生产者需要自行实现全局唯一id，不能以消费组形式消费数据）等；HashHash是一个key-value的集合，其比较适合存储对象。内部实现是由压缩列表或哈希表实现的。在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了一般用于缓存对象，购物车等；SetSet是无序且唯一的存储集合。其内部实现使用哈希表或整数集合实现的。应用场景有聚合计算（并集，交集，差集）常见，比如点赞，共同关注，抽奖活动等。ZsetZset是有序集合，其内部实现有跳表和listpack。主要应用于排序场景，比如排行榜，电话和姓名排序等。新增4种数据类型应用场景： BitMap：二值状态统计的场景，比如签到，判断用户登录状态等； HyperLogLog：海量数据基数统计的场景； GEO：储存地理位置的场景； Strean：消息队列，相比于List，可以自动生成全局唯一消息ID，支持以消费形式消费数组。五种常见数据类型实现方式：键值对Redis使用了一个哈希表来保存所有的键值对。在哈希表中的元素叫哈希桶，哈希桶中存放数据的指针，所以键值对的数据结构并不直接保存值本身，而是指向Redis对象。SDSRedis使用C语言实现的，但是他自己封装了简单动态字符串SDS。其结构如下：其二进制安全，不会发生缓冲区溢出。压缩列表压缩列表是由连续内存块组成的顺序型数据结构，类似于数组。压缩列表表头有三个字段： zlbytes，记录整个压缩列表占用对内存字节数； zltail，记录压缩列表「尾部」节点距离起始地址由多少字节，也就是列表尾的偏移量； zllen，记录压缩列表包含的节点数量； zlend，标记压缩列表的结束点，固定值 0xFF。在压缩列表中查找头尾元素根据头结点信息进行定位会很快，但是查询中间元素的效率会下降到O(N)，因此不适合保存过多元素。哈希表Redis采用链式哈希。整数集合整数集合本质上是一块连续的内存空间。跳表Redis只有Zset对象的底层实现用到了跳表，跳表的优势是能支持平均O(logN)复杂度的结点查找。 结构设计 跳表是在链表基础上改进过来的，实现了一种多层的有序链表，好处是可以快速定位数据。 以一个3层跳表的结构为例： 图中的头结点有L0-L2三个头指针，分别指向不同层级的结点，每个层级的结点都通过指针连接起来。 跳表可以在多个层级上跳来跳去，所以当数据量大后，跳表的查找复杂度是O(logN)。Zset对象同时要保持元素和元素的权重，对应到跳表结点中就是sds类型的ele变量和double类型的score遍历。每个跳表结点都有一个向后指针，指向前一个结点。同时每一个层级可以包含多个结点，每一个结点通过指针连接起来，实现这一特性的就是跳表结构体种的zskiplistLevel结构体类型的level数组。跳表的跨度实际上是为了计算这个结点在跳表中的排位。 查询过程 查找一个跳表结点，跳表会从头结点的最高层开始，逐一遍历每一层。再遍历某一层的跳表结点时，会用跳表结点中的SDS类型元素和元素权重来进行判断： 如果当前节点的权重「小于」要查找的权重时，跳表就会访问该层上的下一个节点。 如果当前节点的权重「等于」要查找的权重时，并且当前节点的 SDS 类型数据「小于」要查找的数据时，跳表就会访问该层上的下一个节点。 层数设置 跳表的相邻两层的结点数量最理想的比例是2:1，查找复杂度可以降到O(logN)。 4. Redis线程Redis 单线程指的是「接收客户端请求-&gt;解析请求 -&gt;进行数据读写等操作-&gt;发送数据给客户端」这个过程是由一个线程（主线程）来完成的。但是Redis 程序并不是单线程的，Redis 在启动的时候，是会启动后台线程（BIO）单线程模式5. Redis持久化当 Redis 重启后，内存中的数据就会丢失，那为了保证内存中的数据不会丢失，Redis 实现了数据持久化的机制，这个机制会把数据存储到磁盘，这样在 Redis 重启就能够从磁盘中恢复原有的数据。Redis 共有三种数据持久化的方式： AOF 日志：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里； RDB 快照：将某一时刻的内存数据，以二进制的方式写入磁盘； 混合持久化方式：Redis 4.0 新增的方式，集成了 AOF 和 RBD 的优点；(1) AOF日志实现：Redis 在执行完一条写操作命令后，就会把该命令以追加的方式写入到一个文件里，然后 Redis 重启时，会读取该文件记录的命令，然后逐一执行命令的方式来进行数据恢复。在主线程中执行Reids 是先执行写操作命令后，才将该命令记录到 AOF 日志里的，这么做其实有两个好处：避免额外的检查开销，不会阻塞当前写操作命令的执行。但是也有风险：数据可能会丢失，可能阻塞其他操作。AOF有三种写回方式，Always, Everysec, No.(2) RBF快照：AOF 日志记录的是操作命令，不是实际的数据，恢复的时候和能会很慢。RDB 快照就是记录某一个瞬间的内存数据，记录的是实际数据。Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave，他们的区别就在于是否在「主线程」里执行： 执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，会阻塞主线程； 执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以避免主线程的阻塞；6. Redis集群主从复制AOF和RDB这两个持久化技术保证了即使在服务器重启的情况下也不会丢失数据。但是由于数据都在一台服务器上，如果出事就会丢失数据。要避免这种单点故障。就需要将数据备份到其他服务器。让这些服务器也可以提供服务。这样一来即使某个服务器发生故障，其他服务器依然可以继续提供服务。为了让这些服务器之间的数据保持一致性，Redis提供了主从复制模式。主从复制是 Redis 高可用服务的最基础的保证，实现方案就是将从前的一台 Redis 服务器，同步数据到多台从 Redis 服务器上，即一主多从的模式，且主从服务器之间采用的是「读写分离」的方式。多台服务器使用 replicaof 命令来确定谁是主服务器。在从服务器上执行replicaof &lt;主服务器的 IP 地址&gt; &lt;主服务器的 Redis 端口号&gt;来进行主从服务器的分配。Redis主从节点采用长连接的的方式。主从节点组成一个Redis集群，主从服务器之间采用ping-pong的心态检测机制。如果有一半以上的节点区ping一个节点而没有pong回应的话，那么集群就会认为这个节点挂掉了。从而断开与这个节点的连接。如果主节点处理了一个key或者通过淘汰算法淘汰了一个key，这时主节点模拟一条del命令发送给从节点，从节点收到该命令后，就进行删除key操作。Redis 主节点每次收到写命令之后，先写到内部的缓冲区，然后异步发送给从节点，所以同步复制是异步操作。不过由于是异步操作，所以主节点和从节点的数据无法保持强一致性，即时时刻刻保持一致。主从复制一共有三种模式：全量复制，基于场连接的命令传播，增量复制。主从服务器第一次同步的时候，采用全量复制；第一次同步完成后，主从服务器都会维护着一个长连接，主服务器在接收到写操作命令后，就会通过这个链接将写命令传给从服务器，来保证主从服务器的数据一致性。如果遇到网络断开，增量复制就可以上场了。主节点挂掉后，从节点是无法自己升级到主节点的，需要人工外部处理，在此期间Redis无法提供写操作。哨兵模式当 Redis 的主从服务器出现故障宕机时，需要手动进行恢复。哨兵模式做到了可以监控主从服务器，并且提供主从节点故障转移的功能。哨兵其实是一个运行在特殊模式下的Redis进程，相当于一个观察节点。哨兵一般是以集群的方式部署的，至少需要三个结点，其主要负责三件事情：监控，选主，通知。哨兵结点之间是通过Redis的Pub-Sub机制来相互发现的。运行过程为： 第一轮投票，判断主结点下线； 第二轮投票，选出哨兵leader； 有哨兵leader进行主从故障转移。如何判断主节点故障哨兵会每隔1秒给所有主从节点发送命令，当主从节点收到PING命令后，会发送一个响应命令给哨兵，这样就可以判断其是否下线。如果节点在规定时间内没有响应PING命令，那么哨兵就会将其标记为主观下线。但是如果遇到网络拥塞或者主节点系统压力比较大，也会无法响应PING，但是这时主节点并没有下线。针对这种情况，哨兵在部署的时候会部署多个节点组成哨兵集群，通过多个哨兵节点一起判断，就可以就可以避免单个哨兵因为自身网络状况不好，而误判主节点下线的情况。如何选取leader哪个哨兵节点判断主节点为客观下线，这个哨兵节点就是候选者。候选者会向其他哨兵发送命令，表明希望成为leader来执行主从切换。让其他哨兵进行投票，在投票过程中，任何一个候选者需要拿到半数以上赞成票，并且拿到的票数要大于等于配置中 quorum 的值。故障转移主从故障转移操作包含以下四个步骤： 在已下线主节点属下的所有从节点里面，挑选出一个从节点，并将其转换为主节点。 让已下线主节点属下的所有从节点修改复制目标，修改为复制新主节点； 将新主节点的 IP 地址和信息，通过Pub-Sub机制通知给客户端； 继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点；7. 缓存缓存雪崩当大量缓存数据在同一时间过期（失效）或者 Redis 故障宕机时，如果此时有大量的用户请求，都无法在 Redis 中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃，这就是缓存雪崩的问题。 大量数据同时过期 均匀设置过期时间； 互斥锁； 双 key 策略； 后台更新缓存； Redis故障宕机 服务熔断或请求限流机制； 构建 Redis 缓存高可靠集群； 缓存击穿如果缓存中的某个热点数据过期了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮，这就是缓存击穿的问题。可以发现缓存击穿跟缓存雪崩很相似，你可以认为缓存击穿是缓存雪崩的一个子集。应对缓存击穿可以采取前面说到两种方案： 互斥锁方案，保证同一时间只有一个业务线程更新缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。 不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间；缓存穿透当用户访问的数据，既不在缓存中，也不在数据库中，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是缓存穿透的问题。缓存穿透的发生一般有这两种情况： 业务误操作，缓存中的数据和数据库中的数据都被误删除了，所以导致缓存和数据库中都没有数据； 黑客恶意攻击，故意大量访问某些读取不存在数据的业务；应对缓存穿透的方案，常见的方案有三种。 第一种方案，非法请求的限制； 第二种方案，缓存空值或者默认值； 第三种方案，使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在；布隆过滤器可以在写入数据库的时候，使用布隆过滤器做标记，当用户请求时，业务线程确认缓存失效后，可以通过查询布隆过滤器来快速判断数据是否存在，如果不存在就查询数据库。布隆过滤器由「初始值都为 0 的位图数组」和「 N 个哈希函数」两部分组成。当我们在写入数据库数据时，在布隆过滤器里做个标记，这样下次查询数据是否在数据库时，只需要查询布隆过滤器，如果查询到数据没有被标记，说明不在数据库中。布隆过滤器会通过 3 个操作完成标记： 第一步，使用 N 个哈希函数分别对数据做哈希计算，得到 N 个哈希值； 第二步，将第一步得到的 N 个哈希值对位图数组的长度取模，得到每个哈希值在位图数组的对应位置。 第三步，将每个哈希值在位图数组的对应位置的值设置为 1；热key问题当有几十万的请求突然去访问Redis上的某个特定key，那么这样会导致流量过于集中，产生热key问题。解决的方式有 利用二级缓存：比如 ehcache 或者 Hashmap ，当发现热key后，把热key加载到jvm中。针对这种热key请求，会直接从jvm中取，而不会走到redis层。 备份热key：把这个key，在多个redis上都存一份。当有热key请求进来的时候，我们就在有备份的redis上随机选取一台，进行访问取值，返回数据。8. 分布式锁基础我们在系统中修改已有数据的时候，需要先读取，然后进行修改保存，此时很容易遇到并发问题，因为这三个操作不是原子性的。为了解决这个问题，我们需要锁。对于锁而言，在 Java 中的 synchronized 以及 ReentrantLock 可重入锁都是比较常见的。但是这种是本地锁，在现在微服务，分布式系统思想大行其道的时候，本地锁显然无法发挥作用。所以可以通过 MySQL、可以通过 ZK、也可以通过 Redis ，都可以用来解决分布式锁的问题。解决方案分布式锁实现的思路很简单，就是进来一个线城先占位，当别的线城进来操作时，发现已经有人占位了，就会放弃或者稍后再试。在 Redis 中，占位一般使用 setnx 指令，先进来的线程先占位，线程的操作执行完成后，再调用 del 指令释放位子。同时为了防止死锁，我们一般还要给锁加一个过期时间，到期了自动释放。" }, { "title": "JAVA", "url": "/posts/JAVA/", "categories": "笔记", "tags": "JAVA", "date": "2022-03-16 02:34:00 +0000", "snippet": "JAVA基础1. 面向对象三大特性Java有三大特性：封装，继承，多态。封装：利用抽象数据和基于数据的操作封装在一起，使其构成一个不可分割的独立实体。数据在被保护的抽象数据类型的内部，尽可能隐藏内部细节，只保留一些对外接口使之与外部发生联系，用户无需知道对象内部的细节，但可以通过对象对外提供的接口来访问该对象。继承：继承实现了IS-A关系，遵循里氏替换原则，即派生子类可以在程序中替换其基类对...", "content": "JAVA基础1. 面向对象三大特性Java有三大特性：封装，继承，多态。封装：利用抽象数据和基于数据的操作封装在一起，使其构成一个不可分割的独立实体。数据在被保护的抽象数据类型的内部，尽可能隐藏内部细节，只保留一些对外接口使之与外部发生联系，用户无需知道对象内部的细节，但可以通过对象对外提供的接口来访问该对象。继承：继承实现了IS-A关系，遵循里氏替换原则，即派生子类可以在程序中替换其基类对象。父类引用指向子类对象称为向上转型，比如List&lt;?&gt; list=new ArrayList&lt;&gt;();多态：多态分为编译时多态和运行时多态： 编译时多态主要指方法的重载； 运行时多态主要指程序中定义的对象引用所指向的具体类型在运行期间才确定。函数式编程指令式编程利用计算机的指令或者语法，告诉计算机一步步要做什么。而声明式方法就是告诉计算机要实现什么样的功能，而不关注计算机内部处理。面向对象编程时对数据进行抽象，而函数式编程是对行为进行抽象。函数式编程能让程序员写出更容易阅读的代码，这种代码更多的表现了业务逻辑，而不是从机制是如何实现。在写回调函数和事件处理器时，程序员不必再纠缠于匿名内部类的冗繁和可读性，函数式编程让事件处理系统变得更加简单。能将函数方便地传递也让编写惰性代码变得容易，只有在真正需要的时候，才初始化变量的值。其核心思想是使用不可变的值和函数，函数对一个值进行处理，映射成另一个值。对核心类库的改进主要包括集合类的API和新引入的流Stream。流使程序员可以站在更高的抽象层次上对集合进行操作。2. 数据类型包装类型Java有八个基本类型：boolean(1)，byte(8)，char(16)，short(16)，int(32)，float(32)，long(64)，double(64)。基本类型都有包装类型，基本类型与其对应的包装类型之间的赋值使用自动装箱与拆箱完成。缓存池编译器会在缓冲池范围内的基本类型（比如在Java8中Integer的缓存大小默认为-128～127）自动装箱的过程调用valueOf()方法，一次多个Integer实力使用自动装箱来创建并且值相同，那么就会引用相同对象。例如 new Integer(123)每次都会新建一个对象； Integer.valueOf(123)会用缓存池中的对象，多次调用会取得同一个对象的引用。String字符串概述(1) String 类声明为 final的，不可被继承。(2) String实现了Serializable接口：表示字符串是支持序列化的；实现了Comparable接口：表示String可以比较大小。底层存储JDK8及以前底层使用final char[]数组；JDK9及以后改用final byte[]数组。改用final byte[]是为了节省空间 (char占2个字节，而byte只用占用1个字节）Java中的String具有不可变性(1) 如下操作需要生成新的字符串，而不是修改原有的字符串 ﻿﻿对现有的字符串进行连接操作时； ﻿﻿对字符串重新赋值时； ﻿﻿调用String的replace()方法修改指定字符或字符串时。(2) 如何保证String的不可变性？ char[]使用final修饰，无法指向新的char[]数组； String内部没有提供修改的方法，保证内容不会变。 (3) 为什么将String设计为不可变？ 字符串在实际的开发中使用太频繁，为了提高执行效率，把字符串放到了方法区的字符串常量池当中； 不可变字符串，使得编译器可以让字符串共享； String的Hash值经常被使用，不变的特征可以使得hash值也不变，因此只需一次计算； 如果一个String对象已经被创建过，那么就会从String Pool（字符串常量池）中取得引用。只有String是不可变的才能使用字符串常量池。字符串常量池(1) 常量池中不会存在相同内容的常量；(2) 通过字符串字面量赋值时，数据是在常量池中；(3) String Pool是一个固定大小的 Hashtable（不会扩容） ﻿﻿数组+链表的哈希表（拉链法解决hash冲突）； ﻿﻿使用StringTableSize可设置StringTable的长度。String.intern()使用String.intern()可以保证相同内容的字符串变量引用同一内存对象。字符串拼接操作常量与常量的拼接结果在常量池 （原理是编译期优化）只要其中有一个是变量，结果就在堆中（变量拼接的原理是 String Builder)如果拼接的结果调用 intern()方法（将字符串添加到字符常量池中），则主动将常量池中还没有的字符串对象放入池中，并返回此对象地址。String、StringBuilder、StringBuffer:String 底层数组用 final 修饰，不可变。StringBuilder 底层数组没有用 final 修饰，可变;线程不安全，效率高(一般用的多)StringBuffer 底层数组没有用 final 修饰，可变;线程安全，效率低(一般用的少)参数传递Java的参数是以值的形式传入方法中，而不是引用传递。在将一个对象参数传入一个方法时，本质上是将对象的地址以值的方式传递到形参中。因此在方法中改变指针引用的对象，那么此时两个指针指向的是完全不同的对象，一方改变所指对象内容对另一方没有影响。但如果在方法中改变对象的字段值会改变原来对象的字段值，因为改变的是同一个地址指向的内容。3. 继承抽象类与接口1. 抽象类抽象类和抽象方法都使用abstract关键字进行声明。抽象类一般会包含抽象方法，抽象方法一定位于抽象类中。抽象类和普通类最大的区别是，抽象类不能被实例化，需要继承抽象类才能实例化其子类。2. 接口接口是抽象类的延伸。在Java8之前，他可以看作一个完全抽象的类，从Java8开始，接口也可以拥有默认的方法实现。接口的成员默认都是public的，并且不允许被定义为private或者protected。接口的字段默认是static和final的。Super访问父类的构造函数：可以使用super()函数访问父类构造函数，委托父类完成一些初始化的工作。访问父类的成员，如果子类重写了父类中的某个方法的实现，可以通过使用super关键字来引用父类方法的实现。函数式接口FunctionalFunction&lt;T, R&gt; 是 Java 8 中的一个函数式接口，用于表示接受一个输入参数 T，并返回一个结果 R 的函数。Function接口中有一个抽象方法apply，用于定义函数的逻辑。Function接口通常用于将数据进行转换、映射或者执行某种转换操作。SupplierSupplier&lt; T &gt; 是一个功能接口，表示无参传入，返回一个结果为T的函数。接口中有一个功能方法get()，不接受刃和参数。Supplier可以如下定义：Supplier&lt;T&gt; s = ()-&gt;{ //函数逻辑实现}s.get() //调用接口Accumulator在Java中，我们可以使用类来定义累加器。累加器类通常包含一个私有的累加结果变量和一些公共方法，用于更新和获取累加结果。静态绑定和动态绑定在Java中存在两种绑定方式，一种为静态绑定，又称作早期绑定。另一种就是动态绑定，亦称为后期绑定。区别 静态绑定发生在编译时期，动态绑定发生在运行时期。 使用private或static或final修饰的变量或方法，使用静态绑定；而可以被子类重写的方法则会根据运行时的对象进行动态绑定。 静态绑定可以使用类信息来完成，而动态绑定需要使用对象信息完成。 重载的方法使用静态绑定完成，重写的方法则用动态绑定完成。重载和重写 重写是子类对父类的允许访问的方法的实现过程进行重新编写, 返回值和形参都不能改变。即外壳不变，核心重写，重写的好处在于子类可以根据需要，定义特定于自己的行为。 也就是说子类能够根据需要实现父类的方法。 重载(overloading) 是在一个类里面，方法名字相同，而参数不同。返回类型可以相同也可以不同。每个重载的方法（或者构造函数）都必须有一个独一无二的参数类型列表。类的初始化考虑到以下继承关系：class A{ static int a;//类变量 String name; int id; //静态代码块 static{ a=10; System.out.println(\"这是父类的静态代码块\"+a); } //构造代码块 { id=11; System.out.println(\"这是父类的构造代码块id:\"+id); } A(){ System.out.println(\"这是父类的无参构造函数\"); } A(String name){ System.out.println(\"这是父类的name\"+name); }}class B extends A{ String name; static int b; static{ b=12; System.out.println(\"这是子类的静态代码块\"+b); } B(String name) { super(); this.name = name; System.out.println(\"这是子类的name:\"+name); }}public class Test666 {\tpublic static void main(String[] args) { \tB bb=new B(\"GG\");\t}}静态代码在类的初始化阶段就被初始化。所以当类加载的时候，首先执行父类A的静态代码块，然后执行子类B的静态代码块；当new一个B对象时，首先执行父类A的构造代码块，然后执行父类的构造方法，接着执行子类的构造代码块，最后执行子类B的构造方法。4. 泛型泛型的意义在于适用于多种数据类型，执行相同的代码。其本质是为了参数化类型。也就是说在泛型的使用过程中，操作的数据类型被指定位一个参数，这种参数可以用在类，接口方法中，分别称为泛型类，泛型接口和泛型方法。基本使用泛型类比如HashMap中的Node数组class Node&lt;K,V&gt;{ // 此处指定了两个泛型类型 private K key ; // 此变量的类型由外部决定 private V value ; // 此变量的类型由外部决定 public K getKey(){ return this.key ; } public V getValue(){ return this.value ; } public void setKey(K key){ this.key = key ; } public void setValue(V value){ this.value = value ; } } Node&lt;String, Integer&gt; node = new Node&lt;&gt;(); // 用String和Integer初始化泛型接口interface Info&lt;T&gt;{ // 在接口上定义泛型 public T getVar() ; // 定义抽象方法，抽象方法的返回值就是泛型类型 } class InfoImpl&lt;T&gt; implements Info&lt;T&gt;{ // 定义泛型接口的子类 private T var ; // 定义属性 public InfoImpl(T var){ // 通过构造方法设置属性内容 this.setVar(var) ; } public void setVar(T var){ this.var = var ; } public T getVar(){ return this.var ; } } Info&lt;String&gt; i = new InfoImpl&lt;String&gt;(\"GG\") ; // 通过子类实例化对象 泛型方法是在调用方法的时候声明泛型的具体类型。定义泛型方法的语法格式：调用泛型方法的语法格式：在定义泛型方法的时候，必须要在返回值的前面加一个 &lt;T&gt; 来声明这是一个泛型方法，持有一个泛型T，然后才可以用泛型T作为方法的返回值。Class&lt;T&gt; 的作用就是指明泛型的具体类型，而Class&lt;T&gt; 类型的变量可以用来创建泛型类的对象。泛型方法中，我们不知道具体的类型是什么，也不知道构造方法如何，因此没办法去new一个对象，但是可以用遍变量的newInstance方法创建对象，也就是利用反射去创建对象。泛型类要在实例化的时候就指明类型，如果想换一种类型，不得不重新new一次，可能不够灵活；而泛型方法可以在调用的时候指明类型，更加灵活。泛型的上下限为了解决泛型中隐含的类型转换问题，Java泛型加入了类型参数的上下边界机制。&lt;? extends A&gt;表示该类型参数可以是A(上边界)或者A的子类类型。&lt;? super A&gt;表示该类型参数可以是A(下边界)或者A的父类类型。如果有多个限制，则使用&amp;符号。类型擦除为了兼容之前的Java版本，Java泛型的实现采用了伪泛型的策略，即Java在语法上支持泛型，但是在编译阶段会进行类型擦除。将所有的泛型表示都替换为具体的类型。泛型擦除的原则是： 消除类型参数声明，即删除&lt;&gt;及其包围的部分。 根据类型参数的上下界推断并替换所有的类型参数位原生态类型：如果类型参数是无限制通配符或没有上下界限定则替换为Object，如果存在上下界限定则根据子类替换原则取类型参数的最左边限定类型（即父类）。 为了保证类型安全，必要时插入强制类型转换代码。 自动产生桥接方法，以保证擦除类型后的代码仍具有泛型的多态性。Java编译器是通过先检查代码中泛型的类型，然后在进行类型擦除，再进行编译。ArrayList&lt;String&gt; list1 = new ArrayList(); // 一般写成new ArrayList&lt;&gt;()ArrayList list2 = new ArrayList&lt;String&gt;();list1在初始化的时候指定了泛型，而后面new的时候只是在内存中开辟了一个存储空间，可以存储任何对象，真正涉及类型检查的是他们的引用。所以list2没有指定泛型的话就没有类型检查。泛型的多态类型的擦除会造成多态的冲突，而JVM解决的方法就是桥接方法。考虑到继承关系：class Pair&lt;T&gt; { private T value; public T getValue() { return value; } public void setValue(T value) { this.value = value; } }class DateInter extends Pair&lt;Date&gt; { @Override public void setValue(Date value) { super.setValue(value); } @Override public Date getValue() { return super.getValue(); } }在子类中我们将父类的泛型设定为Date，并且覆盖了父类的两个方法，本意是对父类的get和set方法进行重写。但是编译器在进行类型擦除的时候，会将父类指定的Date擦除成Object，但是子类方法的参数还会是Date类型。所以为了防止重写变成重载，JVM使用了桥接方法，在子类中生成对应的Object参数的set和get方法，在方法中调用自己重写的get和set方法，解决了类型擦除和多态的冲突。基本类型不能作为泛型在Java中，基本类型不能作为泛型，比如 List&lt;int&gt; 是不被允许的。因为在编译的时候进行类型擦除，List的原始类型变为Object，而Object不能存储int，只能引用Integer的值。但是由于Java提供了自动装箱拆箱的操作，所以可以使用 list.add(1) 。泛型也不能被实例化，因为泛型的构造方法不确定，找不到对应的字节码文件。但是可以通过反射的方法初始化T obj = clazz.newInstance();泛型中的静态方法和静态变量泛型类中的静态方法和静态变量不可以使用泛型类所声明的泛型类型参数。public class Test2&lt;T&gt; { public static T one; //编译错误 public static T show(T one){ //编译错误 return null; } }public class Test2&lt;T&gt; { public static &lt;T&gt; T show(T one){ //这是正确的 return null; } }因为泛型类中的泛型参数的实例化时在定义对象的时候指定的，而静态变量和静态方法不需要使用对象来调用。不过可以定义泛型方法，因为泛型方法使用的T时自己在方法中定义的T，而不是泛型类中的T。5. 反射反射是程序在运行时才知道要操作的类型，并可以获取到类的完整构造。通过反射机制，Java可以做到运行时类型识别，它允许运行中的Java程序对自身进行检查，能直接操作程序对内部属性和方法。反射就是把Java中的各种成分映射成一个个Java对象。例如：一个类有：成员变量、方法、构造方法、包等等信息，利用反射技术可以对一个类进行解剖，把个个组成部分映射成一个个对象。Class类Class类存在于java.lang包中，其实例表示Java应用程序运行时的类或接口。每个java类运行的时候都在JVM里表现为一个class对象，可以通过类名.class，类型.getClass()，Class.forName(“类名”)等方法获得class对象。数组也同样被映射为class对象的一个类，所有具有相同元素类型和位数的数组都应该共享该Class对象。基本类型也同样表现为class对象。反射APIJava类成员包括以下三类：属性字段，构造函数，方法。而反射API分为以下几类： Field 类：提供有关类的属性信息，以及对它的动态访问权限。它是一个封装反射类的属性的类。 Constructor 类：提供有关类的构造方法的信息，以及对它的动态访问权限。它是一个封装反射类的构造方法的类。 Method 类：提供关于类的方法的信息，包括抽象方法。它是用来封装反射类方法的一个类。 Class 类：表示正在运行的 Java 应用程序中的类的实例。 Object 类：Object 是所有 Java 类的父类。所有对象都默认实现了 Object 类的方法。实现原理 反射类及反射方法的获取，都是通过从列表中搜寻查找匹配的方法，所以查找性能会随类的大小方法多少而变化； 每个类都会有一个与之对应的Class实例，从而每个类都可以获取method反射方法，并作用到其他实例身上； 反射也是考虑了线程安全的，放心使用； 反射使用软引用relectionData缓存class信息，避免每次重新从jvm获取带来的开销； 反射调用多次生成新代理Accessor, 而通过字节码生存的则考虑了卸载功能，所以会使用独立的类加载器； 当找到需要的方法，都会copy一份出来，而不是使用原来的实例，从而保证数据隔离； 调度反射方法，最终是由jvm执行invoke0()执行。invoke0是个native方法，由jvm进行调用业务方法。从而完成反射调用功能。6. 注解基础注解annontation是Java5开始引入的新特性，他提供了一种安全的类似注解的机制，用来将任何的信息或元数据与程序元素进行关联，为程序元素加上更直观的说明。Java的注解是附加在代码中的一些元信息，用于一些工具在编译，运行时进行解析和使用，起到说明，配置的功能。注解不会也不影响代码的实际逻辑，仅仅起到辅助作用。注解的用处 生成文档，常见的有 @param，@return 等 跟踪代码的依赖性，实现替代配置文件的功能。 在编译时进行格式检查，比如 @override，放在方法前，如果这个方法并不是覆盖了超类的方法，则编译时就会检查出。注解的分类Java的注解可以分为三大类： 标准注解：包括@Override，@Deprecated，@SuppressWarning等，他们提供了一些常用元数据，可以帮助程序员更好组织和管理代码。 元注解：Java的元注解是用来注解其他注解的注解，它们包括@Retention，@Target，@Document，@Inherited等。其主要用来控制注解的作用域，保留期限，文档化等。 自定义注解：可以用于类，方法，变量，参数等程序元素，以提供额外的指令。原理注解的本质是一个继承了 Annotation 的特殊接口，其具体实现类是Java运行时产生的动态代理类。而我们通过反射获取注解时，返回的是Java运行时生成的动态代理对象 $Proxy1。通过代理对象调用自定义注解的方法，最终会调用 AnnotationInvocationHandler 的 invoke 方法。具体来说，Java注解实现原理可以分为以下四大步骤：定义Java注解Java的注解实际上就是一个接口，它可以包含多个成员变量和方法，其中的成员变量称为注解的元素@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface TestAnnotation { String value();}这个注解包含了一个属性value，表示注解的值。注解标记使用Java注解时，需要在对应的类，方法，字段上添加注解标记。@TestAnnotation(\"Hello\")public void doSomething { // method}编译期间处理Java编译器在编译源代码时，会扫描源代码中所有使用了注解的地方，并将注解处理成一个与注解元素相关的数据结构。这个数据结构包含了：注解的所有元素的值，并保存在编译后的Java字节码文件中，这个过程成为注解的编译时处理。在编译期间，Java编译器会将这些注解信息转换为Java字节码中的注解信息，并将这些信息存储在Class文件中。反射调用在运行时，可以通过Java反射机制读取和处理注解信息。Method method = MyClass.class.getMethod(\"doSomething\");TestAnnotation annotation = method.getAnnotation(TestAnnotation.class);String value = annotation.value();这里通过反射机制获取doSomething方法的注解，然后获取注解value的值。使用以Spring的@Autowired注解为例，某类上有@Autowired注解，Java可以通过反射机制知道这个属性上有这个注解，然后根据这个注解，执行spring事先写好的让这个注解的起作用的代码，然后完成注入。注解不能使用extends来继承，但是注解在编译后，编译器会自动继承Java.lang.annotation.Annotation接口。区别于注解的继承，被注解的子类继承父类注解可以用@Inherited。如果某个类使用了被@Inherited修饰的注解，则其子类将自动具有该注解。7. 异常异常的结构异常指不期而至的各种情况。他发生在程序运行期间，干扰了正常的指令流程。Java通过API中Throwable类的众多子类描述不同的异常。所以Java的异常都是对象，是Throwable子类的实例。异常关键字 try：用于监听。将要被监听的代码放在try语句块之内，当try语句块内发生异常的时候，异常被抛出。 catch：用于捕获异常。捕获try中抛出的异常。 finally：finally语句块总是会被执行。它主要用于回收在try中打开的资源，只有在finally块执行完成后，才会返回执行try或catch中的返回或抛出语句。 throw：抛出异常/ throws：用在方法签名中，用于声明该方法可能会抛出异常。异常的申明在Java中，当前执行的语句必须属于某个方法，Java解释器调用main方法执行开始执行程序。若方法中存在检查异常，如果不对其捕获，那必须在方法头中显式声明该异常，以便于告知方法调用者此方法有异常，需要进行处理。 在方法中声明一个异常，方法头中使用关键字throws，后面接上要声明的异常。若是父类的方法没有声明异常，则子类继承方法后，也不能声明异常。异常处理机制Java处理异常主要依靠异常表。异常表中包含了一个或多个异常处理者(Exception Handler)的信息，这些信息包含如下 from 可能发生异常的起始点 to 可能发生异常的结束点 target 上述from和to之前发生异常后的异常处理者的位置 type 异常处理者处理的异常的类信息当异常发生的时候： JVM会在当前出现异常的方法中，查找异常表，是否有合适的处理者来处理； 如果当前方法的异常表不为空，并且符合异常处理者的from和to节点，并且type也匹配，则JVM调用位于target的调用者来处理； 如果上一条未找到合适的处理者，则继续查找异常表中的剩余条目； 如果当前方法的异常表无法处理，则继续查找刚刚调用该方法的调用处，并重复上面的操作。 如果所有的栈帧都被弹出，仍然没有处理，则会跑给当前的Thread，Thread会终止； 如果当前Thread为最后一个非守护线程，且未处理异常，则会导致JVM终止运行。Java容器1. CollectionSet TreeSet 基于红黑树实现，无序，不可重复，自动排序； 存放在TreeSet中相当于存放到TreeMap中的key部分。 HashSet 基于哈希表实现，无序，不可重复，支持快速查找。 LinkedHashSet 基于双向链表实现，具有 Hashset 的查找效率。 Queue LinkedList 可以实现双向队列。 PriorityQueue 基于堆结构实现，可以实现优先队列。 ListList在Java里面是一个接口，继承自Collection。为了追求效率，ArrayList和LinkedList都没有实现同步，vector有同步。ArrayList 底层结构是Object数组，元素可以为null； 相比于原生的数组在初始化的时候必须指定大小，ArrayList实现了动态扩容： new—个ArravList 的时候，默认会有一个空的Object 数组，大小为0，第一次add 数据的时候，会给这个数组一个初始化的大小，默认为 10； 每一次add，都会先去计算这个数组够不够空间，够就追加上去，不够就扩容； 在源码里面，有个grow方法，每一次扩容原来的1.5倍，扩完容后，调用arraycopy来对数组进行拷贝。 日常开发中用的最多，因为遍历需求高。 LinkedListLinkedList同时实现了List接口和Deque接口，因为它既可以看作一个顺序容器们也可以看作一个队列。其底层数据结构是双向链表，元素可以为null。QueueQueue可以通过LinkedList实现，队列的插入，删除，检视可以使用自带collection的方法，也可以用队列实现的方法。前者失败会抛出异常，后者会返回特殊值。Vector底层结构是数组，线程安全，扩容的时候直接扩两倍容。ArrayList和LinkedList区别 线程安全 二者都是线程不安全的。 底层数据结构 ArrayList底层使用的是Objiect[]数组; Linkedlist底层使用的是双向链表数据结构。 插入和删除是否受元素位置影响 ArrayList采用数组存储，所!以插入和删除元素的时间复杂度受元泰位置的影响； Linkedlist 采用链表进行存储。 是否支持随机快速访问 ArrayList 支持 get(index) 方法； Linkedlist 不支持高效的随机元素访问。 内存空间占用 ArravList 的空间浪费主要体现在list列表的结尾会预留一定的容量空间； Linkedlist 的空间花费则体现在它的每个元素都需要消耗比ArrayList更多的空间，用于存放直接后继和直接前驱以及数据。 ArrayList和Vector区别两者都用Object[]存储，但是ArrayList线程不安全，vector线程安全。PriorityQueue优先队列，其作用是保证每次取出的元素都是队列中权值最小的，元素大小的判断可以通过构造比较器。Java中的优先队列实现了Queue接口，不允许放入null元素，其通过堆实现，具体说是通过完全二叉树实现的小顶堆。2. MapHashMapHashMap实现了Map接口，即允许放入key为null的的元素，也允许插入value为null的元素，该容器不保证元素顺序，根据需要可能会对元素重新哈希。HashMap的参数如下：// 最开始的容量，必须是 2 的次方，这里即 2 的 4 次方static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16// 最大容量static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;// 负载static final float DEFAULT_LOAD_FACTOR = 0.75f;// list to tree 的临界值static final int TREEIFY_THRESHOLD = 8;// 删除冲突节点后，hash相同的节点数目小于这个数，红黑树就恢复成链表static final int UNTREEIFY_THRESHOLD = 6;// 扩容的临界值static final int MIN_TREEIFY_CAPACITY = 64;// 存储元素的数组transient Node&lt;k,v&gt;[] table; HashMap 底层是一个数组； 在Java8之前，数组中每个元素是一个单向链表(即，采用拉链法解决哈希冲突)，单链表的节点每个节点是 Node&lt;K, V&gt; 类型； Java8之后，对 HashMap 底层数据结构(单链表)进行了改进，如果单链表元素超过8个，则将单链表转变为红黑树；如果红黑树节点数量小于6时，会将红黑树重新变为单链表。 同一个单链表中所有Node的hash值不一定一样，但是他们对应的数组下标一定一样； 数组下标利用哈希函数/哈希算法根据 hash值计算得到的； HashMap 是数组和单链表的结合体 数组查询效率高，但是增删元素效率较低； 单链表在随机增删元素方面效率较高，但是查询效率较低； HashMap 将二者结合起来，充分它们各自的优点； HashMap 特点 无序、不可重复； 无序: 因为不一定挂在那个单链表上了 为什么不可重复？ 通过重写 equals 方法保证的。 数组扩容 resize()方法用于初始化数组或数组扩容，每次扩容后，容量为原来的2倍，并进行数据迁移。 HashMap扩容HashMap通过调用Key的hashCode()方法来得到hash值，然后通过Hash算法的高位运算和取模运算来定位该键值对的存储位置。如果两个key定位到了同一个位置，则发生了Hash碰撞，Hash计算的结果越分散，Hash碰撞的概率越小。3. HashMap，HashTable，ConcurrentHashMap线程安全：HashMap 是线程不安全的。在多线程条件下，容易导致死循环。JDK 1.8 HashMap 采用数组 + 链表 + 红黑二叉树的数据结构，优化了 1.7 中数组扩容的方案，解决了 Entry 链死循环和数据丢失问题。但是多线程背景下，put 方法存在数据覆盖的问题。HashTable是线程安全的。在ConcurrentHashMap中，无论是读操作还是写操作都能保证很高的性能：在进行读操作时(几乎)不需要加锁，而在写操作时通过锁分段技术只对所操作的段加锁而不影响客户端对其它段的访问。特别地，在理想状态下，ConcurrentHashMap 可以支持 16 个线程执行并发写操作（如果并发级别设为16），及任意数量线程的读操作。ConcurrentHashMap的高效并发机制是通过以下三方面来保证的： 使用volatile保证当Node中的值变化时对于其他线程是可见的，因为volatile关键字，会在读指令前插入读屏障，可以让高速缓存中的数据失效，重新从主内存加载数据； 使用table数组的头结点作为synchronized的锁来保证写操作的安全。synchronized是互斥锁，有且只有一个线程能够拿到这个锁，从而保证了put操作是线程安全的； 当头结点为null时，使用CAS操作来保证数据能正确的写入。所谓的CAS，即即compareAndSwap，执行CAS操作的时候，将内存位置的值与预期原值比较，如果相匹配，那么处理器会自动将该位置值更新为新值，否则，处理器不做任何操作。Java并发1. 基础为什么需要多线程CPU，内存，I/O设备的速度有极大的差异，为了合理利用CPU的高性能，平衡三者的速度差异，计算机做出了一下优化： CPU增加了缓存，以平衡与内存的速度差异，但是也导致了可见性问题； 操作系统增加了线程，进程，以分时复用CPU，进而均衡CPU与I/O设备的速度差异，但是导致了原子性问题； 编译程序优化指令执行顺序，以便合理利用缓存，但是导致了有序性问题。并发编程重要特性原子性对于一个或多次操作，要么所有的操作全部得到执行并且不会收到任何因素的干扰而中断，要么都不执行，用synchronized关键字来保证。可见性当一个线程对共享变量进行了修改，那么另外的线程都是立即看到修改后的最新值，用volatile字段保证共享变量的可见性。有序性代码在执行过正中的先后顺序，在编译期间，代码未必顺序执行，而volatile关键字可以禁止指令进行重排优化。Java如何解决并发 volatile，synchronized和final关键字； Happens-before原则。Happens-before规则JVM规定了先行发生原则，让一个操作无需控制就能先于另一个操作完成。单一线程原则：在一个线程内，在程序前面的操作先行发生于后面的操作；管理锁定规则：一个unlock操作先行发生于后面对同一个锁的lock操作；volatile变量规则：对一个volatile变量的写操作先行发生于后面对这个变量的读操作；线程启动规则：Thread对象的start()方法调用先行发生于此线程的每一个动作；线程加入规则：Thread对象的结束先行发生于join()方法返回；线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生；对象终结规则：一个对象的初始化完成先行发生于它的finalize()方法的开始；传递性：如果操作A先行发生于B，操作B先行发生于C，那么操作A先行发生于操作C。线程安全实现方法 互斥同步：synchronized和ReentrantLock； 非阻塞同步：CAS，AtomicInteger和ABA； CAS：比较并交换，是硬件支持的原子性操作，CAS指令有三个操作数，内存地址V，旧的预期值A和新值B。当执行操作时，只有当V的值等于A，才将V的值更新为B。 ABA：通过控制变量值的版本来保证CAS的正确性。 无同步方案：栈封闭，线程本地存储和可重入代码。 栈封闭：多个线程访问同一个方法的局部变量时，不会出现线程安全问题，因为局部变量存储在虚拟机栈中，属于线程私有。 线程本地存储：如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证，就可以把共享数据的可见范围限制在同一个线程之内，这样无需同步也能保证线程之间不出现数据争用的问题。 2. 线程线程状态转换线程使用方式实现Runnable接口：需要实现run()方法，通过Thread调用start()方法来启动线程。public class MyRunnable implements Runnable { public void run() { // ... }}public static void main(String[] args) { MyRunnable instance = new MyRunnable(); Thread thread = new Thread(instance); thread.start();}实现Callable接口：与Runnable相比，Callable可以有返回值，返回值通过FutureTask进行封装。public class MyCallable implements Callable&lt;Integer&gt; { public Integer call() { return 123; }}public static void main(String[] args) throws ExecutionException, InterruptedException { MyCallable mc = new MyCallable(); FutureTask&lt;Integer&gt; ft = new FutureTask&lt;&gt;(mc); Thread thread = new Thread(ft); thread.start(); System.out.println(ft.get());}继承Thread类：同样是实现run()方法，因为Thread类也实现了Runnable接口。当调用start()方法启动一个线程时，虚拟机会将该线程放入就绪队列中等待被调度，当一个线程被调度时会执行该线程的run()方法。public class MyThread extends Thread { public void run() { // ... }}public static void main(String[] args) { MyThread mt = new MyThread(); mt.start();}3. 锁Java中的锁分为显示锁和隐式锁。隐式锁由synchronized关键字实现，而显示锁是由实现了Lock接口和AQS框架等等类来实现。锁的分类从宏观上看，锁的分类可以分为乐观锁与悲观锁；共享锁和排他锁，可重入锁和不可重入锁等。乐观锁和悲观锁乐观锁就是对数据冲突保持乐观态度，认为不会有其他线程同时修改数据。因此乐观锁不会上锁，只是在更新数据的时候判断是否有其他线程更新，如果没有其他线程修改则更新数据，有其他线程同时更改数据，则放弃数据。悲观锁对数据冲突持悲观态度，认为总有数据发生冲突。因此他以一种预防的态度，先行把数据锁住，直到操作完成才释放锁，在此期间其他线程无法操作数据。自旋锁线程如果没有争取到资源时，就会进入阻塞状态，当持有锁的线程释放了锁以后，才可以去竞争，这样会浪费大量性能在阻塞和唤醒的切换上，为了避免这点，在没有获得锁的时候，就不进入阻塞，而是不断循环检测锁是否被释放，这就是自旋。公平锁和非公平锁公平锁是指多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中第一个线程才能获得锁。优点是等待锁的线程不会饿死，缺点是整体吞吐量比非公平锁妖帝，开销较大。非公平锁是多个线程加锁时直接尝试获取锁，获取不到才会到等待队尾等待。如果锁刚好够用，那么这个线程可以无需阻塞直接获取锁。优点是可以减少唤起线程的开销，整体吞吐率较高，缺点是可能有线程会饿死。可重入锁不可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁，不会因为之前已经获取过还没释放而阻塞，可以避免死锁。和可重入锁相反，再进入该线程的内层方法不会自动获取锁。共享锁和排他锁指该锁可以被多个线程持有，如果线程T对数据A加上共享锁后，其他线程只能对A再加共享锁，不能加排他锁。获得共享锁的线程只能读数据，不能改数据。指该锁一次只能被一个线程持有。如果线程T对数据A加上排他锁后，其他线程不能对A再加任何类型的锁。获得排他锁的线程既能读数据也能改数据。锁状态无锁不锁住资源，多个线程中有一个能修改资源成功，其他线程会重试。偏向锁一段同步代码，共享资源一直被一个线程访问，那么该线程自动获取锁，降低代价。轻量级锁当锁是偏向锁的时候，被另外的线程访问，偏向锁回升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。重量级锁互斥锁，会被阻塞。Java的锁升级由锁状态头控制。死锁一般来说，要出现死锁问题需要满足以下条件： 互斥条件：一个资源每次只能被一个线程使用。 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。 不剥夺条件：进程已获得的资源，在未使用完之前，不能强行剥夺。 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。只要破坏死锁 4 个必要条件之一中的任何一个，死锁问题就能被解决。4. Synchronized关键字Synchronized关键字解决的是多个线程之间访问资源的同步性，他可以保证被他修饰的方法或者代码块在任意时刻只能有一个线程执行，在java1.5以前，synchronized属于重量级锁，效率低下。在Java中，每个对象都有一把锁，放置于对象头中，用于记录当前对象被哪个线程持有。synchronized被编译后，使用的是monitor和monitorExit两个字节码指令，而这两个字节码指令以来操作系统中的mutex lock实现。synchronized关键字作用通过使用内置锁，来实现对共享变量的同步操作，进而解决了对共享变量操作的原子性，保证了其他线程对共享变量的可见性、有序性，从而确保在并发情况下的线程安全。同时synchronize是可重入的锁，避免了同一个线程重复请求自身一获取的锁时出现死锁问题。Synchronized字段使用方式 修饰实例方法：作用于当前对象实例this加锁，进入同步代码块前需要先获得该对象实例的锁。 修饰静态方法：也就是给当前类的Class对象加锁，会作用于类的所有对象实例，进入同步代码块之前要先获得当前class的锁。 修饰代码块：指定加锁的对象，给对象/类加锁synchronized(this｜Object)表示进入同步代码块要获得给定对象的锁。与lock的区别 synchronized是Java的关键字，而lock是一个接口； synchronized以获取锁的线程执行完成同步代码，释放锁，如果线程执行异常，jvm会让线程释放锁。而lock在finally中必须释放锁，不然容易造成死锁； 对于synchronized关键字，假设A线程获得锁，B线程等待。如果A线程阻塞，B线程会一直等待；Lock有多个锁获取的方式可以尝试获得锁，线程可以不用一直等待； synchronized关键字无法判断锁状态，而lock可以判断； synchronized锁是可重入，不可中断，非公平的锁，lock是可重入，可判断，可公平的锁； synchronized关键字支持少量同步，而lock可以实现大量同步。5. volatile概念Volatile是Java提供的一种轻量级的同步机制。Java 语言包含两种内在的同步机制：同步块（或方法）和 volatile 变量，相比于synchronized（synchronized通常称为重量级锁），volatile更轻量级，因为它不会引起线程上下文的切换和调度。但是volatile变量的同步性较差（有时它更简单并且开销更低），而且其使用也更容易出错。Java内存模型JMM规定，线程对变量的所有操作都必须在本地内存进行，不能直接读写主存变量。变量从主存于本地内存之间的交互，由8种操作完成。线程的共享变量存储在主内存中，每个线程可以吧变量的副本存在本地内存中，这样可能造成变量不一致。volatile变量特性(1) 保证可见性，不保证原子性当写一个volatile变量时，JMM会把该线程本地内存中的变量强制刷新到主内存中去，这个写会操作会导致其他线程中的缓存无效。其解决了内存不一致问题，当变量声明为volatile时，就告诉JMM该变量是共享且不稳定的，每一次使用都要从主存中读取。(2) 禁止指令重排重排序在单线程下一定能保证结果的正确性，但是在多线程环境下，可能发生重排序，影响结果，使用volatile关键字修饰共享变量便可以禁止这种重排序。若用volatile修饰共享变量，在编译时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。volatile原理volatile可以保证线程可见性且提供了一定的有序性，但是无法保证原子性。在JVM底层volatile是采用“内存屏障”来实现的。与Synchronized关键字区别volatile关键字是线程同步的轻量级实现，性能更好；volatile关键字只能用于变量而synchronized关键字可以修饰方法和代码块；volatile只保证数据的可见性，不保证原子性，而synchronized关键字两者都可以保证；volatile解决变量在多个线程之间的可见性，而synchronized解决多个线程之间资源访问的同步性。6. finalfinal可以修饰类，修饰方法，修饰参数以及修饰变量。修饰类当某个类的整体定义为final时，就表明了你不能打算继承该类，而且也不许别人这么做，即这个类不能有子类。修饰方法父类final方法不能被子类重写，但是可以重载。修饰参数Java允许在参数列表中以声明的方式将参数指名为final，即无法在方法中更改参数引用所指的对象。这个特性主要用来向匿名内部类传递数据。修饰变量final修饰的字段不一定都是编译器常量，只是初始化之后无法在改变。7. CAS，UnsafeCASCAS的全称是Compare-And-Swap，是一条CPU的原子指令。其作用是让CPU先进行比较两个值是否相等，然后原子性地更新某个位置的值。其靠硬件实现。CAS操作需要输入预期的旧值和新值，在操作期间先比较下旧值有没有发生变化，如果没有发生变化，才交换成新值，否则不做操作。CAS是原子性的，所以多线程并发使用CAS更新数据时，可以不使用锁。在Java中，提供了AtomicInteger原子类，其底层基于CAS进行更新数据的。CAS问题CAS方式为乐观锁，Synchronized为悲观锁。 ABA问题 因为CAS在需要操作值的时候，检查值有没有发生变化，没有变化则更新。但是如果一个值原来是A，后来被改成了B，最后又变成了A，那么使用CAS进行检查时就会发现它的值没有发生变化，但实际上却变化了。ABA解决思路就是在变量前加上版本号，每次更新就把版本号加一。 循环时间长开销过大 自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令，那么效率会有一定提升。pause指令有两个作用：第一他可以延迟流水线执行命令，使CPU不会消耗过多执行资源，第二它可以避免在退出循环的时候因内存顺序冲突而引起CPU流水线被清空，从而提高CPU执行效率。 只能保证一个共享变量 当对一个共享变量进行操作时，我们可以使用CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁。 从Java 1.5开始，JDK的Atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法的作用是首先检查当前引用是否等于预期引用，并且检查当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。Unsafe类Unsafe是位于sun.misc包下的一个类，主要提供一些用于执行低级别，不安全操作的方法。如直接访问系统内存资源，自主管理内存资源等，这些方法可以提升Java运行效率，增强Java语言底层资源操作能力。原子类JDK中提供了12个原子操作类。原子更新基本类型 AtomicInteger：原子更新整型； AtomicBoolean：原子更新布尔类型； AtomicLong：原子更新长整型。原子更新数组 AtomicIntegerArray：原子更新整数组里的元素； AtomicLongArray：原子更新长整形数组里的元素； AtomicReferenceArray：原子更新引用数组里的元素。原子更新引用类型 AtomicReference：原子更新引用类型； AtomicStampedReference：原子更新引用类型，内部使用Pair来存储元素值及其版本号； AtomicMarkableReference：原子更新带有标记位的引用类型。原子更新字段类 AtomicIntegerFiledUpdater：原子更新整型字段的更新器； AtomicLongFieldUpdater：原子更新整型字段的更新器； AtomicReferenceFieldUpdater：更新的字段必须要用volatile修饰。8. JUC原子类和锁LockSupportLockSupport是一个线程阻塞工具类，所有的方法都是静态方法。主要有两类方法park和unpark。当调用park时，表示阻塞当前线程，直到unpark方法调用或当前线程被中断，park方法才会返回。当调用unpark时，必须把等待获得许可的线程作为参数进行传递，来唤醒处于阻塞状态的线程。其和显式锁、隐式锁等待唤醒的区别 park和unpark方法的调用不需要获取锁。 先调用unpark方法后调用park方法依然可以唤醒。 park方法响应中断，线程被中断后park方法直接返回，但是不会抛InterruptedException异常。 unpark方法是直接唤醒指定的线程。LockSupport.park阻塞线程，并且该线程在下列情况发生之前都会被阻塞： 调用unpark函数，释放该线程的许可； 该线程被中断； 设置的时间到了，当time设为0，则表示无限等待，直到unpark发送。park函数有两个版本，区别在于无参或传入block参数。LockSupport.unpark如果传入的线程在park上受阻塞，则将它解除其阻塞状态，否则，保障下一次调用park不会受阻塞。如果给定的线程尚未启动，则无法保证效果。线程同步使用wait/notify实现同步时，必须先调用wait，后调用notify。如果先调用notify，再调用wait，则无法起作用，线程会一直阻塞；使用park/unpark实现线程同步时，如果先调用unpark再调用park，线程仍然能正确实现同步，不会被阻塞，跳过park继续执行后续内容，不会造成由wait/notify顺序不当引起的阻塞，因此park/unpark更灵活。Object.wait()和LockSupport.park()的区别 wait()方法需要在synchronized块中执行，park()方法可以在任意地方执行； wait()方法声明抛出了中断异常，调用者需要捕获或者再抛出，park()不需要捕获异常； wait()不带超时的时候，需要另一个线程执行notify()唤醒，但不一定执行后续内容； park()不带超时的时候，需要另一个线程执行unpark()唤醒，一定会执行后续内容。AQSAQS是一个用来构建锁和同步器的框架，其内部使用同步队列来解决实现同步器时的一些细节。使用AQS能简单且高效地构造出应用广泛的大量同步器，比如ReentrantLock，Semaphore， 其他诸如ReentrantReadWriteLock，SynchronousQueue，FutureTask都是基于AQS的。核心思想AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制。这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。AQS使用一个int成员 state 变量来表示同步状态，通过内置的FIFO队列来完成获取资源线程的排队工作。AQS使用CAS对该同步状态进行原子操作实现对其值的修改。资源共享方式AQS定义两种资源共享方式 Exclusive(独占)：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁： 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的 Share(共享)：多个线程可同时执行，如Semaphore/CountDownLatch。Semaphore、CountDownLatCh、 CyclicBarrier、ReadWriteLock 我们都会在后面讲到。ReentrantReadWriteLock 可以看成是组合式，因为ReentrantReadWriteLock也就是读写锁允许多个线程同时对某一资源进行读。不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护(如获取资源失败入队/唤醒出队等)，AQS已经在上层已经帮我们实现好了。AQS参数AQS使用了模版方法模式，使用者继承AQS并重写指定的方法。isHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。tryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。tryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。tryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。这些方法的实现必须是内部线程安全的。AQS数据结构AQS底层使用CLH队列，其是一个虚拟的双向队列(虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系)。在AQS中所有等待锁的线程都会被包装成Node扔到一个同步队列中。每个结点包含了一个thread类型的引用，并且每个结点还存在一个状态waitStatus，具体状态如下 CANCELLED，值为1，表示当前的线程被取消。 SIGNAL，值为-1，表示当前节点的后继节点包含的线程需要运行，需要进行unpark操作。 CONDITION，值为-2，表示当前节点在等待condition，也就是在condition queue中。 PROPAGATE，值为-3，表示当前场景下后续的acquireShared能够得以执行。 值为0，表示当前节点在sync queue中，等待着获取锁。Sync queuesync queue，同步队列，是一个双向链表，我们使用prev、next属性来串联节点。但是在这个同步队列中，我们一直没有用到nextWaiter属性，即使是在共享锁模式下，这一属性也只作为一个标记，指向了一个空节点，因此，在sync queue中，我们不会用它来串联节点。Condtion queue条件队列不是必须的，每创建一个Condtion对象就会对应一个Condtion队列，每一个调用了Condtion对象的await方法的线程都会被包装成Node扔进一个条件队列中:每一个Condition对象对应一个Conditon队列，每个Condtion队列都是独立的，互相不影响的。在上图中，如果我们对当前线程调用了notFull.await(), 则当前线程就会被包装成Node加到notFull队列的末尾。一般情况下，等待锁的同步队列和条件队列是相互独立的，彼此之间没有任何关系，但是当调用某个条件队列的signal方法时，会将某个或所有等待在这个条件队列中的线程唤醒，被唤醒的线程和普通线程一样要去争锁，如果没有抢到则同样要被加到等待锁的同步队列中，此时结点就一个一个的从条件队列转移到同步队列中。总结对于AbstractQueuedSynchronizer的分析，最核心的就是sync queue的分析。 每一个结点都是由前一个结点唤醒。 当结点发现前驱结点是head并且尝试获取成功，则会轮到该线程运行。 condition queue中的结点向sync queue中转移是通过signal操作完成的。 当结点的状态为SIGNAL时，表示后面的结点需要运行。ReentrantLockReentrantLock实现了Lock接口，Lock接口中定义了lock与unlock相关操作，并且还存在newCondition方法，表示生成一个条件。ReentrantLock是一种悲观锁，它总是假设竞争条件总是会发生，所以它同一时刻只有一个线程能获得锁。其支持公平和非公平性的获取锁，内部默认是非公平锁, 因为非公平锁的吞吐量会比公平锁高。由于ReentrantLock基于AQS实现的，所以它支持三种方式获取锁: lock(): 不支持中断的获取锁； lockInterruptibly(): 响应中断地获取锁； tryLock(long timeout, TimeUnit unit): 响应中断并且支持超时获取锁。ReentrantReadWriteLockReentrantReadWriteLock底层是基于ReentrantLock和AQS来实现的，ReentrantReadWriteLock是一种乐观锁，它假设竞争条件并不会经常发生，所以同一时刻能让多个线程执行。它将读写分离，在进行读操作时，多个线程可以同时获取锁，这样能更好的提高并发度。其有以下特性： 公平性: 与ReentrantLock一样，ReentrantReadWriteLock内部也是支持公平性和非公平性锁，默认是非公平性的锁； 可重入: ReentrantReadWriteLock支持一个线程多次获取锁； 读写分离: ReentrantReadWriteLock内部维护两个锁，一个是读锁，另外一个是写锁. 在读多写少的情况下，ReentrantReadWriteLock能发挥更大的并发度。因为ReentrantReadWriteLock支持多个读线程同时获取锁。ReentrantReadWriteLock的读写规则: 当一个写线程获得锁后, 其他线程不能获取锁. 当读线程获得锁后, 其他的读线程可以获得锁，但是写线程不能； 锁降级: 当一个线程持有写锁后, 再获取读锁, 然后释放写锁, 这个过程称为一个锁的降级。ReentrantReadWriteLock不支持锁的升级, 因为锁的升级有可能带来竞争条件的问题。AQS中的状态int类型有32位, ReentrantReadWriteLock将高16位作为读状态，低16位作为写状态，这样每次通过一定的位运算来获取高16位或者低16位。9. JUC集合ConcurrentHashMapHashtable是线程安全的，但是效率低下，因为使用了synchronized关键字对put进行加锁，而synchronized关键字是对整个对象进行加锁，所以在put操作下会把整张表锁住，所以效率低下。在JDK1.7之前，ConcurrentHashMap是通过锁分段机制来实现的，所以最大并发度受到Segment个数的限制，而在JDK1.8中，选择了与HashMap类似的数组+链表+红黑树的方式实现，而加锁则采用CAS和Synchronized实现。数据结构在java1.7之前，concurrentHashMap是一个Segment数组，Segment通过继承ReentrantLock来进行加锁，所以每次加锁锁住的都是一个segment，这样只要保证每个segment是线程安全的即可。而在 Java8 之后，concurrentHashMap的结构和 HashMap 基本一样，不过它要保证线程安全性，所以在源码上要复杂一些。并发性分析添加节点的操作 put 和删除节点的操作 remove 都是要加 segment 上的独占锁的，所以它们之间自然不会有问题，而由于get操作不会加锁，所以并发问题主要出现在get操作中同时发生put或remove的情况。 put 操作的线程安全性。 初始化槽，使用了 CAS 来初始化 Segment 中的数组。 添加节点到链表的操作是插入到表头的，所以，如果这个时候 get 操作在链表遍历的过程已经到了中间，是不会影响的。当然，另一个并发问题就是 get 操作在 put 之后，需要保证刚刚插入表头的节点被读取，这个依赖于 setEntryAt 方法中使用的 UNSAFE.putOrderedObject。 扩容。扩容是新创建了数组，然后进行迁移数据，最后面将 newTable 设置给属性 table。所以，如果 get 操作此时也在进行，那么也没关系，如果 get 先行，那么就是在旧的 table 上做查询操作；而 put 先行，那么 put 操作的可见性保证就是 table 使用了 volatile 关键字。 remove 操作的线程安全性。 如果 remove 破坏的节点 get 操作已经过去了，那么这里不存在任何问题。 如果 remove 先破坏了一个节点，分两种情况考虑。 1、如果此节点是头节点，那么需要将头节点的 next 设置为数组该位置的元素，table 虽然使用了 volatile 修饰，但是 volatile 并不能提供数组内部操作的可见性保证，所以源码中使用了 UNSAFE 来操作数组。2、如果要删除的节点不是头节点，它会将要删除节点的后继节点接到前驱节点中，这里的并发保证就是 next 属性是 volatile 的。 CopyOnWriteArrayListCopyOnWriteArrayList实现了List接口，List接口定义了对列表的基本操作，同时也实现了RandomAccess接口，表示可以随机访问，同时实现了Cloneable接口，表示可克隆；同时也实现了Serializable接口，表示可被序列化。类的属性CopyOnWriteArrayList的部分属性如下（transient是Java的关键字，用来表示一个成员变量不是该对象序列化的一部分）public class CopyOnWriteArrayList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable { // 版本序列号 private static final long serialVersionUID = 8673264195747942595L; // 可重入锁 final transient ReentrantLock lock = new ReentrantLock(); // 对象数组，用于存放元素 private transient volatile Object[] array; // 反射机制 private static final sun.misc.Unsafe UNSAFE; // lock域的内存偏移量 private static final long lockOffset; static { try { UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; k = CopyOnWriteArrayList.class; lockOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(\"lock\")); } catch (Exception e) { throw new Error(e); } }}其内部还包括一个内部类COWIterator，表示迭代器，其也有一个Object数组作为CopyOnWriteArrayList数组的快照，这种快照风格的迭代器方法在创建迭代器时使用了对当前数组的引用。此数组在迭代器的生存周期内不会更改，因此不可能发生冲突。创建迭代器以后，迭代器就不会反映列表的添加、移除或者更改。在迭代器上进行的元素更改操作(remove、set 和 add)不受支持。构造函数CopyOnWriteArrayList有三种构造函数，默认无参构造，CopyOnWriteArrayList(Collection&lt;? extends E&gt;) 型构造函数和 CopyOnWriteArrayList(E[]) 构造函数。CopyOnWriteArrayList(Collection&lt;? extends E&gt;) 构造函数用来创建一个按照collection的迭代器返回元素的顺序包含指定collection的元素列表。该构造函数的处理流程如下： 判断传入的集合c的类型是否为CopyOnWriteArrayList类型，若是，则获取该集合类型的底层数组Object[]，并且设置当前CopyOnWriteArrayList的数组，进入步骤③；否则，进入步骤②。 将传入的集合转化为数组elements，判断elements的类型是否为Object[]类型，若不是，则将elements转化为Object类型的数组。 设置当前CopyOnWriteArrayList的数组为elements。CopyOnWriteArrayList(E[]) 构造函数该构造函数用于创建一个保存给指定数组的副本的列表。public CopyOnWriteArrayList(E[] toCopyIn) { // 将toCopyIn转化为Object[]类型数组，然后设置当前数组 setArray(Arrays.copyOf(toCopyIn, toCopyIn.length, Object[].class));}copyOf函数该函数用于复制指定的数组，截取或用null填充，使得副本有指定的长度。add函数此函数用于将指定的元素添加到此列表的尾部，处理流程如下 获取锁，获取当前的Object数组，获取Object数组的长度为length。 根据Object数组复制一个长度为length+1的Object数组为newElements。 将下标为length的数组元素newElements[length]设置为元素e，在设置当前Object[]为newElements，释放锁，返回。这样就完成了元素的添加。set函数该函数用于指定元素替代此列表指定位置上的元素，也是基于数组的复制来实现的。remove函数此函数用于移除此列表指定位置上的元素。 获取锁，获取当前的Object数组elements，获取数组的长度为length。获取索引的值elements[index]，计算需要移动的元素个数(length - index - 1)，如果个数为0，则表示移除的是数组最后一个元素，复制elements数组，复制长度为length-1，然后设置数组/ 如果移除的不是最后一个元素，则先复制index索引前的元素，再复制index索引后的元素，然后设置数组。 释放锁，返回旧值。总结 该方法是线程安全的。 在add()的时候会加Lock锁，然后复制出个新的数组，往新的数组里面add真正的元素，最后把array的指向改变为新的数组。 get()方法或者是size()方法只是获取array所指向的元素或者大小，读不加锁，但是写加锁。 很耗费内存，每次set，add都会复制一个数组出来。 只能保证数据最终一致性，不能保证数据的实时一致性。 假设有两个线程，A 去读CopyOnWriteArrayList 的数据还没读完，如果现在线程B把这个List给清空了，线程 A此时还是可以把剩余数据给读出来。 线程池1. 线程和进程的区别进程是对运行时程序的封装，是系统进行资源调度和分配的的基本单位，实现了操作系统的并发；线程是进程的子任务，是CPU调度和分派的基本单位，用于保证程序的实时性，实现进程内部的并发；线程是操作系统可识别的最小执行和调度单位。每个线程都独自占用一个虚拟处理器：独自的寄存器组，指令计数器和处理器状态。每个线程完成不同的任务，但是共享同一地址空间（也就是同样的动态内存，映射文件，目标代码等等），打开的文件队列和其他内核资源。线程在进程下行进（单纯的车厢无法运行）一个进程可以包含多个线程（一辆火车可以有多个车厢）不同进程间数据很难共享（一辆火车上的乘客很难换到另外一辆火车，比如站点换乘）同一进程下不同线程间数据很易共享（A车厢换到B车厢很容易）进程要比线程消耗更多的计算机资源（采用多列火车相比多个车厢更耗资源）进程间不会相互影响，一个线程挂掉将导致整个进程挂掉（一列火车不会影响到另外一列火车，但是如果一列火车上中间的一节车厢着火了，将影响到所有车厢）进程可以拓展到多机，进程最多适合多核（不同火车可以开在多个轨道上，同一火车的车厢不能在行进的不同的轨道上）进程使用的内存地址可以上锁，即一个线程使用某些共享内存时，其他线程必须等它结束，才能使用这一块内存。（比如火车上的洗手间）－”互斥锁”进程使用的内存地址可以限定使用量（比如火车上的餐厅，最多只允许多少人进入，如果满了需要在门口等，等有人出来了才能进去）－“信号量”僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait 或waitpid 获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中，这种进程称之为僵尸进程。孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。2. FutureTaskFutureTask为Future提供了基础实现，如获取任务执行结果和取消任务等。如果任务尚未完成，获取任务执行结果时将会阻塞。一旦执行结束，任务就不能被重启或取消。FutureTask常用来封装Callable和Runnable，也可以作为一个任务提交到线程池中执行。关系FutureTask实现了RunnableFuture接口，则RunnableFuture接口继承了Runnable接口和Future接口。所以FutureTask既能当一个Runnable接口被Thread执行，也能作为Future用来得到Callable的计算结果。核心属性//内部持有的callable任务，运行完毕后置空private Callable&lt;V&gt; callable;//从get()中返回的结果或抛出的异常private Object outcome; // non-volatile, protected by state reads/writes//运行callable的线程private volatile Thread runner;//使用Treiber栈保存等待线程private volatile WaitNode waiters;//任务状态private volatile int state;private static final int NEW = 0;private static final int COMPLETING = 1;private static final int NORMAL = 2;private static final int EXCEPTIONAL = 3;private static final int CANCELLED = 4;private static final int INTERRUPTING = 5;private static final int INTERRUPTED = 6;其中需要注意的是state是volatile类型的，也就是说只要有任何一个线程修改了这个变量，那么其他所有的线程都会知道最新的值。7种状态具体表示： NEW:表示是个新的任务或者还没被执行完的任务。这是初始状态。 COMPLETING:任务已经执行完成或者执行任务的时候发生异常，但是任务执行结果或者异常原因还没有保存到outcome字段(outcome字段用来保存任务执行结果，如果发生异常，则用来保存异常原因)的时候，状态会从NEW变更到COMPLETING。但是这个状态会时间会比较短，属于中间状态。 NORMAL:任务已经执行完成并且任务执行结果已经保存到outcome字段，状态会从COMPLETING转换到NORMAL。这是一个最终态。 EXCEPTIONAL:任务执行发生异常并且异常原因已经保存到outcome字段中后，状态会从COMPLETING转换到EXCEPTIONAL。这是一个最终态。 CANCELLED:任务还没开始执行或者已经开始执行但是还没有执行完成的时候，用户调用了cancel(false)方法取消任务且不中断任务执行线程，这个时候状态会从NEW转化为CANCELLED状态。这是一个最终态。 INTERRUPTING: 任务还没开始执行或者已经执行但是还没有执行完成的时候，用户调用了cancel(true)方法取消任务并且要中断任务执行线程但是还没有中断任务执行线程之前，状态会从NEW转化为INTERRUPTING。这是一个中间状态。 INTERRUPTED:调用interrupt()中断任务执行线程之后状态会从INTERRUPTING转换到INTERRUPTED。这是一个最终态。 有一点需要注意的是，所有值大于COMPLETING的状态都表示任务已经执行完成(任务正常执行完成，任务执行异常或者任务被取消)。各个状态之间的可能转换关系如下图所示：3. 线程池线程池（Thread Pool）是一种基于池化思想管理线程的工具，经常出现在多线程服务器中，如MySQL。线程过多会带来额外的开销，其中包括创建销毁线程的开销、调度线程的开销等等，同时也降低了计算机的整体性能。线程池维护多个线程，等待监督管理者分配可并发执行的任务。这种做法，一方面避免了处理任务时创建销毁线程开销的代价，另一方面避免了线程数量膨胀导致的过分调度问题，保证了对内核的充分利用。使用线程池可以带来一系列好处： 降低资源消耗：通过池化技术重复利用已创建的线程，降低线程创建和销毁造成的损耗。 提高响应速度：任务到达时，无需等待线程创建即可立即执行。 提高线程的可管理性：线程是稀缺资源，如果无限制创建，不仅会消耗系统资源，还会因为线程的不合理分布导致资源调度失衡，降低系统的稳定性。使用线程池可以进行统一的分配、调优和监控。 提供更多更强大的功能：线程池具备可拓展性，允许开发人员向其中增加更多的功能。比如延时定时线程池ScheduledThreadPoolExecutor，就允许任务延期执行或定期执行。线程池解决的问题线程池解决的核心问题就是资源管理问题。在并发环境下，系统不能够确定在任意时刻中，有多少任务需要执行，有多少资源需要投入。核心设计与实现Java中的线程池核心实现类是ThreadPoolExecutor，ThreadPoolExecutor实现的顶层接口是Executor，顶层接口Executor提供了一种思想：将任务提交和任务执行进行解耦。用户无需关注如何创建线程，如何调度线程来执行任务，用户只需提供Runnable对象，将任务的运行逻辑提交到执行器(Executor)中，由Executor框架完成线程的调配和任务的执行部分。ThreadPoolExecutor运行机制如图：Java线程池的实现原理，简要来说时一个线程集合workerSet和一个阻塞队列workQueue。当用户向线程池提交一个任务时，线程池会先将任务放在workQueue中，workerSet中的线程会不断的从workQueue中获取线程然后执行。当workQueue中没有任务的时候，worker就会阻塞，直到队列中有任务了就取出来继续执行。Execute原理当一个任务提交至线程池之后： 线程池首先判断当前运行的线程数量是否少于corePoolSize，如果是，则创建一个新的工作线程来执行任务，如果都在执行任务，则进入下一步； 判断BlockingQueue是否已经满了，如果还没满，则将线程放入BlockingQueue，否则进入下一步； 如果创建一个新的工作线程将使当前运行的线程数量超过maximumPoolSize，则交给RejectedExecutionHandler来处理任务。当ThreadPoolExecutor创建新线程时，通过CAS来更新线程池状态。线程池的创建通过Executors类提供的方法。 newCachedThreadPool 创建一个可缓存的线程池，若线程数超过处理所需，缓存一段时间后会回收，若线程数不够，则新建线程。 newFixedThreadPool 创建一个固定大小的线程池，可控制并发的线程数，超出的线程会在队列中等待。 newSingleThreadExecutor 创建一个单线程的线程池，可保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 —————————————–（后面不常用）————————————————– newScheduledThreadPool 创建一个周期性的线程池，支持定时及周期性执行任务。 newSingleThreadScheduledExecutor 创建一个单线程的可以执行延迟任务的线程池。 newWorkStealingPool 创建一个抢占式执行的线程池(任务执行顺序不确定)。 通过ThreadPoolExecutor类自定义。public ThreadPoolExecutor(int corePoolSize,\tint maximumPoolSize,\tlong keepAliveTime,\tTimeUnit unit,\tBlockingQueue&lt;Runnable&gt; workQueue,\tThreadFactory threadFactory,\tRejectedExecutionHandler handler) {\t// 省略...}具体参数如下 corePoolSize 线程池中的核心线程数。当提交一个任务时，线程池创建一个新线程执行任务，直到当前线程数等于corePoolSize，即使有其他空闲的线程能够执行新来的任务，也会继续创建线程。如果当前线程数等于corePoolSize，继续提交的任务会被保存到阻塞队列中等待被执行。 workQueue 用来保存等待被执行的任务的阻塞队列，在JDK中有如下队列： ArrayBlockingQueue: 基于数组结构的有界阻塞队列，按FIFO排序任务； LinkedBlockingQueue: 基于链表结构的阻塞队列，按FIFO排序任务，吞吐量通常要高于ArrayBlockingQueue； SynchronousQueue: 一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQueue； PriorityBlockingQueue: 具有优先级的无界阻塞队列； maximumPoolSize 线程池中允许的最大线程数。如果当前阻塞队列满了，且继续提交任务，则创建新的线程执行任务，直到线程数为maximumPoolSize；当阻塞队列是无界队列，则最大线程数不起作用。 keepAliveTime 线程空闲时的存活时间，即当线程没有任务执行时，该线程继续存活的时间。默认情况下该参数只有线程数大于corePoolSize时才有用，超过这个时间点空闲线程将被终止。 unit keepAliveTime的单位。 threadFactory 创建线程的工厂，通过自定义的线程工厂可以给每个新建的线程设置一个具有识别度的线程名。默认为DefaultThreadFactory。 handler 线程池的饱和策略，当阻塞队列满了，且没有空闲的工作线程，如果继续提交任务，必须采取一种策略处理该任务，线程池提供了4种策略: AbortPolicy: 直接抛出异常，默认策略； CallerRunsPolicy: 用调用者所在的线程来执行任务； DiscardOldestPolicy: 丢弃阻塞队列中靠最前的任务，并执行当前任务； DiscardPolicy: 直接丢弃任务。 Executors 返回的线程池对象的弊端如下： FixedThreadPool 和 SingleThreadPool：允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。 CachedThreadPool：允许的创建线程数量为 Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。 线程池的创建推荐使用最后一种 ThreadPoolExecutor 的方式来创建，因为使用它可以明确线程池的运行规则，规避资源耗尽的风险。ThreadLocalThreadLocal（线程本地存储）提供了一种方式，让在多线程环境下，每个线程都可以拥有自己私有的数据结构，进而减少同一个线程内多个函数或者组件之间一些公共变量的传递的复杂度。但因为其自身的实现机制，使用之后记得及remove，避免内存泄露。设计模式设计模式（Design pattern）是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结。使用设计模式是为了可重用代码、让代码更容易被他人理解、保证代码可靠性。1. 分类创建型模式：对象实例化的模式，创建型模式用于解耦对象的实例化过程。结构型模式：把类或对象结合在一起形成一个更大的结构。行为型模式：类和对象如何交互，及划分责任和算法。2. 特点创建型模式单例模式：某个类只能有一个实例，提供一个全局的访问点。简单工厂：一个工厂类根据传入的参量决定创建出那一种产品类的实例。工厂方法：定义一个创建对象的接口，让子类决定实例化那个类。抽象工厂：创建相关或依赖对象的家族，而无需明确指定具体类。建造者模式：封装一个复杂对象的构建过程，并可以按步骤构造。原型模式：通过复制现有的实例来创建新的实例。结构型模式适配器模式：将一个类的方法接口转换成客户希望的另外一个接口。组合模式：将对象组合成树形结构以表示“”部分-整体“”的层次结构。装饰模式：动态的给对象添加新的功能。代理模式：为其他对象提供一个代理以便控制这个对象的访问。亨元（蝇量）模式：通过共享技术来有效的支持大量细粒度的对象。外观模式：对外提供一个统一的方法，来访问子系统中的一群接口。桥接模式：将抽象部分和它的实现部分分离，使它们都可以独立的变化。行为型模式模板模式：定义一个算法结构，而将一些步骤延迟到子类实现。解释器模式：给定一个语言，定义它的文法的一种表示，并定义一个解释器。策略模式：定义一系列算法，把他们封装起来，并且使它们可以相互替换。状态模式：允许一个对象在其对象内部状态改变时改变它的行为。观察者模式：对象间的一对多的依赖关系。备忘录模式：在不破坏封装的前提下，保持对象的内部状态。中介者模式：用一个中介对象来封装一系列的对象交互。命令模式：将命令请求封装为一个对象，使得可以用不同的请求来进行参数化。访问者模式：在不改变数据结构的前提下，增加作用于一组对象元素的新功能。责任链模式：将请求的发送者和接收者解耦，使的多个对象都有处理这个请求的机会。迭代器模式：一种遍历访问聚合对象中各个元素的方法，不暴露该对象的内部结构。3. 单例模式单例模式指在程序运行期间, 某些类有且最多只有一个实例对象。其优势是尽可能节约内存空间，减少垃圾回收的消耗，并使得程序正常运行。实现思路 静态化实例对象，让实例对象与Class相互绑定，通过Class类对象可以直接访问； 私有化构造方法，禁止通过构造方法创建多个实例； 提供一个公共的静态方法，用来返回这个类的唯一实例。实现方法饿汉模式（eager）/** * 饿汉模式: 类加载时就初始化 */final class HungrySingleton { /** 实例对象 */ private static HungrySingleton instance = new HungrySingleton(); /** 禁用构造方法 */ private HungrySingleton() { } /** * 获取单例对象, 直接返回已创建的实例 * @return instance 本类的实例 */ public static HungrySingleton getInstance() { return instance; }}优点是线程安全，JVM在加载这个类的时候就会对它进行初始化，这里包含对静态变量的初始化；缺点是容易造成空间的浪费。懒汉模式（lazy）/** * 懒汉模式: 用到时再初始化, 线程不安全, 可以在方法上使用synchronized关键字实现线程安全 */final class LazySingleton { /** 实例对象 */ private static LazySingleton instance = null; /** 禁用构造方法 */ private LazySingleton() { } /** * 线程不安全, 可以在方法上使用synchronized关键字实现线程安全 * @return instance 本类的实例 */ public static LazySingleton getInstance() { if (instance == null) { instance = new LazySingleton(); } return instance; }}优点是节省空间，用到的时候再创建实例对象。但是缺点是线程不安全，因为可能两个线程同时进入if语句，从而创建出两个实例。枚举类/** * 枚举类单例模式 */enum EnumSingleton { /** 此枚举类的一个实例, 可以直接通过EnumSingleton.INSTANCE来使用 */ INSTANCE}优点是不需要考虑序列化问题，枚举序列化是由JVM保证的，每一个枚举类型和枚举变量在JVM中都是唯一的；也不需要考虑反射问题，因为不能通过反射创建枚举实例的。缺点是所有的属性都必须在创建时指定，也就意味着不能延迟加载；并且使用枚举时占用的内存比静态变量的2倍还多, 这在性能要求严苛的应用中是不可忽视的。单例模式的破坏反射攻击反射是通过调用构造方法生成新的对象，对于类的私有构造函数，反射可以直接访问。所以可以在构造方法中进行判断，若已有实例, 则阻止生成新的实例, 如:private Singleton() throws Exception { if (instance != null) { throw new Exception(\"Singleton already initialized, 此类是单例类, 不允许生成新对象\"); }}序列化如果单例类实现了序列化接口Serializable，就可以通过反序列化破坏单例，解决方法是：// 反序列化时直接返回当前实例public Object readResolve() { return instance;}Object.clone()Object.clone()方法也会破坏单例, 即使你没有实现Cloneable接口，因为clone()方法是Object类中的. 解决方法是重写clone()方法。消息队列1. 基础消息队列中间件是分布式系统中重要的组件，主要用于应用解耦，异步消息，流量削峰等问题。实现高性能，高可用，可伸缩和最终一致性架构。目前使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，RocketMQ。MQ是消费者-生产者的一个典型代表，一端往消息队列中不断写入消息，而另一端则可以读取队列中的消息。消息的发布者只管把消息发布到MQ中而不管谁来取用，消息使用者只管从MQ中取消息而不关注是谁发布的。2. MQ通信模型MQ通信模型有以下类型 点对点：点对点方式是最传统的通讯方式，它支持一对一，一对多，多对多和多对一等配置方式，支持树状，网状等拓扑结构。 多点广播：能够将消息发送到多个目标站点，并确保为每一个站点可靠的提供消息。 发布-订阅：Pub-Sub模式使得消息的分发可以突破目的队列地理位置的限制，使消息按照特定的主题甚至内容进行分发，用户或应用可以根据主题或内容接受所需要的消息。Pub-Sub模式使得发送者和接收者之间的耦合关系变得更加松散。 集群：为了简化点对点通讯模式中的系统配置，MQ 提供 Cluster(集群) 的解决方案。集群类似于一个域，集群内部的队列管理器之间通讯时，不需要两两之间建立消息通道，而是采用集群通道与其它成员通讯，从而大大简化了系统配置。此外，集群中的队列管理器之间能够自动进行负载均衡，当某一队列管理器出现故障时，其它队列管理器可以接管它的工作，从而大大提高系统的高可靠性 3. MQ的应用异步处理MQ可以将系统之间的处理流程异步化，减少等待响应的时间，从而提高整体并发吞吐量。一般MQ异步处理应用于非核心流程，例如短信/邮件通知，数据推送，上报数据等。系统解耦通过MQ，可以消除系统之间的强耦合，其优点如下 消息的消费者系统可以随意增加，无需修改生产者的系统代码； 生产者系统和消费者系统彼此不会影响对方的流程。 如果生产者系统宕机，消费者系统收不到消息，就不会有下一步的动作。 如果消费者系统宕机，生产者系统让然可以正常发送消息，不影响流程。 流量削峰当上下游处理能力存在差距时，利用MQ做一个漏斗模型，进行流控，可以把MQ当成可靠的消息暂存地，进行一定程度的消息堆积，在下游有能力处理的时候在进行发送。MQ 的流量削峰常用于高并发场景（例如：秒杀、团抢等业务场景），它是缓解瞬时暴增流量的核心手段之一。传输缓冲MQ常被用于做海量数据的传输缓冲，例如kafka常被用于做为各种日志数据、采集数据的数据中转。然后，Kafka 将数据转发给 Logstash、Elasticsearch 中，然后基于 Elasticsearch 来做日志中心，提供检索、聚合、分析日志的能力。开发者可以通过 Kibana 集成 Elasticsearch 数据进行可视化展示，或自行进行定制化开发。MQ也可以被用于流式处理，比如Kafka几乎已经是流计算的数据采集端的标准组件。而流计算通过实时数据处理能力，提供了更为快捷的聚合计算能力，被大量应用于链路监控、实时监控、实时数仓、实时大屏、风控、推荐等应用领域。4. MQ的问题重复消费以Kafka为例，Kakfa的每个Partition都是一个有序的，不可变的记录序列，不断追加到结构化的提交日志中。Partition 中为每条记录分配一个连续的 id 号，称为偏移量（Offset），用于唯一标识 Partition 内的记录。Kafka 的客户端和 Broker 都会保存 Offset。客户端消费消息后，每隔一段时间，就把已消费的 Offset 提交给 Kafka Broker，表示已消费。如果客户端应用消费消息后，因为宕机，重启等没有提交已消费的Offset，当系统恢复后就会出现重复提交。应对重复消费的方式就是在业务层面通过幂等性设计来解决。比如重复判断，全局唯一ID。消息丢失唯一可能导致消费方丢失数据的情况是：消费方设置了自动提交 Offset。可以关闭此功能来防止消息丢失。消息的顺序性写入数据到 Partition 时指定一个全局唯一的 ID，例如订单 ID。发送方保证相同 ID 的消息有序的发送到同一个 Partition。消息积压临时增加Consumer的数量。5. MQ的高可用：以Kafka为代表Kafka核心概念Kafka包含以下几部分 Broker：Kafka集群包含一个或多个节点，这种节点被称为Broker； Topic：每条发布到Kafka集群里的消息都有一个类别，这个类别被称为Topic。不同 Topic 的消息是物理隔离的；同一个 Topic 的消息保存在一个或多个 Broker 上，但用户只需指定消息的 Topic 即可生产或消费数据而不必关心数据存于何处。 Partition：提高了Kafla的吞吐率，每个Topic包含一个或多个Partition，每个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition所有的消息和索引文件。Kafka的副本机制为了实现高可用，Kafka 引入了复制功能。每个 Partition 都有一个 Leader，零个或多个 Follower。Leader 和 Follower 都是 Broker，每个 Broker 都会成为某些分区的 Leader 和某些分区的 Follower，因此集群的负载是平衡的。Leader处理一切对分区的读写请求，而Follower只需被动的同步Leader上的数据。同一个Topic的不同Partition会分布在多个Broker上，而且一个Partition还会在其他的Broker上进行备份。发布者在发布消息到某个分区时，先找到该 Partition 的 Leader，然后向这个 Leader 推送消息；每个 Follower 都从 Leader 拉取消息，拉取消息成功之后，向 Leader 发送一个 ACK 确认。Kafka 选举 LeaderPartition 在多个 Broker 上存在副本，如果某个 Follower 宕机，啥事儿没有，正常工作。如果 Leader 宕机了，会从 Follower 中重新选举一个新的 Leader。其他1. DockerDocker的优势总结如下： 更快的启动时间。Docker容器启动是几秒钟的事情，因为容器只是一个操作系统进程而已。带有完整操作系统的虚拟机则需要几分钟来加载。 更快部署。不需要建立一个新的环境。使用Docker,Web开发团队只需要下载Docker镜像并在不同的服务器上运行。 容器更易管理与扩展。因为销毁与运行容器比销毁与运行虚拟机更快。 计算资源的更好利用，因为在一个服务器上你可以运行的容器比虚拟机要多。 支持多种操作系统，Windows,Mac,Debian等等。2. Zookeeper介绍ZooKeeper 是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。解决问题在分布式系统中，以下问题经常出现： 确定Leader； 配置协调管理； 群组管理； 分布式锁。设计 顺序一致性，从同一个客户端发起的事务请求，最终将会严格地按照其发起顺序被应用到Zookeeper中去。 原子性，所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，即整个集群要么都成功应用了某个事务，要么都没有应用。 单一视图，无论客户端连接的是哪个 Zookeeper 服务器，其看到的服务端数据模型都是一致的。 可靠性，一旦服务端成功地应用了一个事务，并完成对客户端的响应，那么该事务所引起的服务端状态变更将会一直被保留，除非有另一个事务对其进行了变更。 实时性，Zookeeper 保证在一定的时间段内，客户端最终一定能够从服务端上读取到最新的数据状态。组成 客户端: 使用Zookeeper服务， 服务器:用于负载平衡和容错的复制服务集成， 会话:客户端连接到服务器直到其关闭， Znode:客户端的内存数据对象。像传统的文件系统但不存储太多的文件。 临时znode:在会话中保持活动，在关闭时进行清理。 普通znode:由用户创建，由Zookeeper服务维护的根节点。 " } ]
