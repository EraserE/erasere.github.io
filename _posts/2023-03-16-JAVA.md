---
title: JAVA
date: 2022-03-16 10:34:00 +0800
categories: [笔记]
tags: [JAVA]
pin: true
author: Eraser

toc: true
comments: true
typora-root-url: ../../eraseryao.github.io
math: false
mermaid: true
---

# JAVA

## 基础

### 1. 面向对象

#### 三大特性

Java有三大特性：**封装，继承，多态**。

**封装**：利用抽象数据和基于数据的操作封装在一起，使其构成一个不可分割的独立实体。数据在被保护的抽象数据类型的内部，尽可能隐藏内部细节，只保留一些对外接口使之与外部发生联系，用户无需知道对象内部的细节，但可以通过对象对外提供的接口来访问该对象。

**继承**：继承实现了IS-A关系，遵循里氏替换原则，即派生子类可以在程序中替换其基类对象。父类引用指向子类对象称为**向上转型**，比如`List<?> list=new ArrayList<>();`

**多态**：多态分为编译时多态和运行时多态：

- 编译时多态主要指方法的重载；
- 运行时多态主要指程序中定义的对象引用所指向的具体类型在运行期间才确定。

#### 函数式编程

指令式编程利用计算机的指令或者语法，告诉计算机一步步要做什么。而声明式方法就是告诉计算机要实现什么样的功能，而不关注计算机内部处理。

**面向对象编程时对数据进行抽象，而函数式编程是对行为进行抽象**。函数式编程能让程序员写出更容易阅读的代码，这种代码更多的表现了业务逻辑，而不是从机制是如何实现。

在写回调函数和事件处理器时，程序员不必再纠缠于匿名内部类的冗繁和可读性，函数式编程让事件处理系统变得更加简单。能将函数方便地传递也让编写惰性代码变得容易，只有在真正需要的时候，才初始化变量的值。

其核心思想是使用不可变的值和函数，函数对一个值进行处理，映射成另一个值。对核心类库的改进主要包括集合类的API和新引入的流Stream。流使程序员可以站在更高的抽象层次上对集合进行操作。

### 2. 数据类型

#### 包装类型

Java有八个基本类型：boolean(1)，byte(8)，char(16)，short(16)，int(32)，float(32)，long(64)，double(64)。

基本类型都有包装类型，基本类型与其对应的包装类型之间的赋值使用自动装箱与拆箱完成。

#### 缓存池

编译器会在**缓冲池范围内的基本类型**（比如在Java8中Integer的缓存大小默认为-128～127）自动装箱的过程调用valueOf()方法，一次多个Integer实力使用自动装箱来创建并且值相同，那么就会引用相同对象。

例如

- new Integer(123)每次都会新建一个对象；
- Integer.valueOf(123)会用缓存池中的对象，多次调用会取得同一个对象的引用。

#### String字符串

**概述**

(1) String 类声明为 final的，**不可被继承**。

(2) String实现了Serializable接口：表示字符串是支持序列化的；实现了Comparable接口：表示String可以比较大小。

**底层存储**

JDK8及以前底层使用final char[]数组；

JDK9及以后改用final byte[]数组。

改用final byte[]是为了节省空间 (char占2个字节，而byte只用占用1个字节）

**Java中的String具有不可变性**

(1) 如下操作需要生成新的字符串，而不是修改原有的字符串

- ﻿﻿对现有的字符串进行连接操作时；
- ﻿﻿对字符串重新赋值时；
- ﻿﻿调用String的replace()方法修改指定字符或字符串时。

(2) 如何保证String的不可变性？

- char[]使用final修饰，无法指向新的char[]数组；

- String内部没有提供修改的方法，保证内容不会变。

(3) 为什么将String设计为不可变？

- 字符串在实际的开发中使用太频繁，为了提高执行效率，把字符串放到了方法区的字符串常量池当中；
- 不可变字符串，使得编译器可以让字符串共享；
- String的Hash值经常被使用，不变的特征可以使得hash值也不变，因此只需一次计算；
- 如果一个String对象已经被创建过，那么就会从String Pool（字符串常量池）中取得引用。只有String是不可变的才能使用字符串常量池。

**字符串常量池**

(1) 常量池中不会存在相同内容的常量；

(2) 通过字符串字面量赋值时，数据是在常量池中；

(3) String Pool是一个固定大小的 Hashtable（不会扩容）

- ﻿﻿数组+链表的哈希表（拉链法解决hash冲突）；
- ﻿﻿使用StringTableSize可设置StringTable的长度。

**String.intern()**

使用String.intern()可以保证相同内容的字符串变量引用同一内存对象。

**字符串拼接操作**

常量与常量的拼接结果在常量池 （原理是编译期优化）

只要其中有一个是变量，结果就在堆中（变量拼接的原理是 String Builder)

如果拼接的结果调用 intern()方法（将字符串添加到字符常量池中），则主动将常量池中还没有的字符串对象放入池中，并返回此对象地址。

**String、StringBuilder、StringBuffer:**

String 底层数组用 final 修饰，不可变。

StringBuilder 底层数组没有用 final 修饰，可变;线程不安全，效率高(一般用的多)

StringBuffer 底层数组没有用 final 修饰，可变;线程安全，效率低(一般用的少)

#### 参数传递

Java的参数是以值的形式传入方法中，而不是引用传递。

在将一个对象参数传入一个方法时，本质上是**将对象的地址以值的方式传递到形参中**。因此在方法中改变指针引用的对象，那么此时两个指针指向的是完全不同的对象，一方改变所指对象内容对另一方没有影响。但如果在方法中改变对象的字段值会改变原来对象的字段值，因为改变的是同一个地址指向的内容。

### 3. 继承

#### 抽象类与接口

**1. 抽象类**

抽象类和抽象方法都使用abstract关键字进行声明。抽象类一般会包含抽象方法，抽象方法一定位于抽象类中。抽象类和普通类最大的区别是，抽象类不能被实例化，需要继承抽象类才能实例化其子类。

**2. 接口**

接口是抽象类的延伸。在Java8之前，他可以看作一个完全抽象的类，从Java8开始，接口也可以拥有默认的方法实现。接口的成员默认都是public的，并且不允许被定义为private或者protected。

接口的字段默认是static和final的。

#### Super

访问父类的构造函数：可以使用super()函数访问父类构造函数，委托父类完成一些初始化的工作。

访问父类的成员，如果子类重写了父类中的某个方法的实现，可以通过使用super关键字来引用父类方法的实现。

### 4. 函数式接口

#### Functional

Function<T, R> 是 Java 8 中的一个函数式接口，用于表示接受一个输入参数 T，并返回一个结果 R 的函数。Function接口中有一个抽象方法apply，用于定义函数的逻辑。Function接口通常用于将数据进行转换、映射或者执行某种转换操作。

#### Supplier

Supplier< T > 是一个功能接口，表示无参传入，返回一个结果为T的函数。接口中有一个功能方法get()，不接受刃和参数。Supplier可以如下定义：

```java
Supplier<T> s = ()->{
    //函数逻辑实现
}
s.get() //调用接口
```

#### Accumulator

在Java中，我们可以使用类来定义累加器。累加器类通常包含一个私有的累加结果变量和一些公共方法，用于更新和获取累加结果。

## Java容器

![Java容器详解Ⅰ——概述- 知乎](/assets/blog_res/2023-03-16-JAVA.assets/v2-37a924e5830ed38d9c76296314cb4baa_1440w.webp)

### 1. Collection

#### Set

1. **TreeSet**

   基于红黑树实现，无序，不可重复，自动排序；

   存放在TreeSet中相当于存放到TreeMap中的key部分。

2. **HashSet**

   基于哈希表实现，无序，不可重复，支持快速查找。

3. **LinkedHashSet**

   基于双向链表实现，具有 Hashset 的查找效率。

#### Queue

1. **LinkedList**

   可以实现双向队列。

2. **PriorityQueue**

   基于堆结构实现，可以实现优先队列。

#### List

List在Java里面是一个接口，继承自Collection。为了追求效率，ArrayList和LinkedList都没有实现同步，vector有同步。

**ArrayList**

1. 底层结构是Object数组，元素可以为null；

2. 相比于原生的数组在初始化的时候必须指定大小，ArrayList实现了动态扩容：

   - new—个ArravList 的时候，默认会有一个空的Object 数组，大小为0，第一次add 数据的时候，会给这个数组一个初始化的大小，默认为 10；

   - 每一次add，都会先去计算这个数组够不够空间，够就追加上去，不够就扩容；

   - 在源码里面，有个grow方法，每一次扩容原来的1.5倍，扩完容后，调用arraycopy来对数组进行拷贝。

3. 日常开发中用的最多，因为遍历需求高。

**LinkedList**

LinkedList同时实现了List接口和Deque接口，因为它既可以看作一个顺序容器们也可以看作一个队列。其底层数据结构是双向链表，元素可以为null。

**Queue**

Queue可以通过LinkedList实现，队列的插入，删除，检视可以使用自带collection的方法，也可以用队列实现的方法。前者失败会抛出异常，后者会返回特殊值。

**Vector**

底层结构是数组，线程安全，扩容的时候直接扩两倍容。

**ArrayList和LinkedList区别**

1. 线程安全

   二者都是线程不安全的。

2. 底层数据结构

   - ArrayList底层使用的是Objiect[]数组;

   - Linkedlist底层使用的是双向链表数据结构。

3. 插入和删除是否受元素位置影响

   - ArrayList采用数组存储，所!以插入和删除元素的时间复杂度受元泰位置的影响；
   - Linkedlist 采用链表进行存储。

4. 是否支持随机快速访问

   - ArrayList 支持 get(index) 方法；
   - Linkedlist 不支持高效的随机元素访问。

5. 内存空间占用

   - ArravList 的空间浪费主要体现在list列表的结尾会预留一定的容量空间；
   - Linkedlist 的空间花费则体现在它的每个元素都需要消耗比ArrayList更多的空间，用于存放直接后继和直接前驱以及数据。

**ArrayList和Vector区别**

两者都用Object[]存储，但是ArrayList线程不安全，vector线程安全。

**CopyOnWriteArrayList**

1. 该方法是线程安全的。

2. add()方法实现

   在add()的时候会加Lock锁，然后复制出个新的数组，往新的数组里面add真正的元素，最后把array的指向改变为新的数组。

3. get()方法或者是size()方法只是获取array所指向的元素或者大小，读不加锁，但是写加锁。

4. 很耗费内存，每次set add都会复制一个数组出来。

5. 只能保证数据最终一致性，不能保证数据的实时一致性。

   假设有两个线程，A 去读CopyOnWriteArrayList 的数据还没读完，如果现在线程B把这个List给清空了，线程 A此时还是可以把剩余数据给读出来。

#### PriorityQueue

优先队列，其作用是**保证每次取出的元素都是队列中权值最小的**，元素大小的判断可以通过构造比较器。

Java中的优先队列实现了Queue接口，不允许放入null元素，其通过堆实现，具体说是通过完全二叉树实现的小顶堆。

### 2. Map

#### HashMap

HashMap实现了Map接口，**即允许放入key为null的的元素，也允许插入value为null的元素**，该容器不保证元素顺序，根据需要可能会对元素重新哈希。

HashMap的参数如下：

``` java
// 最开始的容量，必须是 2 的次方，这里即 2 的 4 次方
static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16
// 最大容量
static final int MAXIMUM_CAPACITY = 1 << 30;
// 负载
static final float DEFAULT_LOAD_FACTOR = 0.75f;
// list to tree 的临界值
static final int TREEIFY_THRESHOLD = 8;
// 删除冲突节点后，hash相同的节点数目小于这个数，红黑树就恢复成链表
static final int UNTREEIFY_THRESHOLD = 6;
// 扩容的临界值
static final int MIN_TREEIFY_CAPACITY = 64;
// 存储元素的数组
transient Node<k,v>[] table;
```
1. HashMap 底层是一个数组；

2. 在Java8之前，数组中每个元素是一个单向链表(即，采用拉链法解决哈希冲突)，单链表的节点每个节点是 Node<K, V> 类型；

   Java8之后，对 HashMap 底层数据结构(单链表)进行了改进，如果单链表元素超过8个，则将单链表转变为红黑树；如果红黑树节点数量小于6时，会将红黑树重新变为单链表。

3. 同一个单链表中所有Node的hash值不一定一样，但是他们对应的数组下标一定一样；

   数组下标利用哈希函数/哈希算法根据 hash值计算得到的；

4. HashMap 是数组和单链表的结合体

   数组查询效率高，但是增删元素效率较低；

   单链表在随机增删元素方面效率较高，但是查询效率较低；

   HashMap 将二者结合起来，充分它们各自的优点；

5. HashMap 特点

   无序、不可重复；

   无序: 因为不一定挂在那个单链表上了

6. 为什么不可重复？

   通过重写 equals 方法保证的。

7. 数组扩容

   resize()方法用于初始化数组或数组扩容，**每次扩容后，容量为原来的2倍**，并进行数据迁移。

#### HashMap扩容

HashMap通过调用Key的hashCode()方法来得到hash值，然后通过Hash算法的**高位运算和取模运算**来定位该键值对的存储位置。

如果两个key定位到了同一个位置，则发生了Hash碰撞，Hash计算的结果越分散，Hash碰撞的概率越小。

### 3. HashMap，HashTable，ConcurrentHashMap线程安全：

**HashMap 是线程不安全的**。

在多线程条件下，容易导致死循环。JDK 1.8 HashMap 采用数组 + 链表 + 红黑二叉树的数据结构，优化了 1.7 中数组扩容的方案，解决了 Entry 链死循环和数据丢失问题。但是多线程背景下，put 方法存在数据覆盖的问题。

**HashTable是线程安全的**。

在ConcurrentHashMap中，无论是读操作还是写操作都能保证很高的性能：在进行读操作时(几乎)不需要加锁，而在写操作时通过锁分段技术只对所操作的段加锁而不影响客户端对其它段的访问。特别地，在理想状态下，ConcurrentHashMap 可以支持 16 个线程执行并发写操作（如果并发级别设为16），及任意数量线程的读操作。 

**ConcurrentHashMap的高效并发机制是通过以下三方面来保证的：**

- 使用volatile保证当Node中的值变化时对于其他线程是可见的，因为volatile关键字，会在读指令前插入读屏障，可以让高速缓存中的数据失效，重新从主内存加载数据；
- 使用table数组的头结点作为synchronized的锁来保证写操作的安全。synchronized是互斥锁，有且只有一个线程能够拿到这个锁，从而保证了put操作是线程安全的；
- 当头结点为null时，使用CAS操作来保证数据能正确的写入。所谓的CAS，即即compareAndSwap，执行CAS操作的时候，将内存位置的值与预期原值比较，如果相匹配，那么处理器会自动将该位置值更新为新值，否则，处理器不做任何操作。

## Java并发

### 1. 基础

#### 为什么需要多线程

CPU，内存，I/O设备的速度有极大的差异，为了合理利用CPU的高性能，平衡三者的速度差异，计算机做出了一下优化：

- CPU增加了缓存，以平衡与内存的速度差异，但是也导致了可见性问题；
- 操作系统增加了线程，进程，以分时复用CPU，进而均衡CPU与I/O设备的速度差异，但是导致了原子性问题；
- 编译程序优化指令执行顺序，以便合理利用缓存，但是导致了有序性问题。

#### 并发编程重要特性

**原子性**

对于一个或多次操作，要么所有的操作全部得到执行并且不会收到任何因素的干扰而中断，要么都不执行，用synchronized关键字来保证。

**可见性**

当一个线程对共享变量进行了修改，那么另外的线程都是立即看到修改后的最新值，用volatile字段保证共享变量的可见性。

**有序性**

代码在执行过正中的先后顺序，在编译期间，代码未必顺序执行，而volatile关键字可以禁止指令进行重排优化。

#### Java如何解决并发

- volatile，synchronized和final关键字；
- Happens-before原则。

#### Happens-before规则

JVM规定了先行发生原则，让一个操作无需控制就能先于另一个操作完成。

**单一线程原则**：在一个线程内，在程序前面的操作先行发生于后面的操作；

**管理锁定规则**：一个unlock操作先行发生于后面对同一个锁的lock操作；

**volatile变量规则**：对一个volatile变量的写操作先行发生于后面对这个变量的读操作；

**线程启动规则**：Thread对象的start()方法调用先行发生于此线程的每一个动作；

**线程加入规则**：Thread对象的结束先行发生于join()方法返回；

**线程中断规则**：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生；

**对象终结规则**：一个对象的初始化完成先行发生于它的finalize()方法的开始；

**传递性**：如果操作A先行发生于B，操作B先行发生于C，那么操作A先行发生于操作C。

#### 线程安全实现方法

1. **互斥同步**：synchronized和ReentrantLock；
2. **非阻塞同步**：CAS，AtomicInteger和ABA；
   - CAS：比较并交换，是硬件支持的原子性操作，CAS指令有三个操作数，内存地址V，旧的预期值A和新值B。当执行操作时，只有当V的值等于A，才将V的值更新为B。
   - ABA：通过控制变量值的版本来保证CAS的正确性。

1. **无同步方案**：栈封闭，线程本地存储和可重入代码。
   - 栈封闭：多个线程访问同一个方法的局部变量时，不会出现线程安全问题，因为局部变量存储在虚拟机栈中，属于线程私有。
   - 线程本地存储：如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证，就可以把共享数据的可见范围限制在同一个线程之内，这样无需同步也能保证线程之间不出现数据争用的问题。

### 2. 线程

#### 线程状态转换

![image](/assets/blog_res/2023-03-16-JAVA.assets/ace830df-9919-48ca-91b5-60b193f593d2.png)

#### 线程使用方式

**实现Runnable接口**：

需要实现run()方法，通过Thread调用start()方法来启动线程。

```java
public class MyRunnable implements Runnable {
    public void run() {
        // ...
    }
}
```

```java
public static void main(String[] args) {
    MyRunnable instance = new MyRunnable();
    Thread thread = new Thread(instance);
    thread.start();
}
```

**实现Callable接口**：

与Runnable相比，Callable可以有返回值，返回值通过FutureTask进行封装。
```java
public class MyCallable implements Callable<Integer> {
    public Integer call() {
        return 123;
    }
}
```

```java
public static void main(String[] args) throws ExecutionException, InterruptedException {
    MyCallable mc = new MyCallable();
    FutureTask<Integer> ft = new FutureTask<>(mc);
    Thread thread = new Thread(ft);
    thread.start();
    System.out.println(ft.get());
}
```
**继承Thread类**：

同样是实现run()方法，因为Thread类也实现了Runnable接口。

当调用start()方法启动一个线程时，虚拟机会将该线程放入就绪队列中等待被调度，当一个线程被调度时会执行该线程的run()方法。

```java
public class MyThread extends Thread {
    public void run() {
        // ...
    }
}
```

```java
public static void main(String[] args) {
    MyThread mt = new MyThread();
    mt.start();
}
```

### 3. 锁

Java中的锁分为显示锁和隐式锁。隐式锁由synchronized关键字实现，而显示锁是由实现了Lock接口和AQS框架等等类来实现。

#### 锁的分类

从宏观上看，锁的分类可以分为乐观锁与悲观锁；共享锁和排他锁，可重入锁和不可重入锁等。

**乐观锁和悲观锁**

乐观锁就是对数据冲突保持乐观态度，认为不会有其他线程同时修改数据。因此乐观锁不会上锁，只是在更新数据的时候判断是否有其他线程更新，如果没有其他线程修改则更新数据，有其他线程同时更改数据，则放弃数据。

悲观锁对数据冲突持悲观态度，认为总有数据发生冲突。因此他以一种预防的态度，先行把数据锁住，直到操作完成才释放锁，在此期间其他线程无法操作数据。

**自旋锁**

线程如果没有争取到资源时，就会进入阻塞状态，当持有锁的线程释放了锁以后，才可以去竞争，这样会浪费大量性能在阻塞和唤醒的切换上，为了避免这点，在没有获得锁的时候，就不进入阻塞，而是不断循环检测锁是否被释放，这就是自旋。

**公平锁和非公平锁**

公平锁是指多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中第一个线程才能获得锁。优点是等待锁的线程不会饿死，缺点是整体吞吐量比非公平锁妖帝，开销较大。

非公平锁是多个线程加锁时直接尝试获取锁，获取不到才会到等待队尾等待。如果锁刚好够用，那么这个线程可以无需阻塞直接获取锁。优点是可以减少唤起线程的开销，整体吞吐率较高，缺点是可能有线程会饿死。

**可重入锁不可重入锁**

又名递归锁，是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁，不会因为之前已经获取过还没释放而阻塞，可以避免死锁。

和可重入锁相反，再进入该线程的内层方法不会自动获取锁。

**共享锁和排他锁**

指该锁可以被多个线程持有，如果线程T对数据A加上共享锁后，其他线程只能对A再加共享锁，不能加排他锁。获得共享锁的线程只能读数据，不能改数据。

指该锁一次只能被一个线程持有。如果线程T对数据A加上排他锁后，其他线程不能对A再加任何类型的锁。获得排他锁的线程既能读数据也能改数据。

#### 锁状态

##### 无锁

不锁住资源，多个线程中有一个能修改资源成功，其他线程会重试。

##### 偏向锁

一段同步代码，共享资源一直被一个线程访问，那么该线程自动获取锁，降低代价。

##### 轻量级锁

当锁是偏向锁的时候，被另外的线程访问，偏向锁回升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。

##### 重量级锁

互斥锁，会被阻塞。

Java的锁升级由锁状态头控制。

![img](/assets/blog_res/2023-03-16-JAVA.assets/1460000022904668.png)

### 4. Synchronized关键字

Synchronized关键字解决的是多个线程之间访问资源的同步性，他可以保证被他修饰的方法或者代码块在任意时刻只能有一个线程执行，在java1.5以前，synchronized属于重量级锁，效率低下。

在Java中，每个对象都有一把锁，放置于对象头中，用于记录当前对象被哪个线程持有。synchronized被编译后，使用的是monitor和monitorExit两个字节码指令，而这两个字节码指令以来操作系统中的mutex lock实现。

#### synchronized关键字作用

通过使用内置锁，来实现对共享变量的同步操作，进而解决了对共享变量操作的原子性，保证了其他线程对共享变量的可见性、有序性，从而确保在并发情况下的线程安全。

同时synchronize是可重入的锁，避免了同一个线程重复请求自身一获取的锁时出现死锁问题。

#### Synchronized字段使用方式

1. **修饰实例方法**：作用于当前对象实例this加锁，进入同步代码块前需要先获得该对象实例的锁。
2. **修饰静态方法**：也就是给当前类的Class对象加锁，会作用于类的所有对象实例，进入同步代码块之前要先获得当前class的锁。
3. **修饰代码块**：指定加锁的对象，给对象/类加锁synchronized(this｜Object)表示进入同步代码块要获得给定对象的锁。

#### 与lock的区别

1. synchronized是Java的关键字，而lock是一个接口；
2. synchronized以获取锁的线程执行完成同步代码，释放锁，如果线程执行异常，jvm会让线程释放锁。而lock在finally中必须释放锁，不然容易造成死锁；
3. 对于synchronized关键字，假设A线程获得锁，B线程等待。如果A线程阻塞，B线程会一直等待；Lock有多个锁获取的方式可以尝试获得锁，线程可以不用一直等待；
4. synchronized关键字无法判断锁状态，而lock可以判断；
5. synchronized锁是可重入，不可中断，非公平的锁，lock是可重入，可判断，可公平的锁；
6. synchronized关键字支持少量同步，而lock可以实现大量同步。

### 5. volatile

#### 概念

Volatile是Java提供的一种轻量级的同步机制。Java 语言包含两种内在的同步机制：同步块（或方法）和 volatile 变量，相比于synchronized（synchronized通常称为重量级锁），volatile更轻量级，因为它不会引起线程上下文的切换和调度。但是volatile变量的同步性较差（有时它更简单并且开销更低），而且其使用也更容易出错。

#### Java内存模型

JMM规定，线程对变量的所有操作都必须在本地内存进行，不能直接读写主存变量。变量从主存于本地内存之间的交互，由8种操作完成。

![截屏2023-03-30 20.34.16](/assets/blog_res/2023-03-16-JAVA.assets/%E6%88%AA%E5%B1%8F2023-03-30%2020.34.16-0226475.png)

线程的共享变量存储在主内存中，每个线程可以吧变量的副本存在本地内存中，这样可能造成变量不一致。

#### volatile变量特性

(1) **保证可见性，不保证原子性**

当写一个volatile变量时，JMM会把该线程本地内存中的变量强制刷新到主内存中去，这个写会操作会导致其他线程中的缓存无效。

其解决了内存不一致问题，当变量声明为volatile时，就告诉JMM该变量是共享且不稳定的，每一次使用都要从主存中读取。

(2) **禁止指令重排**

**重排序**在单线程下一定能保证结果的正确性，但是在多线程环境下，可能发生重排序，影响结果，使用volatile关键字修饰共享变量便可以禁止这种重排序。若用volatile修饰共享变量，在编译时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。

#### volatile原理

volatile可以保证线程可见性且提供了一定的有序性，但是无法保证原子性。在JVM底层volatile是采用“内存屏障”来实现的。

#### 与Synchronized关键字区别

volatile关键字是线程同步的轻量级实现，性能更好；

volatile关键字只能用于变量而synchronized关键字可以修饰方法和代码块；

volatile只保证数据的可见性，不保证原子性，而synchronized关键字两者都可以保证；

volatile解决变量在多个线程之间的可见性，而synchronized解决多个线程之间资源访问的同步性。

### 6. final

final可以修饰类，修饰方法，修饰参数以及修饰变量。

#### 修饰类

当某个类的整体定义为final时，就表明了你不能打算继承该类，而且也不许别人这么做，即这个类不能有子类。

#### 修饰方法

父类final方法不能被子类重写，但是可以重载。

#### 修饰参数

Java允许在参数列表中以声明的方式将参数指名为final，即无法在方法中更改参数引用所指的对象。这个特性主要用来向匿名内部类传递数据。

#### 修饰变量

 final修饰的字段不一定都是编译器常量，只是初始化之后无法在改变。

### 7. CAS，Unsafe

#### CAS

CAS的全称是Compare-And-Swap，是一条CPU的原子指令。其作用是让CPU先进行比较两个值是否相等，然后原子性地更新某个位置的值。其靠硬件实现。CAS操作需要输入预期的旧值和新值，在操作期间先比较下旧值有没有发生变化，如果没有发生变化，才交换成新值，否则不做操作。

CAS是原子性的，所以多线程并发使用CAS更新数据时，可以不使用锁。在Java中，提供了AtomicInteger原子类，其底层基于CAS进行更新数据的。

**CAS问题**

CAS方式为乐观锁，Synchronized为悲观锁。

- ABA问题

  因为CAS在需要操作值的时候，检查值有没有发生变化，没有变化则更新。但是如果一个值原来是A，后来被改成了B，最后又变成了A，那么使用CAS进行检查时就会发现它的值没有发生变化，但实际上却变化了。ABA解决思路就是在变量前加上版本号，每次更新就把版本号加一。

- 循环时间长开销过大

  自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令，那么效率会有一定提升。**pause指令有两个作用：第一他可以延迟流水线执行命令，使CPU不会消耗过多执行资源，第二它可以避免在退出循环的时候因内存顺序冲突而引起CPU流水线被清空，从而提高CPU执行效率。**

- 只能保证一个共享变量

  当对一个共享变量进行操作时，我们可以使用CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁。

从Java 1.5开始，JDK的Atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法的作用是首先检查当前引用是否等于预期引用，并且检查当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。

#### Unsafe类

Unsafe是位于sun.misc包下的一个类，主要提供一些用于执行低级别，不安全操作的方法。如直接访问系统内存资源，自主管理内存资源等，这些方法可以提升Java运行效率，增强Java语言底层资源操作能力。

![img](/assets/blog_res/2023-03-16-JAVA.assets/java-thread-x-atomicinteger-unsafe.png)

#### 原子类

JDK中提供了12个原子操作类。

**原子更新基本类型**

- AtomicInteger：原子更新整型；
- AtomicBoolean：原子更新布尔类型；
- AtomicLong：原子更新长整型。

**原子更新数组**

- AtomicIntegerArray：原子更新整数组里的元素；
- AtomicLongArray：原子更新长整形数组里的元素；
- AtomicReferenceArray：原子更新引用数组里的元素。

**原子更新引用类型**

- AtomicReference：原子更新引用类型；
- AtomicStampedReference：原子更新引用类型，内部使用Pair来存储元素值及其版本号；
- AtomicMarkableReference：原子更新带有标记位的引用类型。

**原子更新字段类**

- AtomicIntegerFiledUpdater：原子更新整型字段的更新器；
- AtomicLongFieldUpdater：原子更新整型字段的更新器；
- AtomicReferenceFieldUpdater：更新的字段必须要用volatile修饰。

### 8. JUC原子类和锁

#### LockSupport

LockSupport是一个线程阻塞工具类，所有的方法都是静态方法。主要有两类方法park和unpark。

当调用park时，表示阻塞当前线程，直到unpark方法调用或当前线程被中断，park方法才会返回。当调用unpark时，必须把等待获得许可的线程作为参数进行传递，来唤醒处于阻塞状态的线程。

其和显式锁、隐式锁等待唤醒的区别

- park和unpark方法的调用不需要获取锁。
- 先调用unpark方法后调用park方法依然可以唤醒。
- park方法响应中断，线程被中断后park方法直接返回，但是不会抛InterruptedException异常。
- unpark方法是直接唤醒指定的线程。

**LockSupport.park**

阻塞线程，并且该线程在下列情况发生之前都会被阻塞：

- 调用unpark函数，释放该线程的许可；
- 该线程被中断；
- 设置的时间到了，当time设为0，则表示无限等待，直到unpark发送。

park函数有两个版本，区别在于无参或传入block参数。

**LockSupport.unpark**

如果传入的线程在park上受阻塞，则将它解除其阻塞状态，否则，保障下一次调用park不会受阻塞。如果给定的线程尚未启动，则无法保证效果。

**线程同步**

使用wait/notify实现同步时，必须先调用wait，后调用notify。如果先调用notify，再调用wait，则无法起作用，线程会一直阻塞；

使用park/unpark实现线程同步时，如果先调用unpark再调用park，线程仍然能正确实现同步，不会被阻塞，跳过park继续执行后续内容，不会造成由wait/notify顺序不当引起的阻塞，因此park/unpark更灵活。

**Object.wait()和LockSupport.park()的区别**

- wait()方法需要在synchronized块中执行，park()方法可以在任意地方执行；
- wait()方法声明抛出了中断异常，调用者需要捕获或者再抛出，park()不需要捕获异常；
- wait()不带超时的时候，需要另一个线程执行notify()唤醒，但不一定执行后续内容；
- park()不带超时的时候，需要另一个线程执行unpark()唤醒，一定会执行后续内容。

#### AQS

AQS是一个用来构建锁和同步器的框架，其内部使用同步队列来解决实现同步器时的一些细节。使用AQS能简单且高效地构造出应用广泛的大量同步器，比如ReentrantLock，Semaphore， 其他诸如ReentrantReadWriteLock，SynchronousQueue，FutureTask都是基于AQS的。

**核心思想**

AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制。这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。

**AQS使用一个int成员** `state` **变量来表示同步状态，通过内置的FIFO队列来完成获取资源线程的排队工作。AQS使用CAS对该同步状态进行原子操作实现对其值的修改。**

**资源共享方式**

AQS定义两种资源共享方式

- Exclusive(独占)：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁： 
  - 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁
  - 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的
- Share(共享)：多个线程可同时执行，如Semaphore/CountDownLatch。Semaphore、CountDownLatCh、 CyclicBarrier、ReadWriteLock 我们都会在后面讲到。

ReentrantReadWriteLock 可以看成是组合式，因为ReentrantReadWriteLock也就是读写锁允许多个线程同时对某一资源进行读。

不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护(如获取资源失败入队/唤醒出队等)，AQS已经在上层已经帮我们实现好了。

**AQS参数**

AQS使用了模版方法模式，使用者继承AQS并重写指定的方法。

```java
isHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。
tryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。
tryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。
tryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。
```

这些方法的实现必须是内部线程安全的。

**AQS数据结构**

AQS底层使用CLH队列，其是一个虚拟的双向队列(虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系)。

**在AQS中所有等待锁的线程都会被包装成Node扔到一个同步队列中。**每个结点包含了一个thread类型的引用，并且每个结点还存在一个状态`waitStatus`，具体状态如下

- `CANCELLED`，值为1，表示当前的线程被取消。
- `SIGNAL`，值为-1，表示当前节点的后继节点包含的线程需要运行，需要进行unpark操作。
- `CONDITION`，值为-2，表示当前节点在等待condition，也就是在condition queue中。
- `PROPAGATE`，值为-3，表示当前场景下后续的acquireShared能够得以执行。
- 值为0，表示当前节点在sync queue中，等待着获取锁。

**Sync queue**

![dummy head](/assets/blog_res/2023-03-16-JAVA.assets/1460000016446954)

`sync queue`，同步队列，是一个双向链表，我们使用`prev`、`next`属性来串联节点。但是在这个同步队列中，我们一直没有用到`nextWaiter`属性，即使是在共享锁模式下，这一属性也只作为一个标记，指向了一个空节点，因此，在`sync queue`中，我们不会用它来串联节点。

**Condtion queue**

条件队列不是必须的，每创建一个Condtion对象就会对应一个Condtion队列，每一个调用了Condtion对象的await方法的线程都会被包装成Node扔进一个条件队列中:

![Conditon queue](/assets/blog_res/2023-03-16-JAVA.assets/1460000016462284)

每一个Condition对象对应一个Conditon队列，每个Condtion队列都是独立的，互相不影响的。在上图中，如果我们对当前线程调用了`notFull.await()`, 则当前线程就会被包装成Node加到`notFull`队列的末尾。

一般情况下，等待锁的同步队列和条件队列是相互独立的，彼此之间没有任何关系，但是当调用某个条件队列的signal方法时，会将某个或所有等待在这个条件队列中的线程唤醒，被唤醒的线程和普通线程一样要去争锁，如果没有抢到则同样要被加到等待锁的同步队列中，此时结点就**一个一个**的从条件队列转移到同步队列中。

**总结**

对于AbstractQueuedSynchronizer的分析，最核心的就是sync queue的分析。

- 每一个结点都是由前一个结点唤醒。
- 当结点发现前驱结点是head并且尝试获取成功，则会轮到该线程运行。
- condition queue中的结点向sync queue中转移是通过signal操作完成的。
- 当结点的状态为SIGNAL时，表示后面的结点需要运行。

#### ReentrantLock

ReentrantLock实现了Lock接口，Lock接口中定义了lock与unlock相关操作，并且还存在newCondition方法，表示生成一个条件。

**ReentrantLock是一种悲观锁**，它总是假设竞争条件总是会发生，所以它同一时刻只有一个线程能获得锁。其支持公平和非公平性的获取锁，内部默认是**非公平锁**, 因为非公平锁的吞吐量会比公平锁高。

由于ReentrantLock基于AQS实现的，所以它支持三种方式获取锁:

- `lock()`: 不支持中断的获取锁；
- `lockInterruptibly()`: 响应中断地获取锁；
- `tryLock(long timeout, TimeUnit unit)`: 响应中断并且支持超时获取锁。

#### ReentrantReadWriteLock

ReentrantReadWriteLock底层是基于ReentrantLock和AQS来实现的，**ReentrantReadWriteLock是一种乐观锁**，它假设竞争条件并不会经常发生，所以同一时刻能让多个线程执行。它将读写分离，在进行读操作时，多个线程可以同时获取锁，这样能更好的提高并发度。

其有以下特性：

- 公平性: 与ReentrantLock一样，ReentrantReadWriteLock内部也是支持公平性和非公平性锁，默认是非公平性的锁；
- 可重入: ReentrantReadWriteLock支持一个线程多次获取锁；
- 读写分离: ReentrantReadWriteLock内部维护两个锁，一个是读锁，另外一个是写锁. 在读多写少的情况下，ReentrantReadWriteLock能发挥更大的并发度。因为ReentrantReadWriteLock支持多个读线程同时获取锁。ReentrantReadWriteLock的读写规则: 当一个写线程获得锁后, 其他线程不能获取锁. 当读线程获得锁后, 其他的读线程可以获得锁，但是写线程不能；
- 锁降级: 当一个线程持有写锁后, 再获取读锁, 然后释放写锁, 这个过程称为一个锁的降级。ReentrantReadWriteLock不支持锁的升级, 因为锁的升级有可能带来竞争条件的问题。

AQS中的状态int类型有32位, ReentrantReadWriteLock将高16位作为读状态，低16位作为写状态，这样每次通过一定的位运算来获取高16位或者低16位。

### 9. JUC集合

#### ConcurrentHashMap

Hashtable是线程安全的，但是效率低下，因为使用了synchronized关键字对put进行加锁，而synchronized关键字是对整个对象进行加锁，所以在put操作下会把整张表锁住，所以效率低下。

在JDK1.7之前，ConcurrentHashMap是通过锁分段机制来实现的，所以最大并发度受到Segment个数的限制，而在JDK1.8中，选择了与HashMap类似的数组+链表+红黑树的方式实现，而加锁则采用CAS和Synchronized实现。

**数据结构**

在java1.7之前，concurrentHashMap是一个Segment数组，Segment通过继承ReentrantLock来进行加锁，所以每次加锁锁住的都是一个segment，这样只要保证每个segment是线程安全的即可。

而在 Java8 之后，concurrentHashMap的结构和 HashMap 基本一样，不过它要保证线程安全性，所以在源码上要复杂一些。

**并发性分析**

添加节点的操作 put 和删除节点的操作 remove 都是要加 segment 上的独占锁的，所以它们之间自然不会有问题，而由于get操作不会加锁，所以并发问题主要出现在get操作中同时发生put或remove的情况。

- put 操作的线程安全性。 
  - 初始化槽，使用了 CAS 来初始化 Segment 中的数组。
  - 添加节点到链表的操作是插入到表头的，所以，如果这个时候 get 操作在链表遍历的过程已经到了中间，是不会影响的。当然，另一个并发问题就是 get 操作在 put 之后，需要保证刚刚插入表头的节点被读取，这个依赖于 setEntryAt 方法中使用的 UNSAFE.putOrderedObject。
  - 扩容。扩容是新创建了数组，然后进行迁移数据，最后面将 newTable 设置给属性 table。所以，如果 get 操作此时也在进行，那么也没关系，如果 get 先行，那么就是在旧的 table 上做查询操作；而 put 先行，那么 put 操作的可见性保证就是 table 使用了 volatile 关键字。
- remove 操作的线程安全性。 
  - 如果 remove 破坏的节点 get 操作已经过去了，那么这里不存在任何问题。
  - 如果 remove 先破坏了一个节点，分两种情况考虑。 1、如果此节点是头节点，那么需要将头节点的 next 设置为数组该位置的元素，table 虽然使用了 volatile 修饰，但是 volatile 并不能提供数组内部操作的可见性保证，所以源码中使用了 UNSAFE 来操作数组。2、如果要删除的节点不是头节点，它会将要删除节点的后继节点接到前驱节点中，这里的并发保证就是 next 属性是 volatile 的。

## 线程池

### 1. 线程和进程的区别

进程是对运行时程序的封装，是**系统进行资源调度和分配的的基本单位，实现了操作系统的并发**；

线程是进程的子任务，**是CPU调度和分派的基本单位**，**用于保证程序的实时性，实现进程内部的并发；线程是操作系统可识别的最小执行和调度单位**。每个线程都独自占用一个**虚拟处理器**：独自的**寄存器组**，**指令计数器和处理器状态**。每个线程完成不同的任务，但是**共享同一地址空间**（也就是同样的**动态内存，映射文件，目标代码等等**），**打开的文件队列和其他内核资源**。

线程在进程下行进（单纯的车厢无法运行）

一个进程可以包含多个线程（一辆火车可以有多个车厢）

不同进程间数据很难共享（一辆火车上的乘客很难换到另外一辆火车，比如站点换乘）

同一进程下不同线程间数据很易共享（A车厢换到B车厢很容易）

进程要比线程消耗更多的计算机资源（采用多列火车相比多个车厢更耗资源）

进程间不会相互影响，一个线程挂掉将导致整个进程挂掉（一列火车不会影响到另外一列火车，但是如果一列火车上中间的一节车厢着火了，将影响到所有车厢）

进程可以拓展到多机，进程最多适合多核（不同火车可以开在多个轨道上，同一火车的车厢不能在行进的不同的轨道上）

进程使用的内存地址可以上锁，即一个线程使用某些共享内存时，其他线程必须等它结束，才能使用这一块内存。（比如火车上的洗手间）－"互斥锁"

进程使用的内存地址可以限定使用量（比如火车上的餐厅，最多只允许多少人进入，如果满了需要在门口等，等有人出来了才能进去）－“信号量”



**僵尸进程**：一个**进程**使用fork创建子**进程**，如果子**进程**退出，而父**进程**并没有调用wait 或waitpid 获取子**进程**的状态信息，那么子**进程**的**进程**描述符仍然保存在系统中，这种**进程**称之为僵尸**进程**。 

**孤儿进程**：一个父**进程**退出，而它的一个或多个子**进程**还在运行，那么这些子**进程**将成为**孤儿进程**。

### 2. FutureTask

FutureTask为Future提供了基础实现，如获取任务执行结果和取消任务等。如果任务尚未完成，获取任务执行结果时将会阻塞。一旦执行结束，任务就不能被重启或取消。FutureTask常用来封装Callable和Runnable，也可以作为一个任务提交到线程池中执行。

#### 关系

![img](/assets/blog_res/2023-03-16-JAVA.assets/java-thread-x-juc-futuretask-1.png)

FutureTask实现了RunnableFuture接口，则RunnableFuture接口继承了Runnable接口和Future接口。所以FutureTask既能当一个Runnable接口被Thread执行，也能作为Future用来得到Callable的计算结果。

#### 核心属性
```java
//内部持有的callable任务，运行完毕后置空
private Callable<V> callable;

//从get()中返回的结果或抛出的异常
private Object outcome; // non-volatile, protected by state reads/writes

//运行callable的线程
private volatile Thread runner;

//使用Treiber栈保存等待线程
private volatile WaitNode waiters;

//任务状态
private volatile int state;
private static final int NEW          = 0;
private static final int COMPLETING   = 1;
private static final int NORMAL       = 2;
private static final int EXCEPTIONAL  = 3;
private static final int CANCELLED    = 4;
private static final int INTERRUPTING = 5;
private static final int INTERRUPTED  = 6;
```

其中需要注意的是state是volatile类型的，也就是说只要有任何一个线程修改了这个变量，那么其他所有的线程都会知道最新的值。7种状态具体表示：

- `NEW`:表示是个新的任务或者还没被执行完的任务。这是初始状态。
- `COMPLETING`:任务已经执行完成或者执行任务的时候发生异常，但是任务执行结果或者异常原因还没有保存到outcome字段(outcome字段用来保存任务执行结果，如果发生异常，则用来保存异常原因)的时候，状态会从NEW变更到COMPLETING。但是这个状态会时间会比较短，属于中间状态。
- `NORMAL`:任务已经执行完成并且任务执行结果已经保存到outcome字段，状态会从COMPLETING转换到NORMAL。这是一个最终态。
- `EXCEPTIONAL`:任务执行发生异常并且异常原因已经保存到outcome字段中后，状态会从COMPLETING转换到EXCEPTIONAL。这是一个最终态。
- `CANCELLED`:任务还没开始执行或者已经开始执行但是还没有执行完成的时候，用户调用了cancel(false)方法取消任务且不中断任务执行线程，这个时候状态会从NEW转化为CANCELLED状态。这是一个最终态。
- `INTERRUPTING`: 任务还没开始执行或者已经执行但是还没有执行完成的时候，用户调用了cancel(true)方法取消任务并且要中断任务执行线程但是还没有中断任务执行线程之前，状态会从NEW转化为INTERRUPTING。这是一个中间状态。
- `INTERRUPTED`:调用interrupt()中断任务执行线程之后状态会从INTERRUPTING转换到INTERRUPTED。这是一个最终态。 有一点需要注意的是，所有值大于COMPLETING的状态都表示任务已经执行完成(任务正常执行完成，任务执行异常或者任务被取消)。

各个状态之间的可能转换关系如下图所示：

![img](/assets/blog_res/2023-03-16-JAVA.assets/java-thread-x-juc-futuretask-2.png)

### 3. 线程池

**线程池（Thread Pool）**是一种基于池化思想管理线程的工具，经常出现在多线程服务器中，如MySQL。

线程过多会带来额外的开销，其中包括创建销毁线程的开销、调度线程的开销等等，同时也降低了计算机的整体性能。线程池维护多个线程，等待监督管理者分配可并发执行的任务。这种做法，一方面避免了处理任务时创建销毁线程开销的代价，另一方面避免了线程数量膨胀导致的过分调度问题，保证了对内核的充分利用。

使用线程池可以带来一系列好处：

- **降低资源消耗**：通过池化技术重复利用已创建的线程，降低线程创建和销毁造成的损耗。
- **提高响应速度**：任务到达时，无需等待线程创建即可立即执行。
- **提高线程的可管理性**：线程是稀缺资源，如果无限制创建，不仅会消耗系统资源，还会因为线程的不合理分布导致资源调度失衡，降低系统的稳定性。使用线程池可以进行统一的分配、调优和监控。
- **提供更多更强大的功能**：线程池具备可拓展性，允许开发人员向其中增加更多的功能。比如延时定时线程池ScheduledThreadPoolExecutor，就允许任务延期执行或定期执行。

#### 线程池解决的问题

线程池解决的核心问题就是资源管理问题。

在并发环境下，系统不能够确定在任意时刻中，有多少任务需要执行，有多少资源需要投入。

#### 核心设计与实现

Java中的线程池核心实现类是ThreadPoolExecutor，ThreadPoolExecutor实现的顶层接口是Executor，顶层接口Executor提供了一种思想：将任务提交和任务执行进行解耦。用户无需关注如何创建线程，如何调度线程来执行任务，用户只需提供Runnable对象，将任务的运行逻辑提交到执行器(Executor)中，由Executor框架完成线程的调配和任务的执行部分。

ThreadPoolExecutor运行机制如图：

![图2 ThreadPoolExecutor运行流程](/assets/blog_res/2023-03-16-JAVA.assets/77441586f6b312a54264e3fcf5eebe2663494.png)

Java线程池的实现原理，简要来说时一个线程集合workerSet和一个阻塞队列workQueue。当用户向线程池提交一个任务时，线程池会先将任务放在workQueue中，workerSet中的线程会不断的从workQueue中获取线程然后执行。当workQueue中没有任务的时候，worker就会阻塞，直到队列中有任务了就取出来继续执行。

#### Execute原理

当一个任务提交至线程池之后：

- 线程池首先判断当前运行的线程数量是否少于corePoolSize，如果是，则创建一个新的工作线程来执行任务，如果都在执行任务，则进入下一步；
- 判断BlockingQueue是否已经满了，如果还没满，则将线程放入BlockingQueue，否则进入下一步；
- 如果创建一个新的工作线程将使当前运行的线程数量超过maximumPoolSize，则交给RejectedExecutionHandler来处理任务。

当ThreadPoolExecutor创建新线程时，通过CAS来更新线程池状态。

#### 线程池的创建

**通过Executors类提供的方法。**

1. **newCachedThreadPool**

   创建一个可缓存的线程池，若线程数超过处理所需，缓存一段时间后会回收，若线程数不够，则新建线程。

2. **newFixedThreadPool**

   创建一个固定大小的线程池，可控制并发的线程数，超出的线程会在队列中等待。

4. **newSingleThreadExecutor**

   创建一个单线程的线程池，可保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。
   
   -----------------------------------------（后面不常用）--------------------------------------------------
   
4. **newScheduledThreadPool**

   创建一个周期性的线程池，支持定时及周期性执行任务。

5. **newSingleThreadScheduledExecutor**

   创建一个单线程的可以执行延迟任务的线程池。

6. **newWorkStealingPool**

   创建一个抢占式执行的线程池(任务执行顺序不确定)。

**通过ThreadPoolExecutor类自定义。**

```Java
public ThreadPoolExecutor(int corePoolSize,
	int maximumPoolSize,
	long keepAliveTime,
	TimeUnit unit,
	BlockingQueue<Runnable> workQueue,
	ThreadFactory threadFactory,
	RejectedExecutionHandler handler) {
	// 省略...
}
```

具体参数如下

- `corePoolSize` 线程池中的核心线程数。当提交一个任务时，线程池创建一个新线程执行任务，直到当前线程数等于corePoolSize，即使有其他空闲的线程能够执行新来的任务，也会继续创建线程。如果当前线程数等于corePoolSize，继续提交的任务会被保存到阻塞队列中等待被执行。
- `workQueue` 用来保存等待被执行的任务的阻塞队列，在JDK中有如下队列：
  - `ArrayBlockingQueue`: 基于数组结构的有界阻塞队列，按FIFO排序任务；
  - `LinkedBlockingQueue`: 基于链表结构的阻塞队列，按FIFO排序任务，吞吐量通常要高于ArrayBlockingQueue；
  - `SynchronousQueue`: 一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQueue；
  - `PriorityBlockingQueue`: 具有优先级的无界阻塞队列；
- `maximumPoolSize` 线程池中允许的最大线程数。如果当前阻塞队列满了，且继续提交任务，则创建新的线程执行任务，直到线程数为maximumPoolSize；当阻塞队列是无界队列，则最大线程数不起作用。
- `keepAliveTime` 线程空闲时的存活时间，即当线程没有任务执行时，该线程继续存活的时间。默认情况下该参数只有线程数大于corePoolSize时才有用，超过这个时间点空闲线程将被终止。
- `unit ` keepAliveTime的单位。
- `threadFactory ` 创建线程的工厂，通过自定义的线程工厂可以给每个新建的线程设置一个具有识别度的线程名。默认为DefaultThreadFactory。
- `handler ` 线程池的饱和策略，当阻塞队列满了，且没有空闲的工作线程，如果继续提交任务，必须采取一种策略处理该任务，线程池提供了4种策略:
  - `AbortPolicy`: 直接抛出异常，默认策略；
  - `CallerRunsPolicy`: 用调用者所在的线程来执行任务；
  - `DiscardOldestPolicy`: 丢弃阻塞队列中靠最前的任务，并执行当前任务；
  - `DiscardPolicy`: 直接丢弃任务。

Executors 返回的线程池对象的弊端如下：

- FixedThreadPool 和 SingleThreadPool：允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。

- CachedThreadPool：允许的创建线程数量为 Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。

线程池的创建推荐使用最后一种 ThreadPoolExecutor 的方式来创建，因为使用它可以明确线程池的运行规则，规避资源耗尽的风险。

##### ThreadLocal

ThreadLocal（线程本地存储）提供了一种方式，让在多线程环境下，每个线程都可以拥有自己私有的数据结构，进而减少同一个线程内多个函数或者组件之间一些公共变量的传递的复杂度。但因为其自身的实现机制，使用之后记得及remove，避免内存泄露。



## 设计模式

设计模式（Design pattern）是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结。使用设计模式是为了可重用代码、让代码更容易被他人理解、保证代码可靠性。

### 1. 分类

**创建型模式：对象实例化的模式，创建型模式用于解耦对象的实例化过程。**

**结构型模式：把类或对象结合在一起形成一个更大的结构。**

**行为型模式：类和对象如何交互，及划分责任和算法。**

### 2. 特点

#### 创建型模式

单例模式：某个类只能有一个实例，提供一个全局的访问点。

简单工厂：一个工厂类根据传入的参量决定创建出那一种产品类的实例。

工厂方法：定义一个创建对象的接口，让子类决定实例化那个类。

抽象工厂：创建相关或依赖对象的家族，而无需明确指定具体类。

建造者模式：封装一个复杂对象的构建过程，并可以按步骤构造。

原型模式：通过复制现有的实例来创建新的实例。

#### 结构型模式

适配器模式：将一个类的方法接口转换成客户希望的另外一个接口。

组合模式：将对象组合成树形结构以表示“”部分-整体“”的层次结构。

装饰模式：动态的给对象添加新的功能。

代理模式：为其他对象提供一个代理以便控制这个对象的访问。

亨元（蝇量）模式：通过共享技术来有效的支持大量细粒度的对象。

外观模式：对外提供一个统一的方法，来访问子系统中的一群接口。

桥接模式：将抽象部分和它的实现部分分离，使它们都可以独立的变化。

#### 行为型模式

模板模式：定义一个算法结构，而将一些步骤延迟到子类实现。

解释器模式：给定一个语言，定义它的文法的一种表示，并定义一个解释器。

策略模式：定义一系列算法，把他们封装起来，并且使它们可以相互替换。

状态模式：允许一个对象在其对象内部状态改变时改变它的行为。

观察者模式：对象间的一对多的依赖关系。

备忘录模式：在不破坏封装的前提下，保持对象的内部状态。

中介者模式：用一个中介对象来封装一系列的对象交互。

命令模式：将命令请求封装为一个对象，使得可以用不同的请求来进行参数化。

访问者模式：在不改变数据结构的前提下，增加作用于一组对象元素的新功能。

责任链模式：将请求的发送者和接收者解耦，使的多个对象都有处理这个请求的机会。

迭代器模式：一种遍历访问聚合对象中各个元素的方法，不暴露该对象的内部结构。

## 死锁

一般来说，要出现死锁问题需要满足以下条件：

1. 互斥条件：一个资源每次只能被一个线程使用。
2. 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
3. 不剥夺条件：进程已获得的资源，在未使用完之前，不能强行剥夺。
4. 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。

只要破坏死锁 4 个必要条件之一中的任何一个，死锁问题就能被解决。

## 反射

反射是程序在运行时才知道要操作的类型，并可以获取到类的完整构造。通过反射机制，Java可以做到**运行时类型识别**，它允许运行中的Java程序对自身进行检查，能直接操作程序对内部属性和方法。

反射就是把Java中的各种成分映射成一个个Java对象。例如：一个类有：成员变量、方法、构造方法、包等等信息，利用反射技术可以对一个类进行解剖，把个个组成部分映射成一个个对象。

### Class类

Class累存在于java.lang包中，其实例表示Java应用程序运行时的类或接口。每个java类运行的时候都在JVM里表现为一个class对象，可以通过类名.class，类型.getClass()，Class.forName("类名")等方法获得class对象。数组也同样被映射为class对象的一个类，所有具有相同元素类型和位数的数组都应该共享该Class对象。基本类型也同样表现为class对象。

### 反射API

Java类成员包括以下三类：属性字段，构造函数，方法。而反射API分为以下几类：

- Field 类：提供有关类的属性信息，以及对它的动态访问权限。它是一个封装反射类的属性的类。
- Constructor 类：提供有关类的构造方法的信息，以及对它的动态访问权限。它是一个封装反射类的构造方法的类。
- Method 类：提供关于类的方法的信息，包括抽象方法。它是用来封装反射类方法的一个类。
- Class 类：表示正在运行的 Java 应用程序中的类的实例。
- Object 类：Object 是所有 Java 类的父类。所有对象都默认实现了 Object 类的方法。

### 实现原理

1. 反射类及反射方法的获取，都是通过从列表中搜寻查找匹配的方法，所以查找性能会随类的大小方法多少而变化；
2. 每个类都会有一个与之对应的Class实例，从而每个类都可以获取method反射方法，并作用到其他实例身上；
3. 反射也是考虑了线程安全的，放心使用；
4. 反射使用软引用relectionData缓存class信息，避免每次重新从jvm获取带来的开销；
5. 反射调用多次生成新代理Accessor, 而通过字节码生存的则考虑了卸载功能，所以会使用独立的类加载器；
6. 当找到需要的方法，都会copy一份出来，而不是使用原来的实例，从而保证数据隔离；
7. 调度反射方法，最终是由jvm执行invoke0()执行；

## Java19新特性

1. **记录模式**（预览版）

使用 ***记录模式*** 增强 Java 编程语言以解构记录值，可以嵌套记录模式和类型模式，实现强大的、声明性的和可组合的数据导航和处理形式。

这是一个预览语言功能。

2. **Linux/RISC-V 移植**

将 JDK 移植到 Linux/RISC-V，目前仅支持 RISC-V 的 RV64GV 配置（包含向量指令的通用 64 位 ISA）。将来可能会考虑支持其他 RISC-V 配置，例如通用 32 位配置 (RV32G)。

3. **外部函数和内存 API （预览版）**

引入一个 API，Java 程序可以通过该 API 与 Java 运行时之外的代码和数据进行互操作。通过该 API 可有效地调用外部函数（ JVM 之外的代码）和安全地访问外部内存（不受 JVM 管理的内存），使得 Java 程序能够调用本机库并处理本机数据，而不会出现 JNI 的脆弱性和危险。

这是个预览版 API 。

4. **虚拟线程（预览版）**

将虚拟线程引入 Java 平台。虚拟线程是轻量级线程，可显著地减少编写、维护和观察高吞吐量并发应用程序的工作量。

虚拟线程 `java.lang.Thread` 是在底层操作系统线程（OS 线程）上运行 Java 代码，但在代码的整个生命周期内不捕获 OS 线程的实例。这意味着许多虚拟线程可以在同一个 OS 线程上运行 Java 代码，从而有效地共享它。

虚拟线程是由 JDK 而不是操作系统提供的线程的轻量级实现，也是**用户模式线程**的一种形式。用户模式线程在 Java 的早期版本中被称为 [“绿色线程”](https://www.oschina.net/action/GoToLink?url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FGreen_threads)，当时操作系统线程的概念还不够成熟和普及， Java 的所有绿色线程都共享一个 OS 线程（M:1 调度），随着线程概念的发展，绿色线程最终被现在的平台线程超越，实现为 OS 线程的包装器（1:1 调度），而最新引入的虚拟线程采用 M:N 调度，其中大量 (M) 虚拟线程被调度为在较少数量 (N) 的 OS 线程上运行。

5. **Vector API （第四次孵化）**

引入一个 API 来表达在运行时能够可靠编译的向量计算，在支持的 CPU 架构上优化向量指令，从而实现优于标量计算的性能。

6. **Switch 模式匹配（第三预览版）**

用 `switch` 表达式和语句的模式匹配，以及对模式语言的扩展来增强 Java 编程语言。将模式匹配扩展到 `switch` 中，允许针对一些模式测试表达式，这样就可以简明而安全地表达复杂的面向数据的查询。

该特性最早在 Java 17 中作为预览版出现， Java 19 为第三次预览。

7. **结构化并发（孵化阶段）**

引入用于结构化并发的 API 来简化多线程编程，结构化并发将不同线程中运行的多个任务视为单个工作单元，从而简化错误处理、提高可靠性并增强可观察性。

这是一个孵化阶段的 API。

**Java 19创建platform thread**

`Runnable gcdRunnable = new GCDRunnable();`

`Thread thread = Thread .ofPlatform() .unstarted(gcdRunnable);`

**Structured Concurrency**：

为了让程序更易于读，理解，更快的写和更安全。

避免线程泄漏和孤儿线程，线程的生命周期都被限制在一个封闭的范围中。

模仿structured programming， 有明确的入口和出口点的执行流代码块；严格嵌套操作的生存期，以反映代码中的语法嵌套。

StructuredTaskScope是Structured Concurrency的基本接口，其定义了几个子类：ShutdownOnFailure和ShutdownOnSuccess。

## Docker

Docker的优势总结如下：

- 更快的启动时间。Docker容器启动是几秒钟的事情，因为容器只是一个操作系统进程而已。带有完整操作系统的虚拟机则需要几分钟来加载。
- 更快部署。不需要建立一个新的环境。使用Docker,Web开发团队只需要下载Docker镜像并在不同的服务器上运行。
- 容器更易管理与扩展。因为销毁与运行容器比销毁与运行虚拟机更快。
- 计算资源的更好利用，因为在一个服务器上你可以运行的容器比虚拟机要多。
- 支持多种操作系统，Windows,Mac,Debian等等。

## Zookeeper

### 1. 介绍

ZooKeeper 是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。

### 2. 解决问题

在分布式系统中，以下问题经常出现：

- 确定Leader；
- 配置协调管理；
- 群组管理；
- 分布式锁。

### 3. 设计

- 顺序一致性，从同一个客户端发起的事务请求，最终将会严格地按照其发起顺序被应用到Zookeeper中去。
- 原子性，所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，即整个集群要么都成功应用了某个事务，要么都没有应用。
- 单一视图，无论客户端连接的是哪个 Zookeeper 服务器，其看到的服务端数据模型都是一致的。
- 可靠性，一旦服务端成功地应用了一个事务，并完成对客户端的响应，那么该事务所引起的服务端状态变更将会一直被保留，除非有另一个事务对其进行了变更。
- 实时性，Zookeeper 保证在一定的时间段内，客户端最终一定能够从服务端上读取到最新的数据状态。

### 4. 组成

- 客户端: 使用Zookeeper服务，

- 服务器:用于负载平衡和容错的复制服务集成，

- 会话:客户端连接到服务器直到其关闭，

- Znode:客户端的内存数据对象。像传统的文件系统但不存储太多的文件。

  临时znode:在会话中保持活动，在关闭时进行清理。

  普通znode:由用户创建，由Zookeeper服务维护的根节点。



## 消息队列

### 1. 基础

消息队列中间件是分布式系统中重要的组件，主要用于应用解耦，异步消息，流量削峰等问题。实现高性能，高可用，可伸缩和最终一致性架构。目前使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，RocketMQ。

MQ是消费者-生产者的一个典型代表，一端往消息队列中不断写入消息，而另一端则可以读取队列中的消息。消息的发布者只管把消息发布到MQ中而不管谁来取用，消息使用者只管从MQ中取消息而不关注是谁发布的。

### 2. MQ通信模型

MQ通信模型有以下类型

- **点对点**：点对点方式是最传统的通讯方式，它支持一对一，一对多，多对多和多对一等配置方式，支持树状，网状等拓扑结构。

- **多点广播**：能够将消息发送到多个目标站点，并确保为每一个站点可靠的提供消息。

- **发布-订阅**：Pub-Sub模式使得消息的分发可以突破目的队列地理位置的限制，使消息按照特定的主题甚至内容进行分发，用户或应用可以根据主题或内容接受所需要的消息。Pub-Sub模式使得发送者和接收者之间的耦合关系变得更加松散。

- **集群**：为了简化点对点通讯模式中的系统配置，MQ 提供 Cluster(集群) 的解决方案。集群类似于一个域，集群内部的队列管理器之间通讯时，不需要两两之间建立消息通道，而是采用集群通道与其它成员通讯，从而大大简化了系统配置。此外，集群中的队列管理器之间能够自动进行负载均衡，当某一队列管理器出现故障时，其它队列管理器可以接管它的工作，从而大大提高系统的高可靠性

### 3. MQ的应用

#### 异步处理

MQ可以将系统之间的处理流程异步化，减少等待响应的时间，从而提高整体并发吞吐量。一般MQ异步处理应用于非核心流程，例如短信/邮件通知，数据推送，上报数据等。

![img](/assets/blog_res/2023-03-16-JAVA.assets/mq_4.png)

#### 系统解耦

通过MQ，可以消除系统之间的强耦合，其优点如下

- 消息的消费者系统可以随意增加，无需修改生产者的系统代码；
- 生产者系统和消费者系统彼此不会影响对方的流程。
  - 如果生产者系统宕机，消费者系统收不到消息，就不会有下一步的动作。
  - 如果消费者系统宕机，生产者系统让然可以正常发送消息，不影响流程。

![img](/assets/blog_res/2023-03-16-JAVA.assets/mq_2.png)

#### 流量削峰

当上下游处理能力存在差距时，利用MQ做一个漏斗模型，进行流控，可以把MQ当成可靠的消息暂存地，进行一定程度的消息堆积，在下游有能力处理的时候在进行发送。MQ 的流量削峰常用于高并发场景（例如：秒杀、团抢等业务场景），它是缓解瞬时暴增流量的核心手段之一。

![img](/assets/blog_res/2023-03-16-JAVA.assets/mq_6.png)

#### 传输缓冲

MQ常被用于做海量数据的传输缓冲，例如kafka常被用于做为各种日志数据、采集数据的数据中转。然后，Kafka 将数据转发给 Logstash、Elasticsearch 中，然后基于 Elasticsearch 来做日志中心，提供检索、聚合、分析日志的能力。开发者可以通过 Kibana 集成 Elasticsearch 数据进行可视化展示，或自行进行定制化开发。

MQ也可以被用于流式处理，比如Kafka几乎已经是流计算的数据采集端的标准组件。而流计算通过实时数据处理能力，提供了更为快捷的聚合计算能力，被大量应用于链路监控、实时监控、实时数仓、实时大屏、风控、推荐等应用领域。

### 4. MQ的问题

#### 重复消费

以Kafka为例，Kakfa的每个Partition都是一个有序的，不可变的记录序列，不断追加到结构化的提交日志中。Partition 中为每条记录分配一个连续的 id 号，称为偏移量（Offset），用于唯一标识 Partition 内的记录。

Kafka 的客户端和 Broker 都会保存 Offset。客户端消费消息后，每隔一段时间，就把已消费的 Offset 提交给 Kafka Broker，表示已消费。

如果客户端应用消费消息后，因为宕机，重启等没有提交已消费的Offset，当系统恢复后就会出现重复提交。

应对重复消费的方式就是在业务层面通过幂等性设计来解决。比如重复判断，全局唯一ID。

#### 消息丢失

唯一可能导致消费方丢失数据的情况是：消费方设置了**自动提交 Offset**。可以关闭此功能来防止消息丢失。

#### 消息的顺序性

写入数据到 Partition 时指定一个全局唯一的 ID，例如订单 ID。发送方保证相同 ID 的消息有序的发送到同一个 Partition。

#### 消息积压

临时增加Consumer的数量。

### 5. MQ的高可用：以Kafka为代表

#### Kafka核心概念

Kafka包含以下几部分

- **Broker**：Kafka集群包含一个或多个节点，这种节点被称为Broker；
- **Topic**：每条发布到Kafka集群里的消息都有一个类别，这个类别被称为Topic。不同 Topic 的消息是物理隔离的；同一个 Topic 的消息保存在一个或多个 Broker 上，但用户只需指定消息的 Topic 即可生产或消费数据而不必关心数据存于何处。
- **Partition**：提高了Kafla的吞吐率，每个Topic包含一个或多个Partition，每个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition所有的消息和索引文件。

![img](/assets/blog_res/2023-03-16-JAVA.assets/kafka-cluster-roles.png)

#### Kafka的副本机制

为了实现高可用，Kafka 引入了复制功能。**每个 Partition 都有一个 Leader，零个或多个 Follower**。Leader 和 Follower 都是 Broker，每个 Broker 都会成为某些分区的 Leader 和某些分区的 Follower，因此集群的负载是平衡的。Leader处理一切对分区的读写请求，而Follower只需被动的同步Leader上的数据。

同一个Topic的不同Partition会分布在多个Broker上，而且一个Partition还会在其他的Broker上进行备份。发布者在发布消息到某个分区时，先找到该 Partition 的 Leader，然后向这个 Leader 推送消息；每个 Follower 都从 Leader 拉取消息，拉取消息成功之后，向 Leader 发送一个 ACK 确认。

#### Kafka 选举 Leader

Partition 在多个 Broker 上存在副本，如果某个 Follower 宕机，啥事儿没有，正常工作。如果 Leader 宕机了，会从 Follower 中**重新选举**一个新的 Leader。