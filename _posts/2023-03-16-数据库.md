---
title: 数据库
date: 2022-03-16 10:34:00 +0800
categories: [笔记]
tags: [数据库]
pin: true
author: Eraser

toc: true
comments: true
typora-root-url: ../../eraseryao.github.io
math: false
mermaid: true
---

# 数据库

## MySQL

### 1. InnoDB引擎

MySQL支持数个存储引擎作为对不同表的类型的处理器。MySQL存储引擎包括处理事务安全表的引擎和处理非事务安全表的引擎。

- **MyISAM**管理非事务表。它提供高速存储和检索，以及全文搜索能力。MyISAM在所有MySQL配置里被支持，它是MySQL之前的默认存储引擎。
- **MEMORY**存储引擎提供"内存中"表。MERGE存储引擎允许集合将被处理同样的MyISAM表作为一个单独的表。就像MyISAM一样，MEMORY和MERGE存储引擎处理非事务表，这两个引擎也都被默认包含在MySQL中。

现在MySQL默认采用**InnoDB引擎**，其兼具可靠性和高性能，其为多线程的模型。其主要优点有：

1. 其DML操作，即数据操作语言遵循ACID模型，具有提交，回滚和崩溃回复等功能，可以有效保护数据。
2. 行级锁定，表示只针对当前操作的行进行加锁，可以大大减少数据库的冲突，增加并发度。
3. 将数据安排在磁盘上，来优化基于主键的查询。而且每一个表都有主键索引。
4. 支持外键约束，来保持数据的完整性。

#### **InnoDB如何存储数据**

为了提高一次读取的效率，减少I/O操作，InnoDB按照**数据页**来读写的。数据库I/O的最小单位是页，InnoDB默认数据页大小为**16KB**。

数据页包含七个部分如下：

![数据页](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/243b1466779a9e107ae3ef0155604a17.png)

**文件头**：用于表示页的信息；

**页头**：表示页的状态信息；

**最小和最大记录**：两个虚拟的为记录，用来记录分页中的最小记录和最大记录；

**用户记录**：储存行记录数据；

**空闲空间**：页中还没被使用的空间；

**页目录**：存储用户记录的相对位置，对记录起到索引作用；

**文件尾**：检验页是否完整。

在文件头中有两个指针，分别指向上一个数据页和下一个数据页，相当于双向链表：

![数据页链表](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/557d17e05ce90f18591c2305871af665.png)

#### 数据页中用户记录如何组织数据

数据页中的记录是按照主键顺序来组成单向链表，由于单链表检索效率不高，所以要在数据页中加入一个页目录来起到索引的作用。在InnoDB中，页目录与记录的关系如下：

![索引](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/261011d237bec993821aa198b97ae8ce.png)

页目录的创建过程如下：

1. 将所有的记录划分成几组，包括最小记录和最大记录，但不包括已删除的记录（mysql会用标签标记已删除的记录但并不擦除）；
2. 每个记录组的最后一条记录就是组内最大的那条记录，并且最后一条记录的头信息中会存储该组一共有多少条记录，作为n_owned字段；
3. 页目录用来存储每组最后一条数据的地址偏移量，这些地址偏移量会按照先后顺序存储，每组的地址偏移量也被称之为slot，**每个slot相当于指针指向了不同组的最后一个记录**。

页目录就是由多个槽组成的，槽相当于分组记录的索引。因为记录按照从小到大排列，所以可以用二分法查找，定位到槽后，再遍历槽中的内容，找到记录。

InnoDB的分组一般遵循以下原则：

- 第一个分组中的记录只能有 1 条记录；
- 最后一个分组中的记录条数范围只能在 1-8 条之间；
- 剩下的分组中记录条数范围只能在 4-8 条之间。

### 2. **SQL语句执行**

![mysql查询流程](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/mysql%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B.png)

连接器：MySQL基于TCP，最大连接数由 max_connections 参数控制。

查询缓存：对于更新比较频繁的表，查询缓存的命中率很低的，因为只要一个表有更新操作，那么这个表的查询缓存就会被清空，所以一般不用。

解析语句：词法分析和语法分析。

预处理器：查询表或字段是否存在，将*拓展为表上所有列。

优化器：确定SQL查询的执行方案，选择索引。

执行器：主键索引查询，全表扫描，索引下推。

#### MySQL连接池

连接池是connection对象的缓冲区，它里面会放一些connection，当程序需要连接的时候，不需要重新创建连接，直接从连接池中获取即可。

数据库连接池就是在程序启动时就创建一定数量的数据库连接，将这些连接放入一个池子进行管理。由程序动态的进行连接的申请、使用和释放。

其有以下好处

- **资源复用**：避免频繁创建连接，销毁带来的性能开销，减少系统资源消耗；
- **更快的响应速度**：由于程序启动时就准备好了若干连接备用，业务请求直接使用即可，不需要实时进行连接的创建。
- **统一的连接管理，避免数据库连接泄露**：可预先设定连接占用的超时时间，假如某条连接被占用超过设定值，可以强制回收该连接。

数据库连接池有以下

- **C3P0**：太古老，代码及其复杂，不利于维护。
- **dbcp**：是 apache上的一个 java 连接池项目，也是 tomcat 使用的连接池组件。
- **druid**：是alibba出品的一个功能比较全面，且扩展性较好的数据库连接池，比较方便对jdbc接口进行监控跟踪等。
- **HikariCP**：光连接池，目前被SpringBoot2官方推荐使用的数据库连接池。

### 3. **索引：数据的目录**

#### 分类：

- 按「数据结构」分类：**B+tree索引、Hash索引、Full-text索引**。
- 按「物理存储」分类：**聚簇索引（主键索引）、二级索引（辅助索引）**。
- 按「字段特性」分类：**主键索引、唯一索引、普通索引、前缀索引**。
- 按「字段个数」分类：**单列索引、联合索引**。

#### B树/B+树

B+ 树就是对 B 树做了一个升级，MySQL 中索引的数据结构就是采用了 B+ 树，B+ 树结构如下图：

![B+树](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/b6678c667053a356f46fc5691d2f5878.png)

B+ 树与 B 树差异的点，主要是以下这几点：

- 叶子节点（最底部的节点）才会存放实际数据（索引+记录），非叶子节点只会存放索引；
- 所有索引都会在叶子节点出现，叶子节点之间构成一个有序链表；
- 非叶子节点的索引也会同时存在在子节点中，并且是在子节点中所有索引的最大（或最小）。
- 非叶子节点中有多少个子节点，就有多少个索引。

当我们需要存储大量记录时，需要建立多个数据页。**InnoDB采用B+树作为索引**，因为B+树更为矮胖，可以减少磁盘操作的次数。

InnoDB的B+树中每一个结点都是一个数据页：

![InnoDB的B+树索引](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/7c635d682bd3cdc421bb9eea33a5a413.png)



**B+树和B树区别，为什么用B+树**

B+Tree 只在叶子节点存储数据，而 B 树的非叶子节点也要存储数据，所以 B+Tree 的单个节点的数据量更小，在相同的磁盘 I/O 次数下，就能查询更多的节点。

另外，B+Tree 叶子节点采用的是双链表连接，适合 MySQL 中常见的基于范围的顺序查找，而 B 树无法做到这一点。

二叉树只有两个叶子结点，层次太多，IO操作更频繁。

Hash 表不适合做范围查询，它更适合做等值的查询。

#### 不同索引：

(1) **主键索引**（聚簇索引）和**二级索引**（辅助索引）

区别：

- 主键索引的 B+Tree 的叶子节点存放的是实际数据，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里；
- 二级索引的 B+Tree 的叶子节点存放的是主键值，而不是实际数据。

当根据二级索引查询的时候，根据二级索引的B+树得到主键值，再用主键的B+树进行查找得到数据，这个操作叫做回表。当查询的数据可以在二级索引的B+树里查到，就叫做**覆盖索引**。

在InnoDB中，由于表的数据放在主键索引的叶子结点里，所以InnoDB一定会为表创建一个主键索引，且由于这个数只会保存一份，所以主键索引只能有一个。

InnoDB创建主键索引遵循以下原则：

- 如果有主键，默认会使用主键作为聚簇索引的索引键；
- 如果没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键；
- 在上面两个都没有的情况下，InnoDB 将自动生成一个隐式自增 id 列作为聚簇索引的索引键。

一张表只能有一个主键索引，但是可以有多个二级索引，二级索引的叶子结点存放主键值，其B+树结构如下：

![二级索引B+树](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/3104c8c3adf36e8931862fe8a0520f5d.png)

- B+ 树的叶子节点之间是用「双向链表」进行连接，这样的好处是既能向右遍历，也能向左遍历。
- B+ 树点节点内容是数据页，数据页里存放了用户的记录以及各种信息，每个数据页默认大小是 **16 KB**。



(2) **唯一索引**，**普通索引**和**前缀索引**

唯一索引可以有多个，可以为空值；普通索引可以重复，用INDEX(column,...)创建。

前缀索引是指对字符类型字段的前几个字符建立的索引，而不是在整个字段上建立的索引，用来减少储存空间。

(3) **联合索引**

将多个字段组合成一个索引，其B+树如下所示，叶子结点为双向链表：





![联合索引](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/%E8%81%94%E5%90%88%E7%B4%A2%E5%BC%95.png)

使用联合索引时遵循**最左匹配**原则，如果在查询到时候不遵循最左匹配原则，索引就会失效。在索引为(a,b,c)的情况下，是先按 a 排序，在 a 相同的情况再按 b 排序，在 b 相同的情况再按 c 排序。所以，**b 和 c 是全局无序，局部相对有序的**，如果查询时没有a，则会索引失效。

范围查询：

假设数据表中(a,b)作为联合主键，其范围查询分为以下几种情况

1. `SELECT * FROM <table> WHERE a>1 AND b=2`

   由于联合索引是根据a的顺序排序的，所以先按照a的范围进行索引查询，程序找到a>1的部分，向后扫描，在a>1的部分里b的值是无序的，所以b字段无法用到联合索引。
   
2. `SELECT * FROM <table> WHERE a>=1 AND b=2`

   与上面不同的是，在a=1的时候，b的字段是有序的，所以当a=1的时候，直接找到b=2，从这之后往后扫描，可以减少二级索引的记录范围，这时a和b都用了联合索引。

3. `SELECT * FROM <table> WHERE a BETWEEN 2 AND 8 AND b=2`

   在mysql中，between为两侧闭区间，所以a和b都可以用到联合索引。

4. `SELECT * FROM <table> WHERE a LIKE ‘j%’ AND b=2`

   这里a的扫面范围是[j,k)，所以a和b都可以用到联合索引。

(4) **索引优化**：

**前缀索引优化**，使用某个字段中字符串的前几个字符建立索引，减小索引字段的大小。

**覆盖索引优化**，指语句中查询的所有字段都在联合索引中，用来减少

**主键自增**。提高性能，避免出现页分裂。

**索引下推优化**， 可以在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。

**防止索引失效**，尽量利用索引进行查询。当存在`%like%`和`%like`查询时会发生索引失效。

(5) **索引区分度**：是某个字段 column 不同值的个数「除以」表的总行数。

(6) **索引失效**：

- 当我们使用左或者左右模糊匹配的时候，也就是 `like %xx` 或者 `like %xx%`这两种方式都会造成索引失效；
- 当我们在查询条件中对索引列使用函数，就会导致索引失效。
- 当我们在查询条件中对索引列进行表达式计算，也是无法走索引的。
- MySQL 在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较。如果字符串是索引列，而条件语句中的输入参数是数字的话，那么索引列会发生隐式类型转换，由于隐式类型转换是通过 CAST 函数实现的，等同于对索引列使用了函数，所以就会导致索引失效。
- 联合索引要能正确使用需要遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。
- 在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。

#### COUNT函数

按照性能，`count(*)=count(1)>count(主键字段)>count(字段)`

`count(*)=count(0)`其对主键索引进行遍历，将读取到的记录返回server层，但不读取记录中的任何字段的值。如果不为null就让count字段+1

`count(主键)`会读取主键值，而`count(字段)`对进行全表扫描。

### 5. 事务

#### 事务的特性

事务是由 MySQL 的引擎来实现的，我们常见的 InnoDB 引擎它是支持事务的。事务具有以下四个特性(ACID)：

- **原子性（Atomicity）**：一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样，就好比买一件商品，购买成功时，则给商家付了钱，商品到手；购买失败时，则商品在商家手中，消费者的钱也没花出去。
- **一致性（Consistency）**：是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态。比如，用户 A 和用户 B 在银行分别有 800 元和 600 元，总共 1400 元，用户 A 给用户 B 转账 200 元，分为两个步骤，从 A 的账户扣除 200 元和对 B 的账户增加 200 元。一致性就是要求上述步骤操作后，最后的结果是用户 A 还有 600 元，用户 B 有 800 元，总共 1400 元，而不会出现用户 A 扣除了 200 元，但用户 B 未增加的情况（该情况，用户 A 和 B 均为 600 元，总共 1200 元）。
- **隔离性（Isolation）**：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致，因为多个事务同时使用相同的数据时，不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的。也就是说，消费者购买商品这个事务，是不影响其他消费者购买的。
- **持久性（Durability）**：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。

#### 并行事务引发的问题：

1. 脏读

   **如果一个事务读到了另一个未提交事务修改过的数据，就意味着发生了脏读现象**

   ![脏读](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/10b513008ea35ee880c592a88adcb12f.png)

   如上图所示，如果事务A发生了回滚，那么B会读到过期的数据。

2. 不可重复读

   **在一个事务内多次读取同一个数据，如果出现前后两次读到数据不一样的情况，就意味着发生了不可重复读**

   ![不可重复读](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/f5b4f8f0c0adcf044b34c1f300a95abf.png)

   比如当事务A第一次读取余额数据后，事务B更新了余额数据，在提交前，事务A再次读取了这条数据，就会发生两次读取不一致的情况。

3. 幻读

   **在一个事务内多次查询符合条件的记录数量，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了幻读**

   ![幻读](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/d19a1019dc35dfe8cfe7fbff8cd97e31.png)

   当事务A第一次读取符合条件的记录数量后，事务B插入了一条数据，而当A再次读取记录数量后会发现数量改变，发生了幻读。

**严重性：脏读>不可重复读>幻读**

#### 事务的隔离级别：

- **读未提交（read uncommitted）**，指一个事务还没提交时，它做的变更就能被其他事务看到；
- **读提交（read committed）**，指一个事务提交之后，它做的变更才能被其他事务看到；
- **可重复读（repeatable read）**，指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，**MySQL InnoDB 引擎的默认隔离级别**；
- **串行化（serializable）**；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；

**隔离水平高低：串行化>可重复读>读已提交>读未提交**

针对不同的隔离级别，并发事务可能发生的现象不同

![并发事务](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/4e98ea2e60923b969790898565b4d643.png)

**实现方式**

对于读未提交，直接读取最新数据；

对于串行化，通过加读写锁的方式来避免并行访问；

对于读提交和可重复读的事务来说，他们是通过**Read View**实现的，类似于数据快照。读提交是在每个语句执行前都会重新生成一个Read View，而可重复读诗在启动事务时生成一个Read View，然后整个事务中就用这个Read View。

**Read View**

Read View有四个重要的字段：

- m_ids ：指的是在创建 Read View 时，当前数据库中「活跃事务」的**事务 id 列表**，注意是一个列表，**“活跃事务”指的就是，启动了但还没提交的事务**。
- min_trx_id ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 **id 最小的事务**，也就是 m_ids 的最小值。
- max_trx_id ：这个并不是 m_ids 的最大值，而是**创建 Read View 时当前数据库中应该给下一个事务的 id 值**，也就是全局事务中最大的事务 id 值 + 1；
- creator_trx_id ：指的是**创建该 Read View 的事务的事务 id**。

聚簇索引中的两个隐藏列：

对于InnoDB，其主键索引中包含两个隐藏列：

- trx_id，当一个事务对某条聚簇索引记录进行改动时，就会**把该事务的事务 id 记录在 trx_id 隐藏列里**；
- roll_pointer，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后**这个隐藏列是个指针，指向每一个旧版本记录**，于是就可以通过它找到修改前的记录。

在创建Read View后，记录可以分三种情况：

![trx_id](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/ReadView.drawio.png)

- 如果记录的 trx_id 值小于 Read View 中的 `min_trx_id` 值，表示这个版本的记录是在创建 Read View **前**已经提交的事务生成的，所以该版本的记录对当前事务**可见**。
- 如果记录的 trx_id 值大于等于 Read View 中的 `max_trx_id` 值，表示这个版本的记录是在创建 Read View **后**才启动的事务生成的，所以该版本的记录对当前事务**不可见**。
- 如果记录的 trx_id 值在 Read View 的`min_trx_id`和`max_trx_id`之间，需要判断 trx_id 是否在 m_ids 列表中：
  - 如果记录的 trx_id **在** `m_ids` 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务**不可见**。
  - 如果记录的 trx_id **不在** `m_ids`列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务**可见**。

**这种通过版本链来控制并发事务访问同一个记录的行为就叫MVCC多版本并发控制**。

### 6. 日志

#### undo log（回滚日志）

在执行一条增删改语句的时候，MySQL会隐式开启事务来执行。执行一条语句是否自动提交事务是由`autocommit`参数决定的，默认开启。

如果在提交事务之前，MySQL发生了崩溃，就会调用undo log。它是 Innodb 存储引擎层生成的日志，通过事务回滚实现了事务中的**原子性**，也时实现 MVCC的关键因素之一。

#### Buffer Pool（缓冲池）

为了提高数据库的读写性能，InnoDB设计了一个缓冲池。有了缓冲池后：

- 当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。
- 当修改数据时，如果数据存在于 Buffer Pool 中，那直接修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页（该页的内存数据和磁盘上的数据已经不一致），为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。

在MySQL启动的时候，InnoDB回味Buffer Pool申请一片连续的内存空间，然后按照默认16kb的大小划分出一个个的页，缓冲池中的页就叫缓存页。缓存页的组成如下所示：

![缓冲池](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/bufferpool%E5%86%85%E5%AE%B9.drawio.png)

#### redo log（重做日志）

由于Buffer Pool是基于内存的，为了防止断电重启导致数据丢失，当有一条记录需要更新的时候，InnoDB就会先更新内存，同时标记为脏页，然后将本次对这个页的修改以redo log的形式记录下来，这时候算更新完成。其是Innodb 存储引擎层生成的日志，实现了事务中的**持久性**。

然后，InnoDB会在适当的时候，有后台线程将缓存在Buffer Pool的脏页刷新到磁盘，这就是**WAL （Write-Ahead Logging）技术**。

**WAL 技术指的是， MySQL 的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上**。其过程如下图：

![WAL](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/wal.png)

#### binlog （归档日志）

Binlog是 Server 层生成的日志，主要用于数据备份和主从复制。MySQL在完成一条更新操作后，Server层还会生成一条binlog，等之后事务提交的时候，会将该事务执行过程中产生的所有binlog同意写入binlog文件。

binlog文件是记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作。

redo log和binlog有四点不同：

1. **适用对象不同**

   - binlog是mysql的server层实现的日志，所有存储引擎都可以用；
   - redo log是InnoDB存储引擎实现的日志。

2. **文件格式不同**

   binlog有3种格式类型，而redo log是物理日志。

3. **写入方式不同**

   - binlog是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志；
   - redo log是循环写，日志空间大小固定。

4. **用途不同**

   - binlog用于备份恢复，主从复制；
   - redo log用于掉电等故障恢复。

### 7. 锁

#### 全局锁

将数据库变为只读状态，对数据库修改的操作都会被阻塞。

`flush tables with read lock` `unlock tables`

全局锁的应用场景主要是全库逻辑备份，这样在备份数据库期间，不会因为数据或表结构的更新，出现数据不一致的情况。但是加上全局锁后，在数据库备份期间，就会造成业务停滞。

#### 表级锁

#### 1. 表锁

如果相对学生表加锁，可以用一下命令。

```sql
//表级别的共享锁，也就是读锁；
lock tables t_student read;

//表级别的独占锁，也就是写锁；
lock tables t_stuent write;
```

表锁会限制别的线程的读写之外，也会限制本线程接下来的读写操作。

#### 2. 元数据锁(MDL)

当我们对数据表进行操作的时候，会自动给这个表加上MDL：

- 对一张表进行 CRUD 操作时，加的是 **MDL 读锁**；
- 对一张表做结构变更操作的时候，加的是 **MDL 写锁**；

MDL是为了保证用户执行CRUD操作的时候，防止其他线程改变表结构。

其在**事务被提交后**才会释放，所以在事务执行期间，MDL是一直持有的。而且**写锁的优先级高于读锁**。

#### 3. 意向锁

- 在使用 InnoDB 引擎的表里对某些记录加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」；
- 在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」；

当执行插入，更新，删除操作时，要先对表加上意向独占锁，然后对该记录加独占锁，而普通的SELECT语句是利用MVCC来实现一致性读的，是无锁的。

意向锁是表级锁，不会与行级锁冲突。**意向锁的目的是为了快速判断表中是否有记录被加锁**。

#### 4. AUTO-INC锁

表的主键自增是根据声明`AUTO_INCREMENT`实现的，之后在数据表中**插入数据时，会给表加一个AUTO-INC锁**，然后被自增修饰的字段赋值，等插入语句执行完成后，才会把锁释放掉。

但是大量插入数据时，AUTO-INC会降低性能，所以在MySQL 5.1.22后InnoDB存储引擎提供了一种轻量级的锁，当插入语句执行时，会被`AUTO INCREMENT`加一个轻量锁，然后给改字段赋值一个字增的值，就把这个轻量级的锁释放了，而不需要等待整个插入语句执行完成后在释放。

#### 行级锁

InnoDB支持行级加锁。如果要在查询时对记录加行锁，可以用如下语句，这种查询会加锁的语句称为锁定读。

```sql
//对读取的记录加共享锁
select ... lock in share mode;

//对读取的记录加独占锁
select ... for update
```

上面两条语句必须在一个事务中，因为当事务被提交了，锁就会被释放，所以在使用这两条语句的时候要加上begin，start transaction或者set autocommit=0。

**共享锁（S锁）满足读读共享，读写互斥。独占锁（X锁）满足写写互斥、读写互斥。**

![SX](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/x%E9%94%81%E5%92%8Cs%E9%94%81.png)

#### 1. Record Lock

Record Lock称为记录锁，锁住的是一条记录，而且是有S锁和X锁之分的：

- 当一个事务对一条记录加了 S 型记录锁后，其他事务也可以继续对该记录加 S 型记录锁（S 型与 S 锁兼容），但是不可以对该记录加 X 型记录锁（S 型与 X 锁不兼容）;
- 当一个事务对一条记录加了 X 型记录锁后，其他事务既不可以对该记录加 S 型记录锁（S 型与 X 锁不兼容），也不可以对该记录加 X 型记录锁（X 型与 X 锁不兼容）。

#### 2. Gap Lock

Gap Lock称为间隙锁，只存在于可重复读隔离级别，目的是为了可重复读隔离级别下幻读的现象。

举例来说，表中有一个3-5的间隙锁，那么其他事务就无法插入。

![间隙锁](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/gap%E9%94%81.drawio.png)

**间隙锁之间是兼容的，即两个事务可以同时持有包含共同间隙范围的间隙锁，并不存在互斥关系，因为间隙锁的目的是防止插入幻影记录而提出的。**

#### 3. Next-Key Lock

Next-key Lock称为临键锁，是Record Lock+Gap Lock的组合，锁定一个范围，并且锁定记录本身。

**next-key lock 是包含间隙锁+记录锁的，如果一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，是会被阻塞的。**

#### 4. 插入意向锁

一个事务在插入一条记录的时候需要判断插入位置是否依旧被其他事务加了间隙锁，如果有的话，插入操作就会发生阻塞，知道拥有间隙锁的那个事务提交为止，在此期间会生成一个插入意向锁，表明有事务想在某个区间插入新纪录，但是现在处于等待状态。

举个例子，假设事务 A 已经对表加了一个范围 id 为（3，5）间隙锁。

![意向锁](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/gap%E9%94%81.drawio-20230318222143819.png)

当事务A还没有提交的时候，事务B向该表插入一条id=4的新纪录，这时会判断到插入的位置已经被事务 A 加了间隙锁，于是事物 B 会生成一个插入意向锁，然后将锁的状态设置为等待状态（PS：MySQL 加锁时，是先生成锁结构，然后设置锁的状态，如果锁状态是等待状态，并不是意味着事务成功获取到了锁，只有当锁状态为正常状态时，才代表事务成功获取到了锁），此时事务 B 就会发生阻塞，直到事务 A 提交了事务。

**插入意向锁的名字虽然有意向锁，但他并不是意向锁，他是一种特殊的间隙锁，属于行级别锁。**

#### MySQL如何加行级锁

**加锁的对象是索引，加锁的基本单位是next-key lock**，他是由记录锁和间隙锁组合而成的，**next-key lock 是前开后闭区间，而间隙锁是前开后开区间**。

但是，next-key lock在一些场景下会退化为记录锁或间隙锁，即**在能适应记录锁或间隙锁就能避免幻读的场景下，next-key lock就会退化成记录锁或间隙锁。**

#### 1. 唯一索引等值查询

当我们使用唯一索引进行等值查询的时候，查询的记录存在与否，加锁的规则也会不同。

- 当查询的记录是「存在」的，在索引树上定位到这一条记录后，将该记录的索引中的 next-key lock 会**退化成「记录锁」**。
- 当查询的记录是「不存在」的，在索引树找到第一条大于该查询记录的记录后，将该记录的索引中的 next-key lock 会**退化成「间隙锁」**。

#### 2. 唯一索引范围查询

当唯一索引进行范围查询时，**会对每一个扫描到的索引加 next-key 锁，然后如果遇到下面这些情况，会退化成记录锁或者间隙锁**：

- 情况一：针对「大于等于」的范围查询，因为存在等值查询的条件，那么如果等值查询的记录是存在于表中，那么该记录的索引中的 next-key 锁会**退化成记录锁**。
- 情况二：针对「小于或者小于等于」的范围查询，要看条件值的记录是否存在于表中：
  - 当条件值的记录不在表中，那么不管是「小于」还是「小于等于」条件的范围查询，**扫描到终止范围查询的记录时，该记录的索引的 next-key 锁会退化成间隙锁**，其他扫描到的记录，都是在这些记录的索引上加 next-key 锁。
  - 当条件值的记录在表中，如果是「小于」条件的范围查询，**扫描到终止范围查询的记录时，该记录的索引的 next-key 锁会退化成间隙锁**，其他扫描到的记录，都是在这些记录的索引上加 next-key 锁；如果「小于等于」条件的范围查询，扫描到终止范围查询的记录时，该记录的索引 next-key 锁不会退化成间隙锁。其他扫描到的记录，都是在这些记录的索引上加 next-key 锁。

#### 3. 非唯一索引等值查询

当我们用非唯一索引进行等值查询的时候，**因为存在两个索引，一个是主键索引，一个是非唯一索引（二级索引），所以在加锁时，同时会对这两个索引都加锁，但是对主键索引加锁的时候，只有满足查询条件的记录才会对它们的主键索引加锁**。

针对非唯一索引等值查询时，查询的记录存不存在，加锁的规则也会不同：

- 当查询的记录「存在」时，由于不是唯一索引，所以肯定存在索引值相同的记录，于是**非唯一索引等值查询的过程是一个扫描的过程，直到扫描到第一个不符合条件的二级索引记录就停止扫描，然后在扫描的过程中，对扫描到的二级索引记录加的是 next-key 锁，而对于第一个不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。同时，在符合查询条件的记录的主键索引上加记录锁**。
- 当查询的记录「不存在」时，**扫描到第一条不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。因为不存在满足查询条件的记录，所以不会对主键索引加锁**。

#### 4. 非唯一索引范围查询

非唯一索引和主键索引的范围查询的加锁也有所不同，不同之处在于**非唯一索引范围查询，索引的 next-key lock 不会有退化为间隙锁和记录锁的情况**，也就是非唯一索引进行范围查询时，对二级索引记录加锁都是加 next-key 锁。

#### 5. 没有加锁的查询

**如果锁定读查询语句，没有使用索引列作为查询条件，或者查询语句没有走索引查询，导致扫描是全表扫描。那么，每一条记录的索引上都会加 next-key 锁，这样就相当于锁住的全表，这时如果其他事务对该表进行增、删、改操作的时候，都会被阻塞**。

不只是锁定读查询语句不加索引才会导致这种情况，update 和 delete 语句如果查询条件不加索引，那么由于扫描的方式是全表扫描，于是就会对每一条记录的索引上都会加 next-key 锁，这样就相当于锁住的全表。

因此，**在线上在执行 update、delete、select ... for update 等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了**。

#### MySQL死锁

死锁的四个必要条件：**互斥、占有且等待、不可强占用、循环等待**。只要系统发生死锁，这些条件必然成立，但是只要破坏任意一个条件就死锁就不会成立。

在数据库层面，有两种策略通过「打破循环等待条件」来解除死锁状态：

- **设置事务等待锁的超时时间**。当一个事务的等待时间超过该值后，就对这个事务进行回滚，于是锁就释放了，另一个事务就可以继续执行了。在 InnoDB 中，参数 `innodb_lock_wait_timeout` 是用来设置超时时间的，默认值时 50 秒。

  当发生超时后，就出现下面这个提示：

- **开启主动死锁检测**。主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 `innodb_deadlock_detect` 设置为 on，表示开启这个逻辑，默认就开启。

  当检测到死锁后，就会出现下面这个提示：

## Redis

### 1. 基础

Redis 是一种基于内存的数据库，对数据的读写操作都是在内存中完成，因此**读写速度非常快**，常用于**缓存，消息队列、分布式锁等场景**。

Redis 提供了多种数据类型来支持不同的业务场景，比如 String(字符串)、Hash(哈希)、 List (列表)、Set(集合)、Zset(有序集合)、Bitmaps（位图）、HyperLogLog（基数统计）、GEO（地理信息）、Stream（流），并且对数据类型的操作都是**原子性**的，因为执行命令由单线程负责的，不存在并发竞争的问题。

### 2. Redis用作MySQL的缓存

Redis 具备高性能，将该用户访问的数据缓存在 Redis 中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了，操作 Redis 缓存就是直接操作内存，所以速度相当快。

Redis 具备高并发，直接访问 Redis 能够承受的请求是远远大于直接访问 MySQL 的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。

### 3. Redis数据结构

常见的有五种数据类型：**String（字符串），Hash（哈希），List（列表），Set（集合）、Zset（有序集合）**

![Redis数据类型](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/Redis%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.png)

随着版本的更新，后面又支持了四种数据类型：**BitMap,HyperLogLog, GEO, Stream**

常见5种数据类型的应用场景：

#### String

String是最基本的key-value结构，其主要内部实现是int和SDS。

其多用于缓存对象，常规计数，分布式锁，共享session等；

#### List

List列表是简单的字符串列表，**按照插入顺序排序**，可以从头部或尾部添加元素。

其内部实现主要由**双向链表或压缩列表**实现。如果列表元素个数小于512个，列表么每个元素的值都小于64字节，Redis会用压缩列表存储。如果不满足上述条件，则会用双向链表存储。但在3.2版本后，List就只由quicklist实现。

一般应用于消息队列（但是生产者需要自行实现全局唯一id，不能以消费组形式消费数据）等；

#### Hash

Hash是一个key-value的集合，其比较适合存储对象。

内部实现是由压缩列表或哈希表实现的。**在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了**

一般用于缓存对象，购物车等；

#### Set

Set是无序且唯一的存储集合。其内部实现使用哈希表或整数集合实现的。

应用场景有聚合计算（并集，交集，差集）常见，比如点赞，共同关注，抽奖活动等。

#### Zset

Zset是有序集合，其内部实现有跳表和listpack。

主要应用于排序场景，比如排行榜，电话和姓名排序等。

新增4种数据类型应用场景：

1. **BitMap**：二值状态统计的场景，比如签到，判断用户登录状态等；
2. **HyperLogLog**：海量数据基数统计的场景；
3. **GEO**：储存地理位置的场景；
4. **Strean**：消息队列，相比于List，可以自动生成全局唯一消息ID，支持以消费形式消费数组。

五种常见数据类型实现方式：

![img](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/9fa26a74965efbf0f56b707a03bb9b7f.png)

#### 键值对

Redis使用了一个哈希表来保存所有的键值对。在哈希表中的元素叫哈希桶，哈希桶中存放数据的指针，所以键值对的数据结构并不直接保存值本身，而是指向Redis对象。

#### SDS

Redis使用C语言实现的，但是他自己封装了简单动态字符串SDS。其结构如下：

![img](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/516738c4058cdf9109e40a7812ef4239-0210222.png)

其二进制安全，不会发生缓冲区溢出。

#### 压缩列表

压缩列表是由**连续内存块组成的顺序型数据结构**，类似于数组。

![img](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/ab0b44f557f8b5bc7acb3a53d43ebfcb.png)

压缩列表表头有三个字段：

- ***zlbytes***，记录整个压缩列表占用对内存字节数；
- ***zltail***，记录压缩列表「尾部」节点距离起始地址由多少字节，也就是列表尾的偏移量；
- ***zllen***，记录压缩列表包含的节点数量；
- ***zlend***，标记压缩列表的结束点，固定值 0xFF。

在压缩列表中查找头尾元素根据头结点信息进行定位会很快，但是查询中间元素的效率会下降到O(N)，因此不适合保存过多元素。

#### 哈希表

Redis采用链式哈希。

#### 整数集合

整数集合本质上是一块连续的内存空间。

#### 跳表

Redis只有Zset对象的底层实现用到了跳表，跳表的优势是能支持平均O(logN)复杂度的结点查找。

1. **结构设计**

   跳表是在链表基础上改进过来的，实现了一种多层的有序链表，好处是可以快速定位数据。

   以一个3层跳表的结构为例：

   ![img](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/3%E5%B1%82%E8%B7%B3%E8%A1%A8-%E8%B7%A8%E5%BA%A6.png)

   图中的头结点有L0-L2三个头指针，分别指向不同层级的结点，每个层级的结点都通过指针连接起来。

   跳表可以在多个层级上跳来跳去，所以当数据量大后，跳表的查找复杂度是O(logN)。Zset对象同时要保持元素和元素的权重，对应到跳表结点中就是sds类型的ele变量和double类型的score遍历。每个跳表结点都有一个向后指针，指向前一个结点。同时每一个层级可以包含多个结点，每一个结点通过指针连接起来，实现这一特性的就是跳表结构体种的**zskiplistLevel结构体类型的level数组**。跳表的跨度实际上是为了计算这个结点在跳表中的排位。

2. **查询过程**

   查找一个跳表结点，跳表会从头结点的最高层开始，逐一遍历每一层。再遍历某一层的跳表结点时，会用跳表结点中的SDS类型元素和元素权重来进行判断：

   - 如果当前节点的权重「小于」要查找的权重时，跳表就会访问该层上的下一个节点。
   - 如果当前节点的权重「等于」要查找的权重时，并且当前节点的 SDS 类型数据「小于」要查找的数据时，跳表就会访问该层上的下一个节点。

3. **层数设置**

   **跳表的相邻两层的结点数量最理想的比例是2:1，查找复杂度可以降到O(logN)。**

### 4. Redis线程

**Redis 单线程指的是「接收客户端请求->解析请求 ->进行数据读写等操作->发送数据给客户端」这个过程是由一个线程（主线程）来完成的**。但是**Redis 程序并不是单线程的**，Redis 在启动的时候，是会**启动后台线程**（BIO）

单线程模式

![redis单线程模型](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/redis%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B.png)

### 5. Redis持久化

当 Redis 重启后，内存中的数据就会丢失，那为了保证内存中的数据不会丢失，Redis 实现了数据持久化的机制，这个机制会把数据存储到磁盘，这样在 Redis 重启就能够从磁盘中恢复原有的数据。

Redis 共有三种数据持久化的方式：

- **AOF 日志**：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里；
- **RDB 快照**：将某一时刻的内存数据，以二进制的方式写入磁盘；
- **混合持久化方式**：Redis 4.0 新增的方式，集成了 AOF 和 RBD 的优点；

#### (1) AOF日志实现：

Redis 在执行完一条写操作命令后，就会把该命令以追加的方式写入到一个文件里，然后 Redis 重启时，会读取该文件记录的命令，然后逐一执行命令的方式来进行数据恢复。在主线程中执行

Reids 是先执行写操作命令后，才将该命令记录到 AOF 日志里的，这么做其实有两个好处：

**避免额外的检查开销**，**不会阻塞当前写操作命令的执行**。

但是也有风险：

**数据可能会丢失**，**可能阻塞其他操作**。

AOF有三种写回方式，Always, Everysec, No.

![img](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/98987d9417b2bab43087f45fc959d32a-0211787.png)

#### (2) RBF快照：

AOF 日志记录的是操作命令，不是实际的数据，恢复的时候和能会很慢。RDB 快照就是记录某一个瞬间的内存数据，记录的是实际数据。

Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave，他们的区别就在于是否在「主线程」里执行：

- 执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，**会阻塞主线程**；
- 执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以**避免主线程的阻塞**；

### 6. Redis集群

#### 主从复制

AOF和RDB这两个持久化技术保证了即使在服务器重启的情况下也不会丢失数据。但是由于数据都在一台服务器上，如果出事就会丢失数据。要避免这种单点故障。就需要将数据备份到其他服务器。让这些服务器也可以提供服务。这样一来即使某个服务器发生故障，其他服务器依然可以继续提供服务。为了让这些服务器之间的数据保持一致性，Redis提供了主从复制模式。

主从复制是 Redis 高可用服务的最基础的保证，实现方案就是将从前的一台 Redis 服务器，同步数据到多台从 Redis 服务器上，即一主多从的模式，且主从服务器之间采用的是「读写分离」的方式。

![主从复制](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6.png)

多台服务器使用 `replicaof` 命令来确定谁是主服务器。在从服务器上执行

`replicaof <主服务器的 IP 地址> <主服务器的 Redis 端口号>`

来进行主从服务器的分配。

Redis主从节点采用**长连接**的的方式。主从节点组成一个Redis集群，主从服务器之间采用ping-pong的心态检测机制。如果有一半以上的节点区ping一个节点而没有pong回应的话，那么集群就会认为这个节点挂掉了。从而断开与这个节点的连接。

如果主节点处理了一个key或者通过淘汰算法淘汰了一个key，这时主节点模拟一条del命令发送给从节点，从节点收到该命令后，就进行删除key操作。

Redis 主节点每次收到写命令之后，先写到内部的缓冲区，然后**异步**发送给从节点，所以**同步复制是异步操作**。不过由于是异步操作，所以主节点和从节点的数据**无法保持强一致性**，即时时刻刻保持一致。

主从复制一共有三种模式：**全量复制，基于场连接的命令传播，增量复制**。

主从服务器第一次同步的时候，采用全量复制；第一次同步完成后，主从服务器都会维护着一个长连接，主服务器在接收到写操作命令后，就会通过这个链接将写命令传给从服务器，来保证主从服务器的数据一致性。如果遇到网络断开，增量复制就可以上场了。

主节点挂掉后，从节点是无法自己升级到主节点的，需要人工外部处理，在此期间Redis无法提供写操作。

#### 哨兵模式

当 Redis 的主从服务器出现故障宕机时，需要手动进行恢复。哨兵模式做到了可以监控主从服务器，并且提供**主从节点故障转移的功能。**

![哨兵模式](/assets/blog_res/2023-03-16-%E6%95%B0%E6%8D%AE%E5%BA%93.assets/%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F.png)

哨兵其实是一个运行在特殊模式下的Redis进程，相当于一个观察节点。哨兵一般是以集群的方式部署的，至少需要三个结点，其主要负责三件事情：**监控，选主，通知**。哨兵结点之间是通过Redis的**Pub-Sub**机制来相互发现的。运行过程为：

1. 第一轮投票，判断主结点下线；
2. 第二轮投票，选出哨兵leader；
3. 有哨兵leader进行主从故障转移。

**如何判断主节点故障**

哨兵会每隔1秒给所有主从节点发送命令，当主从节点收到PING命令后，会发送一个响应命令给哨兵，这样就可以判断其是否下线。

如果节点在规定时间内没有响应PING命令，那么哨兵就会将其标记为**主观下线**。但是如果遇到网络拥塞或者主节点系统压力比较大，也会无法响应PING，但是这时主节点并没有下线。针对这种情况，哨兵在部署的时候会部署多个节点组成**哨兵集群**，**通过多个哨兵节点一起判断，就可以就可以避免单个哨兵因为自身网络状况不好，而误判主节点下线的情况**。

**如何选取leader**

哪个哨兵节点判断主节点为**客观下线**，这个哨兵节点就是候选者。候选者会向其他哨兵发送命令，表明希望成为leader来执行主从切换。让其他哨兵进行投票，在投票过程中，任何一个候选者需要拿到半数以上赞成票，并且拿到的票数要大于等于配置中 `quorum` 的值。

**故障转移**

主从故障转移操作包含以下四个步骤：

- 在已下线主节点属下的所有从节点里面，挑选出一个从节点，并将其转换为主节点。
- 让已下线主节点属下的所有从节点修改复制目标，修改为复制新主节点；
- 将新主节点的 IP 地址和信息，通过Pub-Sub机制通知给客户端；
- 继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点；

### 7. 缓存

#### 缓存雪崩

当**大量缓存数据在同一时间过期（失效）或者 Redis 故障宕机**时，如果此时有大量的用户请求，都无法在 Redis 中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃，这就是**缓存雪崩**的问题。

1. **大量数据同时过期**
   - 均匀设置过期时间；
   - 互斥锁；
   - 双 key 策略；
   - 后台更新缓存；
2. **Redis故障宕机**
   - 服务熔断或请求限流机制；
   - 构建 Redis 缓存高可靠集群；

#### 缓存击穿

如果缓存中的**某个热点数据过期**了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮，这就是**缓存击穿**的问题。

可以发现缓存击穿跟缓存雪崩很相似，你可以认为缓存击穿是缓存雪崩的一个子集。

应对缓存击穿可以采取前面说到两种方案：

- 互斥锁方案，保证同一时间只有一个业务线程更新缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。
- 不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间；

#### 缓存穿透

当用户访问的数据，**既不在缓存中，也不在数据库中**，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是**缓存穿透**的问题。

缓存穿透的发生一般有这两种情况：

- 业务误操作，缓存中的数据和数据库中的数据都被误删除了，所以导致缓存和数据库中都没有数据；
- 黑客恶意攻击，故意大量访问某些读取不存在数据的业务；

应对缓存穿透的方案，常见的方案有三种。

- 第一种方案，非法请求的限制；
- 第二种方案，缓存空值或者默认值；
- 第三种方案，使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在；

**布隆过滤器**

可以在写入数据库的时候，使用布隆过滤器做标记，当用户请求时，业务线程确认缓存失效后，可以通过查询布隆过滤器来快速判断数据是否存在，如果不存在就查询数据库。

布隆过滤器由「初始值都为 0 的位图数组」和「 N 个哈希函数」两部分组成。当我们在写入数据库数据时，在布隆过滤器里做个标记，这样下次查询数据是否在数据库时，只需要查询布隆过滤器，如果查询到数据没有被标记，说明不在数据库中。

布隆过滤器会通过 3 个操作完成标记：

- 第一步，使用 N 个哈希函数分别对数据做哈希计算，得到 N 个哈希值；
- 第二步，将第一步得到的 N 个哈希值对位图数组的长度取模，得到每个哈希值在位图数组的对应位置。
- 第三步，将每个哈希值在位图数组的对应位置的值设置为 1；

#### 热key问题

当有几十万的请求突然去访问Redis上的某个特定key，那么这样会导致流量过于集中，产生热key问题。

解决的方式有

- 利用二级缓存：比如 `ehcache` 或者 `Hashmap` ，当发现热key后，把热key加载到jvm中。针对这种热key请求，会直接从jvm中取，而不会走到redis层。
- 备份热key：把这个key，在多个redis上都存一份。当有热key请求进来的时候，我们就在有备份的redis上随机选取一台，进行访问取值，返回数据。

